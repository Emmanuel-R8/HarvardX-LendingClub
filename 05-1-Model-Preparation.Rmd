# Logistic Regression Model and Credit Scorecard


At the outset, the dataset presents a number of challenges:

+ There is a mix of continuous and categorical data.

+ The number of observations is very large. 

+ The possible number of predictors is large (partially due to one-hot encoding of categorical values).

+ As shown in the previous section, credit margins have changed over time. This is clearly related to the wider US economic environment. Financial hardship is a key driver for some of the loans. Availability of disposable income is important to assess the ability to repay. Therefore, the cost of living, which varies from state to state, seems relevant. 


[TODO: Bias/Complexity trade-off]
[TODO: AoC? or AuC?]


## Introduction

### Split

The dataset was randomly split into training and validation sets (80/20 ratio).

We initiated the exploration of potential models with Principal Component Analysis, Linear Regression, Extreme Boosting and Random Forest. No model could be trained on the full set. We therefore came to limit the training set on a random sample of 0.1% (1 thousandth) of the initial full set.

Any model will require training in batch (e.g. stochastic gradient descent) or online. Our untested intuition is that online methods are not adapted to an unbalanced dataset: the number of defaults/write-offs is fairly low for high quality ratings. However, the dataset is evidently a time series which points to online training. We will not explore that line of investigation, although exploring that tension would be an interesting subject.

### The modeling task

Two step process:
- Given dataset (+/- rating?) find a score between -5 and +5
- Given a score between -5 and +5 given the right parameters for the modes
- Given a density curve extrapolate the required margin

- Make money or not?



> WARNING: To run this model, you will need at least 32GB of memory (real plus virtual/swap space) 

## Weight of evidence binning

### Data preparation

>
> WARNING: Execute `CleanLoad.Rmd` first
>


```{r 05-01-m1-clean-load,echo=FALSE,child="CleanLoad.Rmd"}
```
```{r}
# AFTER EXECUTION OF `CleanLoad.Rmd`

# Variables not used
rm(lending_club, loans)
```
```{r 05-01-load-loans-training,echo=FALSE}
# Datasets to be ready for first training
loansTraining <- readRDS("datasets/LoansTraining.rds")
```
```{r 05-01-load-loans-test,echo=FALSE}
loansTest     <- readRDS("datasets/LoansTest.rds")
```
```{r 05-01-load-IV,echo=FALSE}
#informationValues <- readRDS("datasets/informationValues100.rds")
```
```{r 05-01-load-listBins,echo=FALSE}
#listBins      <- readRDS("datasets/listBins100.rds")
```
```{r 05-01-load-bestBins,echo=FALSE}
#bestBins      <- readRDS("datasets/bestBins100.rds")
```
```{r 05-01-load-allBins,echo=FALSE}
#allBins       <- readRDS("datasets/allBins100.rds")
```
```{r 05-01-load-loans-samples,echo=FALSE}
# loansWorkingSet <- readRDS("datasets/LoansWorkingSet.rds") # Not on github because too big
#loanSample    <- readRDS("datasets/LoanSample.rds")

```


```{r 05-01-vars-inout}
# select the variables that might be used to create the training+test set 
modelVarsIn <- c(LC_variable[LC_variable$inModel == TRUE, "variable_name"])$variable_name
modelVarsIn <- c(modelVarsIn, 
                 "grade_num", "sub_grade_num", 
                 "principal_loss_pct", "creditMargin", "monthDefault")

# Make sure that some variables are NOT in included in the final training set
modelVarsOut <- c("grade_num", "sub_grade_num", 
                  "principal_loss_pct", "creditMargin", "monthDefault", 
                  "zip_code")
```


```{r 05-01-loan-predictors}
## ###############################################################################################
##
## Prepare a dataset with ONLY the predictors NOT removing NA's
## 
loansPredictors <-
  loansWorkingSet %>%

  # Keep the chosen predictors
  # Use tidyselect::one_of() to avoid errors if column does not exist
  select(tidyselect::one_of(modelVarsIn)) %>%

  ##
  ## Dates to numeric, in 'decimal' years since 2000
  ##
  mutate_at(c("issue_d", "earliest_cr_line"), function(d) {
    return(year(d) - 2000 + (month(d) - 1) / 12)
  }) %>%

  ## Add polynomials of the dates to model the time-trend shape
  mutate(
    issue_d2 = issue_d^2,
    issue_d3 = issue_d^3,
    earliest_cr_line2 = earliest_cr_line^2,
    earliest_cr_line3 = earliest_cr_line^3
  ) %>%

  ## Create a logical flag TRUE for non-defaulted (good) loans
  mutate(isGoodLoan = (principal_loss_pct < 0.001)) %>%

  select(-tidyselect::one_of(modelVarsOut))



## ###############################################################################################
##
## Create training / test sets 80%/20%
##
proportionTraining <- 0.8
set.seed(42)

nSamples <- nrow(loansPredictors)

sampleTraining <- sample(1:nSamples, floor(nSamples * proportionTraining), replace = FALSE)
loansTraining <- loansPredictors %>% slice(sampleTraining)
loansTest <- loansPredictors %>% slice(-sampleTraining)

# Subsets of the training set
set.seed(42)
nSamplesTraining <- nrow(loansTraining)

# 1%
sample01 <- sample(1:nSamplesTraining, floor(nSamplesTraining * 0.01), replace = FALSE)
loans01 <- loansTraining %>% slice(sample01)

# 20%
sample20 <- sample(1:nSamplesTraining, floor(nSamplesTraining * 0.20), replace = FALSE)
loans20 <- loansTraining %>% slice(sample20)
```

```{r 05-01-cleanup}
# Not used later on
rm(loansWorkingSet, loansPredictors, LoansNPV, LoansIRR, LoansMargin, RATES, RATES3Y, RATES5Y)
gc(full = TRUE)
```



## Model using all samples

```{r 05-01-reinstall-binner}

# Ensure that `binner` is here and available
if ("package:binner" %in% search()) { 
  detach("package:binner", unload = TRUE, force = TRUE) 
}

if (!("binner" %in% installed.packages()[,1])) {
  devtools::install_local("~/Development/R/DVPT-PACKAGES/Score_modeling_binning/binner", 
                          force = TRUE, 
                          quiet = TRUE)
  # devtools::install_github("Emmanuel-R8/SMBinning")
}

library(binner)
```

### Loop through all variables

```{r 05-01-create-all-bins}
loansBinning <- loansTraining %>%
  mutate(
    home_ownership = as_factor(home_ownership),
    emp_length = as_factor(emp_length),
    grade = as_factor(grade)
  )

informationValues <- tibble(variable = names(loansBinning), IV = -1.0)

listBins <-
  tibble(
    variable = "",
    type = "",
    IV = 0.0,
    WoE = list(),
    .rows = 0
  )

# About 500 sec wall-time
startTime <- proc.time()
for (n in informationValues$variable) {
  cat("Variable: ", n)

  # We don't test the response with itself
  if (n %in% c("isGoodLoan")) {
    cat("\n")

  } else {
    if (class(loansBinning[[1, n]]) == "factor") {
      cat(" is a factor, ")
      result <- WoETableCategorical(
        df = loansBinning,
        x = n,
        y = "isGoodLoan",
        maxCategories = 100)

    } else {
      cat(" is numeric, ")
      result <- WoETableContinuous(df = loansBinning,
                                   x = n,
                                   y = "isGoodLoan",
                                   p = 0.05)
    }

    tryCatch({
      if (is.na(result)) {
        cat("Variable skipped.\n")
        add_row(
          listBins,
          variable = n,
          type = NA,
          IV = NA
        )
      } else {
        cat("     IV : ", result$IV, "\n")

        listBins <- listBins %>%
          add_row(
            variable = n,
            type = result$type,
            IV = result$IV,
            WoE = list(result$table)
          )
        
        informationValues[n] <- result$IV
        
        }
    },
    finally = {})
  }
}
proc.time() - startTime

# saveRDS(informationValues, "datasets/informationValues100.rds")
# saveRDS(listBins, "datasets/listBins100.rds")

```

### Select relevant variables

Ignore the variables that would not be available at the time the credit scoring is performed.

```{r 05-01-create-bestbins}

# This shows that almost all variables have an information value above 2% which is considered the threshold to be weakly
# useful. Useless variables are all related to F and G ratings which we do not use anyway.
for (i in 1:length(listBins$variable)) {
  useless <- listBins$WoE[i] %>% as.data.frame() %>% filter(IV <= 0.02)
  if (nrow(useless) > 0) print(useless)
}

bestBins <- listBins %>%
  arrange(desc(IV)) %>%
  filter(!(variable %in% c(
    "loanID", "term", "int_rate", "creditMargin", "loan_status",
    "grade", "sub_grade", "grade_num", "sub_grade_num",
    "emp_length", "home_ownership", "monthDefault",
    "principal_loss_pct", "creditMargin", "monthDefault",
    "isGoodLoan")))


bestBins

# saveRDS(bestBins, "datasets/bestBins100.rds")

```

### Create data table with only binary variables (transform every bin to a 0/1 value)

For each variable, create new variables for each bin in the WoE table of that variable.

```{r 05-01-create-factored-datasets}
# Variable will contain all the best characteristics. Every continuous variable is reformatted
# into factors reflecting the appropriate bins

allFactorsAsCharacteristics <- loansTraining[,"loanID"]
allFactorsAsBins <- loansTraining[,"loanID"]



for (index in 1:nrow(bestBins)) {
#for (index in 1:3) {
  name <- bestBins$variable[index][[1]]
  
  cat("--------------------",
      index,
      "--",
      name, "\n")
  
  ltIndex <- which(names(loansTraining) == name)
  
  characteristic <- categoriseFromWoE(df = loansTraining[, ltIndex],
                                      varName =  name,
                                      woeTable = bestBins$WoE[index][[1]])
  
  bins <- categoriseFromWoE.Wide(df = loansTraining[, ltIndex],
                                 varName =  name,
                                 woeTable = bestBins$WoE[index][[1]])
  
  allFactorsAsCharacteristics <-
    allFactorsAsCharacteristics %>%
    cbind(characteristic)
  
  
  allFactorsAsBins <-
    allFactorsAsBins %>%
    cbind(bins)
  
}

# saveRDS(allFactorsAsCharacteristics, "datasets/allCharacteristics100.rds") ; saveRDS(allFactorsAsBins, "datasets/allBins100.rds")

```



### Comparison of individual characteristics

>
> [TODO]
> Present data by order of IV
> Sort WoE buildup for key IV


+ re-train secures the lowest Akaike criterion and will be chosen.

+ On this test, the best variables are: SORT BY IV. Then WoE for the first few ones.



```{r}
loansBinning <- loans20 %>%
  mutate(
    home_ownership = as_factor(home_ownership),
    emp_length = as_factor(emp_length)
  )
```

#### dti

```{r}
resultHome <- WoETableContinuous(
  df = loansBinning,
  x = "dti",
  y = "isGoodLoan",
  p = 0.05
)

resultHome$table
resultHome$IV
```

#### Home ownership

```{r}
resultHome <- WoETable(
  df = loansBinning,
  x = "home_ownership",
  y = "isGoodLoan",
  maxCategories = 20
)

resultHome
resultHome$IV
```

#### Verification Status

```{r}
resultVerif <- WoETable(
  df = loansBinning,
  x = "verification_status",
  y = "isGoodLoan",
  maxCategories = 20
)

resultVerif
resultVerif$IV
```



#### Purpose

```{r}
resultHome <- WoETable(
  df = loansBinning,
  x = "purpose",
  y = "isGoodLoan",
  maxCategories = 20
)

resultHome
resultHome$IV
```


#### Sub grade

```{r}
resultSubgrade <- WoETable(
  df = loansBinning,
  x = "sub_grade",
  y = "isGoodLoan",
  maxCategories = 50
)

resultSubgrade
resultSubgrade$IV
```



#### Employment years

```{r}
resultEmp <- WoETable(
  df = loansBinning,
  x = "emp_length",
  y = "isGoodLoan",
  maxCategories = 20
)

resultEmp
resultEmp$IV
```



#### Bank card utilisation

```{r}
resultBC <- WoETable(
  df = loansBinning,
  x = "bc_util",
  y = "isGoodLoan",
  p = 0.05
)

resultBC
resultBC$IV
```

#### State

```{r}
resultState <- WoETable(
  df = loansBinning,
  x = "addr_state",
  y = "isGoodLoan",
  maxCategories = 100
)

resultState
resultState$IV
```


#### Annual income

```{r}
which(names(loansBinning) == "annual_inc_joint")

resultInc <- WoETable(
  df = loansBinning,
  x = "annual_inc_joint",
  y = "isGoodLoan",
  p = 0.05
)

resultHome
resultHome$iv
```

#### Loan amount

```{r}
resultAmnt <- WoETable(
  df = loansBinning,
  x = "loan_amnt",
  y = "isGoodLoan",
  p = 0.05
)

resultAmnt
resultAmnt$IV

categoriseFromWoE(df = loansBinning, 
                  varName = "loan_amnt", 
                  woeTable = resultAmnt,
                  verbose = TRUE)

```
