
## Model result

### Final list of variables

```{r echo=FALSE,message=FALSE}
library(tidyverse)
rm(loansTraining, allFactorsAsCharacteristics, allFactorsAsBins, loanSampleBins, loanSampleCharacteristics)
knitr::opts_chunk$set(
  # Chunks
  eval = TRUE,
  cache = TRUE,
  echo = TRUE,
  message = FALSE,
  warning = FALSE)
```


```{r 05-03-load-models,echo=FALSE,message=FALSE}
# Saved at the end of the modeling file
SGLM_B_train <- readRDS("datasets/SGLM_B_train.rds")
SGLM_B_retrain <- readRDS("datasets/SGLM_B_retrain.rds")
SGLM_B_reretrain <- readRDS("datasets/SGLM_B_reretrain.rds")
```


```{r 05-03-model-names}
# Model to use
GLModel <- SGLM_B_retrain

# List of model variables
modelNames <- 
  attr(GLModel$coefficients, "names") %>%
  enframe(x = .) %>%
  rename(variableName = "value") %>%
  select(variableName) %>%
  mutate(variableName = str_remove_all(variableName, "\`"))
```


```{r 05-03-extract-coefficients}
# and their coefficients in the model (the summary function for speedglm objects is not exported and
# bookdown seems to have a problem with that).

sumSpeed <- speedglm:::summary.speedglm

GLMCoefficients <- 
  sumSpeed(GLModel)$coefficients %>%
  as_tibble() %>%
  cbind(modelNames) %>%
  rename(
    zValue = "z value",
    pValue = "Pr(>|z|)",
    stdErr = "Std. Error"
  ) %>%

  # reorder columns to have names first
  select(variableName, everything())

```


### Scoring

Scoring expresses the coefficients that were estimated during the logistic regression into points on a scale. The conversion is done using  three parameters that are chosen somewhat arbitrarily.

+ the number of points increase / decrease that would reflect halving / doubling the odds of defaulting;

+ an _anchoring_ score reflecting a particular odd.

For our purpose, we will choose 5,000 points ($\text{Score}_{anchor}$) being equivalent to 1 in a 20 to default ($\text{Odds}_{anchor}$), i.e. $\text{Score}_{anchor}$ 5,000 points <=> $\text{Odds}_{Anchor} = \frac{1 / 20}{1 - 1/20}$. We will also choose 100 to reflect _times 2_ change in odds ($DoubleOdds$). Those choices are completely arbitrary. Basically, the score is a linear representation of the odds. The score is defined by a point (the anchor) and the slope of the line going through that point.

Those values will reflect the total estimated score for a borrower (i.e. loan sample). The number of characteristics (information points gathered in a credit application), or number of bins, have to be irrelevant in calculating this score. In other words, if LendingClub were to gather 5 more information points, the score should, __mutatis mutandis__, be unchanged. (However, we would hope that the quality of the estimated score would improve.)

The score per variable needs to be adjusted using the number of information points, that is the number of characteristics. Here, the model has been trained on the number of bins. We first need to determine how many characteristics are used in the model.


```{r 05-03-calculate-n-characteristics}

# The list of characteristics is extracted from the list of bins names.
numberOfCharacteristics <-

  modelNames %>%

  # List of all names excluding the intercept which is not part of the scoring calculations (it
  # would mean giving points for free as a base line)
  filter(variableName != "(Intercept)") %>%

  # Extract strings ("[a-zA-Z0-9-_]*") preceded by an opening bracket ("(?<=\\()") and followed by a
  # closing bracket ("(?=\\))"). (The column names were formatted this way for that purpose.) See
  # "https://github.com/rstudio/cheatsheets/blob/master/strings.pdf" for details on the regex.
  mutate(characteristic = str_match(variableName, "(?<=\\()[a-zA-Z0-9-_]*(?=\\))")) %>%

  # We are only interested in how many distinct characteristic there are.
  distinct(characteristic) %>%
  nrow()

numberOfCharacteristics
```


We can now perform the scoring calculation. 


```{r 05-03-scoring-parameters}

ProbDefaultAtAnchor <- 1/20

# The model is trained so that the 'Good' outcome is that a loan does not default. The odds that
# therefore calculated on the probability of no default.
ProbAtAnchor <- 1 - ProbDefaultAtAnchor
OddsAnchor <- ProbAtAnchor / (1 - ProbAtAnchor)
ScoreAnchor <- 2000

# Doubling odds = 100 points
DoubleOdds <- 100

ScoreFactor <- OddsAnchor / log(2)

# 5,000 points is 20:1 odds of default
ScoreOffset <- ScoreAnchor - ScoreFactor * log(OddsAnchor)

# Score at the intercept
Intercept <- summary(GLModel)$coefficients["(Intercept)", "Estimate"]
```

Then we apportion across characteristics.

```{r 05-03-parameters-per-chr}
ScorePerVariable <- (ScoreFactor * Intercept + ScoreOffset) / numberOfCharacteristics 
InterceptPerVariable <- Intercept * ScoreFactor / numberOfCharacteristics

GLMScores <-
  GLMCoefficients %>%
  mutate(
    weight = Estimate * ScoreFactor,
    weightScaled = weight + ScorePerVariable,
    points = round(weightScaled)
  )
```

> VERY IMPORTANT:

The intercept points have been allocated across all characteristics. Therefore the regression coefficient estimated for the intercept becomes redundant and needs removing.

```{r}
GLMScores[1, "points"] <-  0
```


The `speedglm` package does not have a `predict` function once models have been trained. However, using the model is a simple matrix multiplication: $\text{Loan matrix} \times \text{Scorecard weights}$

## Training set

```{r 05-03-load-factored-datasets,echo=FALSE,message=FALSE}
# Reload the right datasets
allFactorsAsBins <- readRDS("datasets/allBins100.rds")
loansTraining <- readRDS("datasets/LoansTraining.rds")
loansTest <- readRDS("datasets/LoansTest.rds")
```


```{r message=FALSE,echo=FALSE,cache=FALSE}
gc(full = TRUE)
```


```{r 05-03-convert-to-matrix}
# Remove every variable that is not in the list of variables in the model then convert into a matrix
allMatrix <-
  allFactorsAsBins[, !is.na(match(
    names(allFactorsAsBins),
    str_remove_all(GLMCoefficients$variableName, "\`")
  ))] %>%
  as.matrix()
```


```{r 05-03-matrix-add-1-col}
# Add a column of 1s for the intercept
allMatrix <-
  cbind(as.vector(rep.int(
    x = 1, times = dim(allMatrix)[1]
  )), allMatrix)
dim(allMatrix)
```

```{r message=FALSE,echo=FALSE}
# Done with this dataset
rm(allFactorsAsBins)
gc(full = TRUE)
```


```{r 05-03-logit-estimates}
CoefficientsVector <- GLMCoefficients$Estimate %>% as.matrix()

# Score per variable
TrainingScorecard <- allMatrix %*% ( GLMScores$points %>% as.matrix() ) 
dim(allMatrix)
dim(GLMScores$points)

# CHECK: Any variable with NAs?
# GLMCoefficients$modelName[which(is.na(CoefficientsVector))]
# CoefficientsVector[is.na(CoefficientsVector)] <- 0
# dim(CoefficientsVector)

TrainingLogit <- allMatrix %*% CoefficientsVector
TrainingLogit <-
  enframe(TrainingLogit[, 1]) %>%
  mutate(oddsGood = exp(value),
         p = 1 / (1 + oddsGood)) %>% 
  cbind(TrainingScorecard)


```


### Densities of the training results

We plot the results of the training model and group the results by rating ("A" to "G") in Figure \@ref(fig:05-03-training-hists-value).



```{r 05-03-training-hists-value,fig.cap="Model results on the training set"}


gridExtra::grid.arrange(
  loansTraining %>%
    cbind(TrainingLogit) %>%
    filter(between(value, -2, 5)) %>%
    ggplot(aes(value, col = grade)) +
    geom_density(adjust = 0.5) +
    ggtitle("Logit value"),
  
  loansTraining %>%
    cbind(TrainingLogit) %>%
    ggplot(aes(p, col = grade)) +
    geom_density(adjust = 0.5) +
    scale_x_log10() +
    ggtitle("Probability of being GOOD"),
  
  loansTraining %>%
    cbind(TrainingLogit) %>%
    filter(between(oddsGood, 0.1, 100)) %>%
    ggplot(aes(oddsGood, col = grade)) +
    geom_density(adjust = 0.5) +
    scale_x_log10() +
    ggtitle("Odds of being GOOD"),
  
  loansTraining %>%
    cbind(TrainingLogit) %>%
    ggplot(aes(TrainingScorecard, col = grade)) +
    geom_density(adjust = 1) +
    ggtitle("Scorecards"),

  ncol = 1
)

```


## Test set

```{r 05-03-test-bins}
# Prepare the full test set
bestBins <- readRDS("datasets/bestBins100.rds")
predictionCategories <- loansTest[, "loanID"]

for (index in 1:length(bestBins$variable)) {
  binned <-
    binner::categoriseFromWoE.Wide(
      df = loansTest,
      varName = bestBins$variable[index],
      woeTable = bestBins$WoE[[index]]
    )

  predictionCategories <- cbind(predictionCategories, binned)
}

dim(predictionCategories)
```


```{r 05-03-test-matrix-select-variables}
# Retain only the relevant scorecard categories
predictionMatrix <-
  predictionCategories[, !is.na(match(
    names(predictionCategories),
    str_remove_all(GLMCoefficients$variableName, "\`")
  ))] %>%
  as.matrix()
```


```{r 05-03-test-matrix-add-1-col}
predictionMatrix <- cbind(as.vector(rep.int(x = 1, times = dim(predictionMatrix)[1])), predictionMatrix)
dim(predictionMatrix)
```


```{r 05-03-test-matrix}
TestLogit <- predictionMatrix %*% CoefficientsVector
TestLogit <-
  tibble::enframe(TestLogit[, 1]) %>%
  mutate(
    p = 1 / (1 + exp(-value)),
    oddsGood = if_else(is.infinite(p / (1 - p)), 1e10, p / (1 - p)))

predictionScorecard <- predictionMatrix %*% ( GLMScores$points %>% as.matrix() ) 
```

```{r 05-03-test-estimates,fig.cap="Density of loans by scorecard"}
loansTest %>%
  cbind(TestLogit) %>%
  cbind(predictionScorecard) %>%
  filter(predictionScorecard > 0) %>%
  ggplot(aes(predictionScorecard)) +
  geom_density(col = "blue", fill = "lightblue", adjust = 3)

```


```{r 05-03-test-estimates-median}
median(predictionScorecard)
```

Same downward dynamics as training set


```{r 05-03-test-viz-value,fig.cap="Logit value predicted by the model"}
loansTest %>%
  cbind(TestLogit) %>%
  filter(between(value, -2, 5)) %>% 
  ggplot(aes(value, col = grade)) +
  geom_density(adjust = 2)
```


```{r 05-03-test-viz-p,fig.cap="Probability of a loan being GOOD predicted by the model"}
loansTest %>%
  cbind(TestLogit) %>%
  ggplot(aes(p, col = grade)) +
  geom_density(adjust = 2) +
  scale_x_log10()
```


```{r 05-03-test-viz-odds,fig.cap="Odds of a loan being GOOD predicted by the model"}
loansTest %>%
  cbind(TestLogit) %>%
  filter(between(oddsGood, 0.1, 100)) %>% 
  ggplot(aes(oddsGood, col = grade)) +
  geom_density(adjust = 2) + 
  scale_x_log10()
  
```


## Confusion matrix

Given a probability $p$ from the model, we use a $p = 0.50$ cut-off point to decide whether a loan is Good or Bad. The Confusion Matrix results are:

```{r 05-03-test-confusion-matrix,echo=TRUE}
tCM <- loansTest %>%
  cbind(TestLogit) %>%
  select(p, isGoodLoan) %>% 
  
  mutate(p = if_else(p >= 0.50, "GOOD", "BAD"), 
         isGoodLoan = if_else(isGoodLoan, "GOOD", "BAD")) %>% 
  rename(Predicted = p, 
         Actual = isGoodLoan) %>% 
  
  table() %>% 
  caret::confusionMatrix(positive = "GOOD")

tCM

```

The results suggest that the model is effrective at predicting good loans (measured by the sensitivity = $\frac{TP}{TP + FN}$ = `r round(100*tCM$byClass["Sensitivity"], digits = 2)`%). However, this is deceptive since the dataset is unbalanced. The model is performing poorly at detecting bad loans (measured by the specificity = $\frac{TN}{TN + FP}$ = `r round(100*tCM$byClass["Specificity"], digits = 2)`%) The dataset is unbalanced and measuring the model's performance with a confusion matrix is imprecise. A much better approach would be to train many models on balanced datasets (by sampling a reduced 'good loans' dataset) and study the distribution of that resulting models and their parameters.

More critically, tThe confusion matrix does not  (and cannot) reflect the consequence of getting predictions wrong. At the end of the day, the only relevant consequence is estimating the number of dollars lost on a loan. A misqualified loan might lead to a loss of a single dollar, or a million. Predicting a probability of default is not enough. We need to subsequently predict the expected loss when a particular loan defaults. In the conclusion, we suggest one possible avenue.


## ROC Curve

A popular measure for the performance of such a logistic regression model is to consider its _Receiver Operating Characteristic_ curve (_ROC_) and calculate its area under curve (_AUC_). Ideally, a model able to perfectly classify 



```{r 05-03-test-ROC,echo=TRUE}
ROCRPrediction <- ROCR::prediction(TestLogit$value, loansTest$isGoodLoan)
ROCRPerformance <- ROCR::performance(ROCRPrediction, "tpr", "fpr")

ROCData <- tibble(x = ROCRPerformance@x.values[[1]], 
       y = ROCRPerformance@y.values[[1]])

ROCData %>% 
  ggplot(aes(x, y)) +
  geom_point(alpha = 0.2, col = "blue")

```


```{r 05-03-test-ROC2}
stats::ks.test(x = ROCData$x, y = ROCData$y)
```


