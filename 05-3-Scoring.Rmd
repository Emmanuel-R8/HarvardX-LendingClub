
## Model result

### Final list of variables

```{r 05-03-load-models,echo=FALSE,message=FALSE}

rm(loansTraining, allFactorsAsCharacteristics, allFactorsAsBins, loanSampleBins, loanSampleCharacteristics)

# Saved at the end of the modeling file
SGLM_B_train <- readRDS("datasets/SGLM_B_train.rds")
SGLM_B_retrain <- readRDS("datasets/SGLM_B_retrain.rds")
SGLM_B_reretrain <- readRDS("datasets/SGLM_B_reretrain.rds")
```


```{r 05-03-model-names}
# Model to use
GLModel <- SGLM_B_retrain

# List of model variables
modelNames <- 
  attr(GLModel$coefficients, "names") %>%
  enframe(x = .) %>%
  rename(variableName = "value") %>%
  select(variableName) %>%
  mutate(variableName = str_remove_all(variableName, "\`"))
```


```{r 05-03-extract-coefficients}
# and their coefficients in the model (the summary function for speedglm objects is not exported and
# bookdown seems to have a problem with that).

sumSpeed <- speedglm:::summary.speedglm

GLMCoefficients <- 
  sumSpeed(GLModel)$coefficients %>%
  as_tibble() %>%
  cbind(modelNames) %>%
  rename(
    zValue = "z value",
    pValue = "Pr(>|z|)",
    stdErr = "Std. Error"
  ) %>%

  # reorder columns to have names first
  select(variableName, everything())

```


### Scoring

Scoring expresses the coefficients that were estimated during the logistic regression into points on a scale. The conversion is done using  three parameters that are chosen somewhat arbitrarily.

+ the number of points increase / decrease that would reflect halving / doubling the odds of defaulting;

+ an _anchoring_ score reflecting a particular odd.

For our purpose, we will choose ($Score_{anchor}$) 5,000 points being equivalent to 1 in a 20 to default ($Odds_{anchor}$), i.e. 5,000 points <=> $Odds_{Anchor} = \frac{1 / 20}{1 - 1/20}$. We will also choose 100 to reflect _times 2_ change in odds ($DoubleOdds$). Those choices are completely arbitrary. Basically, the score is a linear representation of the odds. The score is defined by a point (the anchor) and the slope of the line going through that point.

Those values will reflect the total estimated score for a borrower (i.e. loan sample). The number of characteristics (information points gathered in a credit application), or number of bins, have to be irrelevant in calculating this score. In other words, if LendingClub were to gather 5 more information points, the score should, __mutatis mutandis__, be unchanged. (However, we would hope that the quality of the estimated score would improve.)

The score per variable needs to be adjusted using the number of information points, that is the number of characteristics. Here, the model has been trained on the number of bins. We first need to determine how many characteristics are used in the model.


```{r 05-03-calculate-n-characteristics}

# The list of characteristics is extracted from the list of bins names.
numberOfCharacteristics <-

  modelNames %>%

  # List of all names excluding the intercept which is not part of the scoring calculations (it
  # would mean giving points for free as a base line)
  filter(variableName != "(Intercept)") %>%

  # Extract strings ("[a-zA-Z0-9-_]*") preceded by an opening bracket ("(?<=\\()") and followed by a
  # closing bracket ("(?=\\))"). (The column names were formatted this way for that purpose.) See
  # "https://github.com/rstudio/cheatsheets/blob/master/strings.pdf" for details on the regex.
  mutate(characteristic = str_match(variableName, "(?<=\\()[a-zA-Z0-9-_]*(?=\\))")) %>%

  # We are only interested in how many distinct characteristic there are.
  distinct(characteristic) %>%
  nrow()

numberOfCharacteristics
```


We can now perform the scoring calculation. 


```{r 05-03-scoring-parameters}

ProbDefaultAtAnchor <- 1/20

# The model is trained so that the 'Good' outcome is that a loan does not default. The odds that
# therefore calculated on the probability of no default.
ProbAtAnchor <- 1 - ProbDefaultAtAnchor
OddsAnchor <- ProbAtAnchor / (1 - ProbAtAnchor)
ScoreAnchor <- 2000

# Doubling odds = 100 points
DoubleOdds <- 100

ScoreFactor <- OddsAnchor / log(2)

# 5,000 points is 20:1 odds of default
ScoreOffset <- ScoreAnchor - ScoreFactor * log(OddsAnchor)

# Score at the intercept
Intercept <- summary(GLModel)$coefficients["(Intercept)", "Estimate"]
```

Then we apportion across characteristics.

```{r 05-03-parameters-per-chr}
ScorePerVariable <- (ScoreFactor * Intercept + ScoreOffset) / numberOfCharacteristics 
InterceptPerVariable <- Intercept * ScoreFactor / numberOfCharacteristics

GLMScores <-
  GLMCoefficients %>%
  mutate(
    weight = Estimate * ScoreFactor,
    weightScaled = weight + ScorePerVariable,
    points = round(weightScaled)
  )
```

> VERY IMPORTANT:

The intercept points have been allocated across all characteristics. Therefore the regression coefficient estimated for the intercept becomes redundant and needs removing.

```{r}
GLMScores[1, "points"] <-  0
```




Using the model is a simple matrix multiplication: $\text{Loan matrix} \times \text{Scorecard weights}$

## Training set

```{r 05-03-load-factored-datasets}
# Reload the right datasets
allFactorsAsBins <- readRDS("datasets/allBins100.rds")
loansTraining <- readRDS("datasets/LoansTraining.rds")
loansTest <- readRDS("datasets/LoansTest.rds")
gc(full = TRUE)
```


```{r 05-03-convert-to-matrix}
# Remove every variable that is not in the list of variables in the model then convert into a matrix
allMatrix <-
  allFactorsAsBins[, !is.na(match(
    names(allFactorsAsBins),
    str_remove_all(GLMCoefficients$variableName, "\`")
  ))] %>%
  as.matrix()
```


```{r 05-03-matrix-add-1-col}
# Add a column of 1s for the intercept
allMatrix <-
  cbind(as.vector(rep.int(
    x = 1, times = dim(allMatrix)[1]
  )), allMatrix)
dim(allMatrix)
```


```{r 05-03-matrix-cleanup}
# Done with this dataset
rm(allFactorsAsBins)
gc(full = TRUE)
```


```{r 05-03-logit-estimates}
CoefficientsVector <- GLMCoefficients$Estimate %>% as.matrix()

# Score per variable
TrainingScorecard <- allMatrix %*% ( GLMScores$points %>% as.matrix() ) 
dim(allMatrix)
dim(GLMScores$points)

# CHECK: Any variable with NAs?
# GLMCoefficients$modelName[which(is.na(CoefficientsVector))]
# CoefficientsVector[is.na(CoefficientsVector)] <- 0
# dim(CoefficientsVector)

TrainingLogit <- allMatrix %*% CoefficientsVector
TrainingLogit <-
  enframe(TrainingLogit[, 1]) %>%
  mutate(oddsGood = exp(value),
         p = 1 / (1 + oddsGood)) %>% 
  cbind(TrainingScorecard)


```


### Histogram of the scores


```{r 05-03-training-hists-value}
loansTraining %>%
  cbind(TrainingLogit) %>%
  filter(between(value, -2, 5)) %>% 
  ggplot(aes(value, col = grade)) +
  geom_density(adjust = 2)
```


```{r 05-03-training-hists-p}
loansTraining %>%
  cbind(TrainingLogit) %>%
  ggplot(aes(p, col = grade)) +
  geom_density(adjust = 2) +
  scale_x_log10()
```


```{r 05-03-training-hists-odds}
loansTraining %>%
  cbind(TrainingLogit) %>%
  filter(between(oddsGood, 0.1, 100)) %>% 
  ggplot(aes(oddsGood, col = grade)) +
  geom_density(adjust = 2) + 
  scale_x_log10()
  
```

The following histogram shows the density plot of the scorecards. Note the log-scale for the score, and the square-root scale for the density. It mirrors the multimodal density distributions of previous visualisations. 

```{r 05-03-training-scores}
loansTraining %>%
  cbind(TrainingLogit) %>%
  ggplot(aes(TrainingScorecard, col = grade)) +
  geom_density(adjust = 2) +
  scale_x_log10() + 
  scale_y_sqrt()
```



## Test set

```{r 05-03-test-bins}
# Prepare the full test set
bestBins <- readRDS("datasets/bestBins100.rds")

predictionCategories <- loansTest[, "loanID"]

for (index in 1:length(bestBins$variable)) {
  binned <-
    binner::categoriseFromWoE.Wide(
      df = loansTest,
      varName = bestBins$variable[index],
      woeTable = bestBins$WoE[[index]]
    )

  predictionCategories <- cbind(predictionCategories, binned)
}

dim(predictionCategories)
```


```{r 05-03-test-matrix-select-variables}
# Retain only the relevant scorecard categories
predictionMatrix <-
  predictionCategories[, !is.na(match(
    names(predictionCategories),
    str_remove_all(GLMCoefficients$variableName, "\`")
  ))] %>%
  as.matrix()
```


```{r 05-03-test-matrix-add-1-col}
predictionMatrix <- cbind(as.vector(rep.int(x = 1, times = dim(predictionMatrix)[1])), predictionMatrix)
dim(predictionMatrix)
```


```{r 05-03-test-matrix}
TestLogit <- predictionMatrix %*% CoefficientsVector
TestLogit <-
  tibble::enframe(TestLogit[, 1]) %>%
  mutate(
    p = 1 / (1 + exp(-value)),
    oddsGood = if_else(is.infinite(p / (1 - p)), 1e10, p / (1 - p)))

predictionScorecard <- predictionMatrix %*% ( GLMScores$points %>% as.matrix() ) 
```

```{r 05-03-test-estimates}
loansTest %>%
  cbind(TestLogit) %>%
  cbind(predictionScorecard) %>%
  mutate(scoreBand = floor(predictionScorecard / 50) * 50) %>%
  filter(predictionScorecard > 0) %>%
  group_by(scoreBand) %>%
  summarise(Count = n()) %>%
  ggplot(aes(scoreBand, Count)) +
  geom_col(col = "blue")
```


```{r 05-03-test-estimates-median}
median(predictionScorecard)
```

Same downward dynamics as training set


```{r 05-03-test-viz-value}
loansTest %>%
  cbind(TestLogit) %>%
  filter(between(value, -2, 5)) %>% 
  ggplot(aes(value, col = grade)) +
  geom_density(adjust = 2)
```


```{r 05-03-test-viz-p}
loansTest %>%
  cbind(TestLogit) %>%
  ggplot(aes(p, col = grade)) +
  geom_density(adjust = 2) +
  scale_x_log10()
```


```{r 05-03-test-viz-odds}
loansTest %>%
  cbind(TestLogit) %>%
  filter(between(oddsGood, 0.1, 100)) %>% 
  ggplot(aes(oddsGood, col = grade)) +
  geom_density(adjust = 2) + 
  scale_x_log10()
  
```


## Correlation matrix

[TODO]


## ROC Curve

```{r 05-03-test-ROC}
ROCRPrediction <- ROCR::prediction(TestLogit$value, loansTest$isGoodLoan)
ROCRPerformance <- ROCR::performance(ROCRPrediction, "tpr", "fpr")

ROCRPlot <-
  tibble(x = ROCRPerformance@x.values[[1]], y = ROCRPerformance@y.values[[1]])


ROCRPlot %>% ggplot(aes(x, y)) +
  geom_point()
```


```{r 05-03-test-ROC2}
stats::ks.test(x = ROCRPlot$x, y = ROCRPlot$y)
```

```{r}
str(ROCRPerformance)
```


## Bin test set by prediction

```{r}
probEstimates <- if_else(TestLogit$value < 0, 0, TestLogit$value)

summary(probEstimates / (1 + probEstimates))
```

