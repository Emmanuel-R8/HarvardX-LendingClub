
# Errands and post-mortem

This project took much longer that the MovieLens capstone. Here is a short list of ideas explored, pitfalls, lessons learned, and character-builders. This last section is written in the belief that knowing what does not work is as worthy as what does work.^[Nobody gets a prize for having been incorrect. But nobody gets a prize not knowing where others have been incorrect.] 


## Modeling

One bit of advice I have known of, agreed with, and naturally set aside, was is to build early and small. In other words, deep and wide exploration of the dataset for the sake of it without modeling is wasteful of time and ideas. Modeling early, small and wrong (at least initially) is a better way to keep track of progress, a good sense of the eventual challenges, and suggest fruitful data exploration avenues. More importantly, it is in and by itself of form of exploration of the dataset. It also tends to explore the data wide-and-shallow rather than deep-but-narrow.


Having said that, I did some early exploration of models. Principal Component Analysis, naive Linear Regression, Extreme Boosting and Random Forest were toyed with. No model could be trained on the full set. I therefore came to limit the training set on a random sample of 0.1% (1 thousandth) of the initial full set. 

I then went on a quest to formulate a model suitable for batch training (either simple sequential batches or stochastic) and gradient descent. 

I also considered online training. However, an untested (and possibly completely wrong) intuition was that online methods are not adapted to an unbalanced dataset: the number of defaults/write-offs is low for high quality ratings. However, the dataset is evidently a time series which points to online training. 

Along the way, the main unanswered question remained what to study out of the dataset: focus on a very narrow of variables? enrich it with other sources to study the impact of cyclical economic crises? determine an optimal pricing of each loan? 

Let's look at a couple of those:

## Geographical data

We sourced US zip and FIPS (_Federal Information Processing Standards_) codes, and macroeconomical data for possible geographical statistics. The source code for the data import and reformatting is available in the GitHub repository. 

Macro-economical datasets were sourced from the same website as Microsoft Excel files. They were converted as-is to tab-separated csv files with LibreOffice. Geofred turned out the best data source.

+ Median income per household:
https://geofred.stlouisfed.org/map/?th=pubugn&cc=5&rc=false&im=fractile&sb&lng=-112.41&lat=44.31&zm=4&sl&sv&am=Average&at=Not%20Seasonally%20Adjusted,%20Annual,%20Dollars&sti=2022&fq=Annual&rt=county&un=lin&dt=2017-01-01

+ Per capita personal income: 
https://geofred.stlouisfed.org/map/?th=pubugn&cc=5&rc=false&im=fractile&sb&lng=-112.41&lat=44.31&zm=4&sl&sv&am=Average&at=Not%20Seasonally%20Adjusted,%20Annual,%20Dollars&sti=882&fq=Annual&rt=county&un=lin&dt=2017-01-01

+ Unemployment:
https://geofred.stlouisfed.org/map/?th=rdpu&cc=5&rc=false&im=fractile&sb&lng=-90&lat=40&zm=4&sl&sv&am=Average&at=Not%20Seasonally%20Adjusted,%20Monthly,%20Percent&sti=1224&fq=Monthly&rt=county&un=lin&dt=2019-08-01



Of key interest were indicators of economic stress with the following intuition: if a borrower had a good credit standing, traditional banks would provide cheaper access to credit. In times of financial distress (indicated by higher unemployment, lower GDP growth, income per household, ...), we should see higher volumes of loans, and/or changes in the loan application patterns. 


Given the time available, that data turned out to be too difficult to use:

+ it was incomplete since the reported figures were not available over the entire timespan of the LendingClub dataset;

+ ZIP codes and FIPS location reference change over time, meaning that determining economic indicators for a given loan was no easy to automatise or would have require substantial time-consuming hand-made adjustment.


Lesson learned: data sourcing, cleaning is a full-time job by itself. [@de2018advances], as one of many sources, warned us. And was ignored...



## Stochastic Gradient Descent

### Conclusions

This subsection is a bit detailed. The main final points are however simple: 

  + A more thorough search for exisitng literature and craft would have been time better spent. 
  
  + Throwing more _iron_ should be a last resort after trying to be more clever (or more realistically looking for what actually clever people have done in the past). This report is not intended to be a PhD thesis. 

  + R is not (yet) equipped to take advantage of advances in full program automatic differentiation (and leverage deep learning optimisation library) like Swift ^[https://blog.tensorflow.org/2019/06/fastais-deep-learning-from-foundations_28.html] and Julia  ^[https://fluxml.ai/Zygote.jl/latest/] are. R has the `Madness` package and can also interface with Julia. But that was another rabbit hole that was too dark from the outset.

  + On the positive side, calculating the derivative of the multimodal NPV function was checked with Maxima symbolic math capabilities and was an opportunity to re-acquaint ourselves with it.


__Here is what was written at the time of exploring SGD.__

  
The early exploration of stochastic gradient as the only way to tackle extremely large dataset was decided on the basis of this diagram: \@ref(fig:scikit-map)^[Source: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html]. It is otherwise extremely valuable, but we should realised much earlier that financial institutions have beeen dealing with such datasets for decades, at times when computing capacity was a orders of magnitude lower than now. If they could do it then, exploring how they did it should have been done first. 


```{r scikit-map, fig.cap="Scikit Learn algorithm cheat-sheet",output.width="70%",cache=FALSE}
knitr::include_graphics("images/scikit-learn-mlmap.png", auto_pdf = TRUE)
```


### Gradient descent

Gradient descent is a generic numerical optimisation algorithm to iteratively converge towards a (sometimes local) minumum of a given function. It is extensively used in statistical learning to minimise error functions.  

In the case of a simple linear regression model, the model training error $J$ (the _cost function_) as a function of $\theta$ is:

$$J_{(\theta)} = \frac{1}{2} \sum_{i=1}^{N}{\epsilon(y_i, \theta X_i)}$$
where the model parameters are denoted $\theta_i$, $X_i \in \mathbb{R^n}$ are the predictors, $Y_i \in \mathbb{R^n}$ are the responses and $\epsilon$ is a distance function. Typically, $\epsilon$ will be the Manhattan error or the Euclidian norm ($A = (a_1, \cdots , a_n), B = (b_1, \cdots , b_n)$).

**Manhattan**: $\epsilon(A, B) = \sum_{i=1}^n|a_i - b_i|$)$

**Euclidian norm**: $\epsilon(A, B) = \sqrt{\sum_{i=1}^n \left( a_i - b_i \right) ^2}$

The gradient descent algorithm uses the gradient of the error function, $\nabla J_{(\theta)}$, defined as:

$$
\nabla J_{(\theta)} = \left( \frac{\partial J}{\partial \theta_{0}},\frac{\partial J}{\partial \theta_{1}}, \cdots, \frac{\partial J}{\partial \theta_{p}} \right)
$$

And in the case of linear regression is in a matrix form that can be computed efficiently:

$$
\nabla J_{(\theta)} =  \left( y^{T} - \theta X^{T} \right) X
$$

The gradient decent algorithm finds parameters in the following manner iterating over the training samples:

While $|| \alpha \nabla J_{(\theta)} || > \eta$, $\theta :=  \theta - \alpha \nabla J_{(\theta)}$

In practice, the cost function will add a penalty term to regularise the model parameters (see below).



### Stochastic Gradient Descent

With realistic datasets, gradient descent can experience slow convergence because (1) each iteration requires calculation of the gradient for every single training example, and (2) since each individual sample is potentially very different from another, the calculated gradient may not be optimal. In such case, the gradient descent can be done using a batch of several training samples and use the average of the cost function (__batch gradient descent__). This addresses those two sources of inefficiency.

This method however still requires iterating over the entire dataset. We can instead iterate over batched of random training samples drawn from the entire dataset, instead of being drawn sequentially. This is the _stochastic gradient descent_.

Aside from the choice of the initial choice of samples, and the averaging of the cost function, the update of $\theta$ remains identical.


### Cost function for multi-modal NPV

Cost function as a function of the $Q$ parameter (equivalent to scorecard).

Looking back at the distribution of the NPV between the -1 and about 1.5, it is multimodal and looks like the sum of 4 log-normal distributions with modes centered on about  


$$
PDF(x) = \frac{1}{x \sigma \sqrt{2 \pi}} exp{\left( -\frac{1}2 \left( \frac{ \log(x) - \mu }{\sigma} \right)^2 \right)}
$$

$$
\text{mode} = m = e^{\mu - \sigma^2} \text{, therefore: } \mu = log(\text{mode}) + \sigma^2
$$

$$
PDF(x) = \sqrt{\frac{e}{2 \pi}} \frac{1}{x \sigma}  exp{\left( -\frac{1}2 \left( \frac{\log(\frac{x}{m}) - \sigma^2}  {\sigma} \right)^2 \right)}
$$

We will center the distribution on the mode, therefore:

$$
PDF(x) = \sqrt{\frac{e}{2 \pi}} \frac{1}{\left( x - m \right) \sigma}  exp{ \left( -\frac{1}2 \left( \frac{\log(\frac{x - m}{m}) - \sigma^2}  {\sigma} \right)^2 \right) }
$$

The distribution's tail is towards positive infinity. For the symmetric result, we would replace $\left( x - m \right)$ by $-\left( x - m \right)$.


If we use 4 log-normal distributions, the cost function is:

$$
\operatorname{J}\left( x,Q\right) =-{{\left[ x-\left( \alpha_1 \operatorname{PDF_1}\left( x,Q\right) + \alpha_2 \operatorname{PDF_2}\left( x,Q\right) + \alpha_2 \operatorname{PDF_3}\left( x,Q\right) + 
\alpha_4 \operatorname{PDF_4}\left( x,Q\right) \right) \right] }^2}
$$

To optimise the shape of the total multi-modal distribution, we will assume that each $\alpha$, $m$ and $\sigma$ is a linear function of $Q$. The derivative 
$\frac{\partial{\operatorname{J}}}{\partial{Q}}$ is^[This was actually generated using Maxima (code in Appendix) which allows for quicker iterations.]:


$$
\begin{array}{ccc}
\frac{\partial{\operatorname{J}}}{\partial{Q}} \left(x, Q \right) = - \sqrt{\frac{2}{\pi}} x
& - & \sqrt{\frac{2}{\pi}} \frac{\alpha_1}{\sigma_1 \left(-x+m_1 \right)} {e^{-\frac{1}{2} \left( \frac{ \log{\left( \frac{-x+m_1}{ m_1} \right)} + \sigma_1^2}{\sigma_1} \right) ^2}} \\
& - & \frac{1}{\sqrt{2 \pi}} \frac{\alpha_2}{\sigma_2 \left(-x+m_2 \right)} {e^{-\frac{1}{2} \left( \frac{ \log{\left( \frac{-x+m_2}{ m_2} \right)} + \sigma_2^2}{\sigma_2} \right) ^2}} \\
& - & \sqrt{\frac{2}{\pi}} \frac{\alpha_3}{\sigma_3 \left(-x+m_3 \right)} {e^{-\frac{1}{2} \left( \frac{ \log{\left( \frac{-x+m_3}{ m_3} \right)} + \sigma_3^2}{\sigma_3} \right) ^2}} \\
& - & \sqrt{\frac{2}{\pi}} \frac{\alpha_4}{\sigma_4 \left( x-m_4 \right)} {e^{-\frac{1}{2} \left( \frac{ \log{\left( \frac{ x-m_4}{ m_4} \right)} + \sigma_4^2}{\sigma_4} \right) ^2}}
\end{array}
$$



We then worked on the basis of code developed for the _Movielens_ capston ^[See https://github.com/Emmanuel-R8/https://github.com/Emmanuel-R8/HarvardX-Movielens].


## Final final Conclusion

We only received 999 cuts. We survived...


