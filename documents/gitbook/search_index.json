[
["introduction.html", "LendingClub Loans Pricing HarvardX - PH125.9x Data Science Capstone Introduction", " LendingClub Loans Pricing HarvardX - PH125.9x Data Science Capstone Emmanuel Rialland - https://github.com/Emmanuel_R8 December 04, 2019 Introduction Lending Club (LC) is an American company listed on the New York stock exchange that provides a platform for peer-to-peer lending. Unlike banks, it does not take deposits and invest them. It is purely a matching system. Each loan is split into $25 that multiple investors can invest in. LC is remunerated by fees received from both sides. LC states that they have intermediated more than $50bln since they started operations. Further description of the company is easily available online numerous sources. In order for investors to make the best investment decisions, LC make a historical dataset publicly available to all registered investors. This dataset is the subject of this report. It was downloaded from the Kaggle data science website1. The size of the dataset is rich enough that it could be used to answer many different questions. We decided for a focused approach. Following Chapter 5 of (Peng 2012), we will first formulate the question we want to answer to guide our analysis. The business model of LC is to match borrowers and investors. Naturally, more people want to receive money than part with it. An important limiting factor to LC’s growth is the ability to attract investors, build a trusting relationship where, as a minimum first step, investors trust LC to provide accurate, transparent and reliable information of the borrowers. For this purpose, LC decided not only to provide extensive information about potential borrowers’ profile, but also historical information about past borrowers’ performance. This is, as we understand, one of the key purposes of this dataset. We decided to use the dataset for this very purpose. Essentially, the questions are: given a borrower profile, is his/her rating appropriate in terms of risk of default? And if a default occurs, what is the expected recovery? The summary question is: given a borrower profile, is the risk/reward balance appropriate to commit funds? In answering this question, we understand that LC allows investment of very granular amounts. Therefore, even an individual investor can diversify his/her loan and risk portfolio. It is not necessary to ‘gamble’ funds on a single borrower. This is exactly what institutional investors achieve through syndication (although on a very different scale, typically $10-25mln for a medium-size bank). For this exercise, we made two simplifying (hopefully not simplistic) assumptions: In determining the risk/return balance, we have not accounted for LC’s cost of intermediation. By ignoring fees paid by both sides, we obviously overestimate the returns to the investors. But in first approximation, we will assume that the risk/reward balance, from the investors’ point of view, across ratings is independent from fees. This is a simplification. Real-world fees are higher the lower the investment grade and push the investors to receive, and the borrowers to pay, higher interest margin. All-in interest rates paid by borrowers are fixed. This is highly desirable for borrowers to be able to manage their cashflow. However, an investor should always consider an investment return as a margin above a risk-free return. Banks would look at LIBOR; bond investors (e.g. life insurers) would look at government bonds. Those risk-free rates can change very quickly, whereas we understand that LC sets those rates on a less frequent basis. In other word, the risk premium will vary rapidly. We assume that individual investors are ‘in-elastic’ to change in implied risk premia. But we recognise this as a limitation of our work. This report is organised as follows: [XXXX] References "],
["internal-rate-of-return-credit-margins-and-net-present-values.html", "Chapter 1 Internal Rate of Return, Credit Margins and Net Present Values 1.1 Important warning 1.2 Background 1.3 Internal Rate of Return 1.4 Dataset calculation", " Chapter 1 Internal Rate of Return, Credit Margins and Net Present Values In this section, we describe the response variables that we will generate for each loan and that will be used in the rest of this report. As indicated in the introduction, our purpose is to test a model that predicts the financial risk of a loan. 1.1 Important warning The calculations presented here are simplistic, although they bear some resemblance to what financial institutions (FIs) do. The literature on credit assessment and pricing is very rich and very complex. Finding the optimal capital allocation to particular risks while at the same time satisfying internal risk policies and regulatory requirements is a problem that financial institutions have yet to solve in full. Investing in a loan is not only a matter of assessing the risk of a particular borrower, but also assessing systemic risks (which exist across all borrowers), risks associated with funding the loan (interest, currency and liquidity markets), each requiring a risk assessment and pricing. In other words, nobody would, let alone should, make any investment decision based on the calculations below. 1.2 Background This subsection can be skipped by anybody with basic financial knowledge. A bird in hand or two in the bush; a penny today or a pound tomorrow. What is the price of delaying obtaining and owning something? This is what pricing a loan is about. A lender could keep his/her cash in hand, or lend it and have it in hand later. He/she would accept this in exchange for receiving a bit more: this is the rate of interest. A lender wants to be compensated for delaying the possibility of using the cash, but also for taking the risk of not receiving it, partially or in full, when repayment is due. There are borrowers that one can see as (almost) completely safe or risk-free such as central banks or governments of strong economies. A lender always has the possibility to lend to them instead of more risky borrowers. Therefore, a lender would require a higher interest rate than risk-free. The additional interest that a lender requires is commensurate with the risk of the borrower not repaying (called credit worthiness) and is called the credit margin. For each individual borrower, an FI would assess information provided by the borrower and massive amounts of historical data to answer the question: considering historical borrowers with a profile similar to the applicant’s, what is the probability of not getting principal and interest back (Probability of Default or PD)? And, in case the borrower stops paying and using additional courses of action (such as seizing and selling assets), what is the total loss that could be expected on average (Loss given Default or LGD)? Making that assessment, the FI would require an interest rate which would roughly be the sum of: the risk-free rate; a margin to cover the average loss of similar individual borrowers2; a margin to cover all the operational costs of running their operations; and, a margin to remunerate the capital allocated by the FI (banking regulations require all banks to allocate an amount of capital against any risk taken; those are stipulated in a number of complex rules). Said crudely, this total is the amount for the FI to get out of bed and look at a loan. Although this sounds like an exact science (for some definition of the word), it is not. At the end of the day, the FI will also have to contend with the competition from other FIs or non banking lenders, market liquidity (if there is a lot of money available to be lent, it brings prices down) and, critically, whether the borrower would at all be interested in accepting that cost. Note that the dataset is distorted by this additional survival effect: the application information of many loans does not appear merely because the rate of interest was considered too high (this is not dissimilar to survival effects where some data did not survive through the history of a dataset3). 1.3 Internal Rate of Return For the purpose of this report, we will simplify things enormously: we will only consider the first two components of the interest rate. The risk-free rate and the credit margin that would cover the cost of default/losses of individual borrowers. The modeling exercise will focus on trying to approximate on average the credit margin given the information provided by the borrower. With respect to a given loan and its cash flow, two calculations are important here: the Net Present Value (NPV) and the Internal Rate of Return (IRR). If we remember that an FI is indifferent to holding a principal \\(P\\) today or receiving it with an annual interest a year later (i.e. \\(P \\times (1 + r)\\) where \\(r\\) is the annual rate of interest), we can say that any amount \\(CF_1\\) received in a year is equivalent to \\(CF_0 = \\frac{CF_1}{1 + r}\\) today. More generally, a steam of future cash receipts is worth: \\[NPV(r) = \\sum_{Year \\space i = 1}^{Year = n}\\frac{CF_i}{(1 + r)^i}\\] The amount \\(NPV(r)\\) is called the Net Present Value of the cash flow discounted at the rate \\(r\\). Given that the LendingClub repayments are monthly, the formula becomes: \\[NPV(r) = \\sum_{Month \\space i = 1}^{Month = 12 \\times n}\\frac{CF_i}{(1 + \\frac{r}{12})^i}\\] If we now have a day 1 cash flow \\(CF_0\\), we can calculate: \\[CF_0 - \\sum_{Year \\space i = 1}^{Year = n}\\frac{CF_i}{(1 + r)^i}\\] However, for any given \\(CF_0\\), there is no reason that it would equal the NPV of the future cash flow (i.e no reason why the difference would be equal to zero). But this is an equation depending on \\(r\\). If we can find a value of \\(r\\) that zeroes this formula, it is called the internal rate of return of the cash flow: \\[CF_0 - \\sum_{Year \\space i = 1}^{Year = n}\\frac{CF_i}{(1 + IRR(CF))^i} = 0\\] or for monthly cash flow: \\[CF_0 - \\sum_{Month \\space i = 1}^{Month = 12 \\times n}\\frac{CF_i}{(1 + \\frac{IRR(r)}{12})^i} = 0\\] 1.4 Dataset calculation For each loan. we calculated the IRR, credit margin and NPV. The calculations were performed in Julia due to R’s slow performance on such a large dataset. For this reason, the resulting datasets are available on the GitHub repository as gzipped CSV files. 1.4.1 IRR We used the dataset to calculate the IRR of each loan. We used the following information for the dataset: funded_amnt(loan amount funded), int_rate (all-in interest rate), term (tenor of the loan in months), total_pymnt (total cumulative amount received from the borrower), total_rec_prncp (amount repaid allocated to principal repayment), total_rec_int (amount repaid allocated to interest payment), recoveries (any amount recovered later from the borrower) and total_rec_late_fee (any late payments fees paid by the borrower). From that information, we recreated a cash flow for each loan. The R code is presented in appendix. Unfortunately, this code takes close to a full day to run on the entire dataset of completed loans (i.e. excluding all ongoing loans). This is just impractical for anybody to run to check this report and the resulting IRR results dataset is included in the Github repository. To make things practical, the dataset was actually created using code in Julia4. It is a direct translation of the R code, with a similar syntax (therefore very easy to follow). The Julia code runs about 500 times quicker (this is not a typo), or about 3 minutes. We appreciate that this is the departure from the assignment description. Similarly, we calculate the credit margin required by each loan noting that: \\[ \\text{Risk-free} + \\text{Credit Margin} = IRR(loan)\\] 1.4.2 Credit Margins As noted in the previous section, risk-free rates change over time. When solving for the credit margin, we use the relevant risk-free rate. Again, this was coded in Julia. The Julia code here takes about 1h20min to run. On the assumptions that the equivalent R code would take therefore almost 30 days to run through the full dataset, we did not write any R code for this calculation. The code is in appendix, and we believe easy to follow. 1.4.3 NPV We also calculated the NPV of each loan. Again, this was coded in Julia. The code is in appendix. We calculate both the NPV as an absolute dollar amount and as a portion of the original It is important to realise that the average margin only brings the borrower back to having earned the risk-free rate average: the additional income from the credit margin will be spent to cover average losses. In addition, we present the credit margin as income against borrower-specific losses. It does not address a lot of other risks such as correlation risks: a borrower might default because the economy as a whole gets worse, in which case many borrowers will default. This is a cyclical systemic risk similar to the 2007 US real estate crisis.↩ A well-known example is historical stock prices which disappear when companies are de-listed or go bankrupt.↩ https://julialang.org/↩ "],
["dataset.html", "Chapter 2 Dataset 2.1 Preamble 2.2 General presentation 2.3 Rates 2.4 Net present value 2.5 Variables 2.6 Loan decision 2.7 Payment-related information", " Chapter 2 Dataset The data is sourced as a SQLite database that downloaded from (Preparation: Wendy Kan 2019) and imported as a tibble dataframe with the RSQLite package. The variables were reformatted according to their respective types. [We also sourced US zip and FIPS codes, and macroeconomical data for possible geographical statistics. The source code for the data import and reformatting is given in appendix.] 2.1 Preamble The LendingClub dataset, although rich, is difficult to interpret. The only explanation of what the variables mean comes from a spreadsheet attached to the dataset. The explanations are not precise and/or subject to conflicting interpretation. Despite serching the LendingClub website, no further original information was found. We collected a number of reasonable assumptions in Appendix (see (List of Assumptions)[list-assumptions]). The dataset has been used a number of times in the past by various people. One paper (Kim and Cho 2019) mentions they used a dataset that included 110 variables, which is less than ours with 145 variables. The dataset has changed over time in ways we do not know. For example, have loans been excluded because the full 145 veriables were not available? 2.2 General presentation The original dataset is large: it includes 2260668 loan samples, each containing 145 variables (after the identification variables filled with null values). The loans were issued from 2007-06-01 to 2018-12-01. 2.2.1 Business volume The dataset represents a total of ca.$34bln in loan principals, which is a substantial share of the total amount stated to have been intermediated to date by LC (publicly reported to be $50bln+). About 55%/60% of the portfolio is fully repaid. See Table ??. Figure ?? plots the number, volume (cumulative principal amount) and average principal per loan. It shows that the business grew exponentially (in the common sense of the word) from inception until 2016. At this point, according to Wikipedia:5 Figure 2.1: Business volume written per month &quot; Like other peer-to-peer lenders including Prosper, Sofi and Khutzpa.com, LendingClub experienced increasing difficulty attracting investors during early 2016. This led the firm to increase the interest rate it charges borrowers on three occasions during the first months of the year. The increase in interest rates and concerns over the impact of the slowing United States economy caused a large drop in LendingClub’s share price.&quot; The number and volume of loans plotted have been aggregated by month. The growth is very smooth in the early years, and suddenly very volatile. As far as the first part of the dataset is concerned, a starting business could expect to be volatile and could witness a yearly cycle (expected from economic consumption figures) superimposed on the growth trend. This is not the case. An interesting metric is that the average principal of loans has increased (see RHS Figure ??, on a sample of 100,000 loans). Partly, the increase in the early years could be interpreted success in improving marketing, distribution capabilities and confidence building. This metric plateau-ed in 2016 and decreased afterwards, but to a much lesser extent than the gross volume metrics. However, it is more volatile than the two previous metrics in the early years. By the end of the dataset, those metrics have essentially recovered to their 2016 level. 2.2.2 Loan lifecyle and status In the dataset, less loans are still outstanding than matured or “charged off” (term that LC use to mean partially or fully written off, i.e. there are no possibilty for LC and/or the investors to receive further payments). The share of outstanding loans is: ## Share of current loans = 42.214 % The dataset describes the life cycle of a loan. In the typical (ideal) case, we understand it to be: \\[ \\text{Loan is approved} \\rightarrow \\text{Full amount funded by investors} \\rightarrow \\text{Loan marked as Current} \\rightarrow \\text{Fully Paid} \\] In the worst case, it is: \\[ \\text{Loan is approved} \\rightarrow \\text{Full amount funded by investors} \\rightarrow \\text{Loan marked as Current} \\rightarrow \\] \\[ \\rightarrow \\text{Grace period (missed payments under 2 weeks)} \\rightarrow \\text{Late 15 to 31 days} \\rightarrow \\] \\[ \\rightarrow \\text{Late 31 to 120 days} \\rightarrow \\text{Default} \\rightarrow \\text{Charged Off} \\] Note that Default precedes and is distinct from Charged Off.6 A couple of things could happen to a loan in default: LC and the borrower restructure the loan with a new repayment schedule, where the borrower may repay a lesser amount over a longer period; or, the claim could be sold to a debt recovery company that would buy the claim from LC/investors. This would be the final payment (if any) received by LC and the investors. The dataset also describes situations where a borrower negotiated a restructuring of the repayment schedule in case of unexpected hardship (e.g. disaster, sudden unemployment). Note that this progression of distinguishing default (event in time) from actual financial loss mirrors what banks and rating agencies do. The former is called the Probability of Default (PD), the latter Loss Given Default (LGD). Ratings change over time (in a process resembling Markov Chains). LGD show some correlations with ratings. The dataset, although detailed, does not include the full life of each loan to conduct this sort of analysis (change of loan quality over time). This is an important reason why we decided to focus on the loan approval and expected return. CHANGE: Debt-Settlement companies7 that explains that debt settlement companies can step in, buy the debt and pay to LC. CHANGE: What is the difference between a loan that is in “default” and a loan that has been “charged off”?8 2.2.3 Loan application Before a loan is approved, the borrower undergoes a review process that assess his/her capacity to repay. This includes: employment situation and income, as well whether this income and possibly its source has been independently verified; whether the application is made jointly (likely with a partner or a spouse, but there are no details); housing situation (owner, owner with current mortgage, rental) and in which county he/she lives (that piece of information is partially anonymised by removing the last 2 digits of the borrower’s zipcode); the amount sought, its tenor and the purpose of the loan; and, what seems to be previous credit history (number of previous deliquencies). The dataset is very confusing in that regard: it is clear that such information relates to before the loan is approved in the case of the joint applicant. In the case of the principal borrower however, the variable descriptions could be read as pre-approval information, or information gathered during the life of the loan. We have assumed that the information related to the principal borrower is also pre-approval. We also used Sales Supplements from the LC website9 that describe some of the information provided to investors. LendingClub also provides a summary description of its approval process in its regulatory filings with the Securities Exchange Commission (San Francisco - California 2019). 2.3 Rates 2.3.1 IRR and required credit margins Figure ?? shows the evolution of credit margins over time grouped by ratings. The plots are made with a random sample of 300,000 loans. Figure 2.2: Credit margins per grade over time We notice long periods where certain margins remain very stable which indicate that both the initial pricing was constant and that the proportion of default remains very low. The graphs show considerations that are relevant to the modeling&quot;: The margins clearly change over time. Predictions will require to account for time [probably in a non-linear fashion]. For a given rating, it widens and narrows over time. The changes happen in multiples that depends on the ratings: For high quality / low margin loans: the changes are multiples of the margin, for example going from roughly 3% to 6/7%. Although the range of change is wide, those changes do not happen very often, especially in the later years. By comparison, for low quality / high margin loans, the range of change is smaller, but more frequent and volatile. In other words, the relation between loan quality (its rating) and its pricing (the credit margin) will significantly non-linear. Figure 2.3: Credit margins per grade over time Figure 2.4: Credit margins per grade over time 2.3.2 Dataset Because we are interested decisions made prior to invest, we will limit the predictors to be used to those that are realistically available prior to funding. We eliminated 2.3.3 Interest rates Based on this information, the loan is approved or not. Approval includes the final amount (which could be lower than the amount requested), tenor (3 or 5 years) and a rating similar to those given to corporate borrowers. Unlike corporate borrowers however, the rating mechanically determines the rate of interest according to a grid known to the borrower in advance10. The rates have changed over time. Those changes where not as frequent as market conditions (e.g. changes in Federal Reserve Bank’s rates)11. Figure ??12 shows the predetermined interest rate depending on the initial rating as of July 2019. Figure 2.5: Interest rates given rating At the date of this report, the ratings range from A (the best) down to D, each split in 5 sub-ratings. However, LC previously also intermediated loans rated F or G (until 6 November 2017) and E (until 30 June 2019).13 This explains that such ratings are in the dataset. We will assume that the ratings in the dataset are the rating at the time of approval and that, even if loans are re-rated by LC, the dataset does not reflect it. Figures ?? shows the change in interest rate over time for different ratings and separated for each tenor. (Each figure is on a sample of 100,000 loans.) For each rating, we can see several parallel lines which correspond to the 5 sub-rating of each rating. We note that the range of interest rates has substantial widened over time. That is, the risk premium necessary to attract potential investors has had to substantially increase. In the most recent years, the highest rates exceed 30% which is higher than many credit cards.3-year loans are naturally considered safer (more A-rated, less G-rated). Identical ratings attract identical rates of interest. Figure 2.6: Interest rate per grade over time By comparison, we plot the 3-year (in red) and 5-year (in blue) bank swap rates in Figure ??. We see that the swap curve has flattened in recent times (3-year and 5-y rates are almost identical). We also can see that in broad terms the interest rates charged reflect those underlying swap rates. It is therefore most relevant to examine the credit margins added to the swap rates. Figure 2.7: Historical Swap Rates Figures ?? shows the change in credit margin over time for different ratings and separated for each tenor. (Each figure is on a sample of 100,000 loans.) As above, for each rating, we can see several parallel lines which correspond to the 5 sub-rating of each rating. We note that the range of credit margins has widened over time but less than the interest rates. Identical ratings attract identical credit margins. Figure 2.8: Credit margins per grade over time 2.3.4 Purpose When applying, a potential borrower must state the purpose of the loan. As shown in table ??, the main purpose is the consolidation of existing debts. ## # A tibble: 14 x 2 ## purpose Number ## &lt;fct&gt; &lt;int&gt; ## 1 debt_consolidation 758691 ## 2 credit_card 286044 ## 3 home_improvement 84709 ## 4 other 75358 ## 5 major_purchase 28451 ## 6 small_business 15171 ## 7 medical 15081 ## 8 car 14184 ## 9 moving 9218 ## 10 vacation 8751 ## 11 house 7011 ## 12 wedding 2350 ## 13 renewable_energy 914 ## 14 educational 423 Figure 2.9: Histograms of credit margins per purpose Figure 2.10: Boxplots of credit margins per purpose [TODO: DTI, amount… by grade] 2.3.5 Payments The loans are approved for only two tenors, 3 and 5 years, with monthly repayments. Installments are calculated easily with the standard formula: \\[ Installment = Principal \\times rate \\times \\frac{1}{1 - \\frac{1}{(1+rate)^N}} \\] Where \\(Principal\\) is the amount borrowed, \\(rate = \\frac{\\text{Quoted Interest Rate}}{12}\\) is the monthly interest rate, and \\(N\\) is the number of installments (36 or 60 monthly payments). The following piece of code shows that the average error between this formula and the dataset value is about 2 cents. We therefore precisely understand this variable. local({ installmentError &lt;- loans %&gt;% mutate( PMT = round(funded_amnt * int_rate / 12 / (1 - 1 / (1 + int_rate / 12) ^ term), 2), PMT_delta = abs(installment - PMT) ) %&gt;% select(PMT_delta) round(mean(100 * installmentError$PMT_delta), digits = 2) }) 2.4 Net present value The behaviour of the NPV of loan losses is important. 2.4.1 Average NPV and credit margin by subgrade Figure ?? shows that as ratings worsen, the average NPV14 expressed as a portion of the funded amount decreases. For the best quality loans, we see that the NPV exceeds 1.00 = 100%: at a risk-free rate, investors receive more than what is necessary to compensate for credit loss and can use the excess to cover additional costs mentioned in the Preamble. As ratings worsen, the NPV drops down to about 50%. If loans were adequately priced, the excess returns (thanks to higher interest) should on average offset credit losses, that is an NPV average should be at least 100%. This seems to be the case down to ratings of about D4. Further down, credit losses become too frequent and/or too substantial to be covered on average. We posit that this justified rejecting loans applications rated E1 and below. Figure 2.11: Average NPV et credit margin (%) depending on sub-rating 2.4.2 Principal losses 2.4.3 Distribution of principal losses by rating Figure ?? shows that for a given grade, the losses are very widely spread. The loans are group by ratings and loans that have been fully repaid are removed. Setting aside the loans rated “A” or “B”, the distributions seem log-normal. Unsurprisingly, the worse the rating the larger the principal loss. Figure 2.12: Distribution of NPV (%) depending on rating (y-axis square-root scaling) 2.4.4 NPV distribution by rating Principal loss does not reflect the timing of that loss: a loss now is worse than a loss later. This subsection looks at the NPVs of actual loan cashflow (principal and interest) discounted the risk-free rate. Figure ?? shows that for a given grade, the NPVs are very widely spread. From top to bottom, loans are group by ratings: from quality ratings of A and B, average ratings of C and D, to poor ratings of E and below. From left to right, we focus on different parts of how NPVs are distributed. Note that each graph is based on a random sample of 100,000 loans (about 1/12th of the original set) and therefore the NPV densities are comparable from graph to graph. Figure 2.13: Distribution of NPV (%) depending on rating (y-axis square-root scaling) At the outset, column by column (where NPVs are on the same scale), the NPV distribution show several modes on the same location. The modes are made more apparent by zooming on where the modes are present: the leftmost column basically shows the entire range of the NPVs (as portion of the loan). The middle graph zooms on the -20% / 50% range. The rightmost column zooms on the -100% / -25% section. Looking at the left hand scale, we can see that the lower NPVs overall gain in importance as the loan rating worsen. Zooming without scaling the y-axis and grouping all the ratings available for investment on a single plot gives more details. Figure ?? shows a mode with a maximum around 1.25 / 1.5 being loans seemingly repaid in full (the mode is above 100% given the repayment of principal and interest); Figure 2.14: NPV % over 120% (no y-axis scaling) Figure ?? and figure ?? show a second and third mode around 41% and -1%; Figure 2.15: NPV % around 41% (no y-axis scaling) Figure 2.16: NPV % around -1% (no y-axis scaling) Finally, figure ?? one last very diffuse mode around -100%. Figure 2.17: NPV % for close to total loss % (no y-axis scaling) The overall trend is what we should expect. What is surprising is the existence of (1) very clearly defined modes which (2) are common to all types of borrowers. They roughly look log-normal, apart from the mode around 41% which look Gaussian. 2.5 Variables We here present other aspects of the dataset. The full list of variable is given in appendix (see Table ??). This dataset will be reduced as we focused on our core question: Are LC’s loans priced appropriately?. 2.5.1 Identification The dataset is anonymised (all identifying ID numbers are deleted) and we therefore removed those columns from the dataset. Since the identification IDs have been removed to anonymise the dataset, we cannot see if a borrower borrowed several times. 2.6 Loan decision As indicated in the introduction, our focus is on loans that have gone through their entire life cycle to consider their respective pricing, risk and profitability. To that effect, we will remove all loans which are still current (either performing or not), and we will only retain loans which currently available (rated A1 to D5). Another reason for limiting ourselves to this subset is that the previous subsection graphing NPVs strongly suggests that the lowest quality loans were very underpriced yielding average losses. From here on, everything will be based on this reduced dataset. In this reduced dataset, we focus on loans that have matured or been terminated. It contains 1306356 samples. Most of the loans (ca.80%) have been repaid in full. See Table ??. When grouped by grade (Figure ??), we see a clear correlation between grade and default: the lower the grade the higher the portion defaults (note the limited scale with a minimum at about 50%). In addition, most of the business is written in the B- or C-rating range. Figure 2.18: Funding and Write-offs by Sub-grades 2.7 Payment-related information As mentioned previously, the descriptions of the dataset variables is at times incomplete or confusing. For the purpose of determining the cash flow of each individual loans, we have attempted to reconstruct the variables. We have verfied that: installments are calculated as per the formula shown above, rounded to the next cent. total_pymnt = total_rec_prncp + total_rec_int + total_rec_late_fee + recoveries References "],
["logistic-regression-model-and-credit-scorecard.html", "Chapter 3 Logistic Regression Model and Credit Scorecard 3.1 Introduction 3.2 Logistic Regression 3.3 Binning and Weight of Evidence 3.4 Logistic Regression 3.5 Model result 3.6 Training set 3.7 Test set 3.8 Correlation matrix 3.9 ROC Curve 3.10 Bin test set by prediction", " Chapter 3 Logistic Regression Model and Credit Scorecard At the outset, the dataset presents a number of challenges: There is a mix of continuous and categorical data. The number of observations is very large. The possible number of predictors is large (partially due to one-hot encoding of categorical values). As shown in the previous section, credit margins have changed over time. This is clearly related to the wider US economic environment. Financial hardship is a key driver for some of the loans. Availability of disposable income is important to assess the ability to repay. Therefore, the cost of living, which varies from state to state, seems relevant. [TODO: Bias/Complexity trade-off] [TODO: AoC? or AuC?] 3.1 Introduction 3.1.1 Split The dataset was randomly split into training and validation sets (80/20 ratio). We initiated the exploration of potential models with Principal Component Analysis, Linear Regression, Extreme Boosting and Random Forest. No model could be trained on the full set. We therefore came to limit the training set on a random sample of 0.1% (1 thousandth) of the initial full set. Any model will require training in batch (e.g. stochastic gradient descent) or online. Our untested intuition is that online methods are not adapted to an unbalanced dataset: the number of defaults/write-offs is fairly low for high quality ratings. However, the dataset is evidently a time series which points to online training. We will not explore that line of investigation, although exploring that tension would be an interesting subject. 3.1.2 The modeling task Two step process: - Given dataset (+/- rating?) find a score between -5 and +5 - Given a score between -5 and +5 given the right parameters for the modes - Given a density curve extrapolate the required margin Make money or not? 3.2 Logistic Regression Logistic models (also called logit model) are used to model binary events. Examples would be passing or failing an exam, a newborn being a boy or a girl, a voter choosing a particular political party, or – relevant to us – a borrower defaulting or not on a loan. If the binary variable is modeled as a 0/1 outcome, the model will yield a value between 0 and 1 which can be used as a probabilty. We are interested in using a number of variables (being continuous and/or categorical) to model the binary response. A natural model is a linear combination of the variables. Since the predicted value would be continuous and not be bounded by 0/1, the outcome is transformed. A commonly used transformation of the logodds (logarithm of the odds given a particular probability) \\(\\log \\left( \\frac{p}{1 - p} \\right)\\). This expression has a few advantages: it converts any value (between \\(- \\infty\\) and \\(+\\infty\\) produced by the linear regression), and it is symmetrical around \\(x = 0\\) and \\(y = 1/2\\). That is, using the odds instead of the probability avoids infinity; it behaves identically when p approaches 0 or 1 (this would not be the case using p). The reciprocal of the logodds is \\(p = \\frac{1}{1 - e^{-x}}\\). For a number of \\(X_i\\) variables, the model to fit is then: \\[p = \\frac{1}{1 - e^{-\\sum_i{\\alpha_i X_i}}}\\] The commonly used method to evaluate the creditworthiness of a borrower is to create scorecards whereby particular characteristics are segmented into intervals and attributed discrete scores. In plain English, a continuous variable (say the age of the applicant) is segmented into intervals (e.g. 0-18 year-olds, 18-26 year-olds,…), and then given a score. Those different segments become categorical variables. The task of the model is to: identify the best way to segment a continuous variable to maximise the information value of the different segments (called bins): intuitively empty or quasi-empty bins (either no or few applicants in the bin) are not informative; bins for which the response is completely random are not predictive, whereas a bin where the response always has the same response is informative (i.e. anybody with income of 0 and 10 dolars per year will default, anybody with a salary of $1 million per month will repay). use a generalised linear model using the new categorical variables; transforms the linear coefficients estimated for each category into numerical scores. WARNING: To run this model, you will need at least 32GB of memory (real plus virtual/swap space) 3.2.1 Data preparation WARNING: Execute CleanLoad.Rmd first # AFTER EXECUTION OF `CleanLoad.Rmd` # Variables not used rm(lending_club, loans) # select the variables that might be used to create the training+test set modelVarsIn &lt;- c(LC_variable[LC_variable$inModel == TRUE, &quot;variable_name&quot;])$variable_name modelVarsIn &lt;- c(modelVarsIn, &quot;grade_num&quot;, &quot;sub_grade_num&quot;, &quot;principal_loss_pct&quot;, &quot;creditMargin&quot;, &quot;monthDefault&quot;) # Make sure that some variables are NOT in included in the final training set modelVarsOut &lt;- c(&quot;grade_num&quot;, &quot;sub_grade_num&quot;, &quot;principal_loss_pct&quot;, &quot;creditMargin&quot;, &quot;monthDefault&quot;, &quot;zip_code&quot;) ## ############################################################################################### ## ## Prepare a dataset with ONLY the predictors NOT removing NA&#39;s ## loansPredictors &lt;- loansWorkingSet %&gt;% # Keep the chosen predictors # Use tidyselect::one_of() to avoid errors if column does not exist select(tidyselect::one_of(modelVarsIn)) %&gt;% ## ## Dates to numeric, in &#39;decimal&#39; years since 2000 ## mutate_at(c(&quot;issue_d&quot;, &quot;earliest_cr_line&quot;), function(d) { return(year(d) - 2000 + (month(d) - 1) / 12) }) %&gt;% ## Add polynomials of the dates to model the time-trend shape mutate( issue_d2 = issue_d^2, issue_d3 = issue_d^3, earliest_cr_line2 = earliest_cr_line^2, earliest_cr_line3 = earliest_cr_line^3 ) %&gt;% ## Create a logical flag TRUE for non-defaulted (good) loans mutate(isGoodLoan = (principal_loss_pct &lt; 0.001)) %&gt;% select(-tidyselect::one_of(modelVarsOut)) ## ############################################################################################### ## ## Create training / test sets 80%/20% ## proportionTraining &lt;- 0.8 set.seed(42) nSamples &lt;- nrow(loansPredictors) sampleTraining &lt;- sample(1:nSamples, floor(nSamples * proportionTraining), replace = FALSE) loansTraining &lt;- loansPredictors %&gt;% slice(sampleTraining) loansTest &lt;- loansPredictors %&gt;% slice(-sampleTraining) # Subsets of the training set set.seed(42) nSamplesTraining &lt;- nrow(loansTraining) # 1% sample01 &lt;- sample(1:nSamplesTraining, floor(nSamplesTraining * 0.01), replace = FALSE) loans01 &lt;- loansTraining %&gt;% slice(sample01) # 20% sample20 &lt;- sample(1:nSamplesTraining, floor(nSamplesTraining * 0.20), replace = FALSE) loans20 &lt;- loansTraining %&gt;% slice(sample20) # Not used later on rm(loansWorkingSet, loansPredictors, LoansNPV, LoansIRR, LoansMargin, RATES, RATES3Y, RATES5Y) gc(full = TRUE) ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 2831583 151.3 6816128 364.1 6816128 364.1 ## Vcells 250281346 1909.5 1168995629 8918.8 1826494161 13935.1 3.3 Binning and Weight of Evidence This subsection owes a lot influence to the smbinning package source code from which we reimplemented some aspects using the tidyverse style (the original source code uses SQL statements to access dataframes), and the Information package vignette.15 To identify the various bins (and number and location) Let’s say that we have a binary dependent variable Y and a set of predictive variables X1,,Xp. As mentioned above, Y can capture a wide range of outcomes, such as defaulting on a loan, clicking on an ad, or terminating a subscription. WOE and IV play two distinct roles when analyzing data: WOE describes the relationship between a predictive variable and a binary target variable. IV measures the strength of that relationship. # Ensure that `binner` is here and available if (&quot;package:binner&quot; %in% search()) { detach(&quot;package:binner&quot;, unload = TRUE, force = TRUE) } if (!(&quot;binner&quot; %in% installed.packages()[,1])) { devtools::install_local(&quot;~/Development/R/DVPT-PACKAGES/Score_modeling_binning/binner&quot;, force = TRUE, quiet = TRUE) # devtools::install_github(&quot;Emmanuel-R8/SMBinning&quot;) } library(binner) 3.3.1 Loop through all variables loansBinning &lt;- loansTraining %&gt;% mutate( home_ownership = as_factor(home_ownership), emp_length = as_factor(emp_length), grade = as_factor(grade) ) informationValues &lt;- tibble(variable = names(loansBinning), IV = -1.0) listBins &lt;- tibble( variable = &quot;&quot;, type = &quot;&quot;, IV = 0.0, WoE = list(), .rows = 0 ) # About 500 sec wall-time startTime &lt;- proc.time() for (n in informationValues$variable) { cat(&quot;Variable: &quot;, n) # We don&#39;t test the response with itself if (n %in% c(&quot;isGoodLoan&quot;)) { cat(&quot;\\n&quot;) } else { if (class(loansBinning[[1, n]]) == &quot;factor&quot;) { cat(&quot; is a factor, &quot;) result &lt;- WoETableCategorical( df = loansBinning, x = n, y = &quot;isGoodLoan&quot;, maxCategories = 100) } else { cat(&quot; is numeric, &quot;) result &lt;- WoETableContinuous(df = loansBinning, x = n, y = &quot;isGoodLoan&quot;, p = 0.05) } tryCatch({ if (is.na(result)) { cat(&quot;Variable skipped.\\n&quot;) add_row( listBins, variable = n, type = NA, IV = NA ) } else { cat(&quot; IV : &quot;, result$IV, &quot;\\n&quot;) listBins &lt;- listBins %&gt;% add_row( variable = n, type = result$type, IV = result$IV, WoE = list(result$table) ) informationValues[n] &lt;- result$IV } }, finally = {}) } } ## Variable: loanID is numeric, Number of missing/NA values: 0 ## IV : 0.03483779 ## Variable: loan_amnt is numeric, Number of missing/NA values: 0 ## IV : 0.03616236 ## Variable: term is numeric, Number of missing/NA values: 0 ## IV : 0.1732862 ## Variable: int_rate is numeric, Number of missing/NA values: 0 ## IV : 0.4652705 ## Variable: grade is a factor, IV : 0.4601578 ## Variable: sub_grade is a factor, IV : 0.4939204 ## Variable: emp_length is a factor, Variable skipped. ## Variable: home_ownership is a factor, IV : 0.03122319 ## Variable: verification_status is a factor, IV : 0.0568103 ## Variable: issue_d is numeric, Number of missing/NA values: 0 ## IV : 0.04082864 ## Variable: purpose is a factor, IV : 0.0195876 ## Variable: addr_state is a factor, IV : 0.01663099 ## Variable: dti is numeric, Number of missing/NA values: 247 ## IV : 0.07445211 ## Variable: delinq_2yrs is numeric, Number of missing/NA values: 23 ## IV : 0.002442208 ## Variable: earliest_cr_line is numeric, Number of missing/NA values: 23 ## IV : 0.01668446 ## Variable: inq_last_6mths is numeric, Number of missing/NA values: 24 ## IV : 0.02654189 ## Variable: mths_since_last_delinq is numeric, Number of missing/NA values: 527124 ## IV : 0.002617462 ## Variable: mths_since_last_record is numeric, Number of missing/NA values: 866836 ## IV : 0.006109422 ## Variable: open_acc is numeric, Number of missing/NA values: 23 ## IV : 0.004893466 ## Variable: pub_rec is numeric, Number of missing/NA values: 23 ## IV : 0.005781389 ## Variable: revol_bal is numeric, Number of missing/NA values: 0 ## IV : 0.002693195 ## Variable: revol_util is numeric, Number of missing/NA values: 687 ## IV : 0.02549172 ## Variable: total_acc is numeric, Number of missing/NA values: 23 ## IV : 0.001581812 ## Variable: application_type is a factor, IV : 0.001462783 ## Variable: annual_inc_joint is numeric, Variable skipped. ## Variable: dti_joint is numeric, Variable skipped. ## Variable: verification_status_joint is a factor, IV : 0.001828885 ## Variable: acc_now_delinq is numeric, Variable skipped. ## Variable: open_rv_12m is numeric, Number of missing/NA values: 645401 ## IV : 0.02649645 ## Variable: open_rv_24m is numeric, Number of missing/NA values: 645401 ## IV : 0.03337626 ## Variable: max_bal_bc is numeric, Number of missing/NA values: 645401 ## IV : 0.02120239 ## Variable: inq_fi is numeric, Number of missing/NA values: 645401 ## IV : 0.01993185 ## Variable: avg_cur_bal is numeric, Number of missing/NA values: 56032 ## IV : 0.05429846 ## Variable: bc_open_to_buy is numeric, Number of missing/NA values: 51160 ## IV : 0.03048348 ## Variable: bc_util is numeric, Number of missing/NA values: 51160 ## IV : 0.03048348 ## Variable: mo_sin_old_il_acct is numeric, Number of missing/NA values: 85391 ## IV : 0.009095095 ## Variable: mo_sin_old_rev_tl_op is numeric, Number of missing/NA values: 56016 ## IV : 0.02704707 ## Variable: mo_sin_rcnt_rev_tl_op is numeric, Number of missing/NA values: 56016 ## IV : 0.02959229 ## Variable: mo_sin_rcnt_tl is numeric, Number of missing/NA values: 56015 ## IV : 0.03358796 ## Variable: mort_acc is numeric, Number of missing/NA values: 39839 ## IV : 0.04381551 ## Variable: mths_since_recent_bc is numeric, Number of missing/NA values: 49826 ## IV : 0.02727271 ## Variable: mths_since_recent_bc_dlq is numeric, Number of missing/NA values: 797767 ## IV : 0.001486543 ## Variable: mths_since_recent_inq is numeric, Number of missing/NA values: 137406 ## IV : 0.0348828 ## Variable: mths_since_recent_revol_delinq is numeric, Number of missing/NA values: 696281 ## IV : 0.001433636 ## Variable: num_accts_ever_120_pd is numeric, Number of missing/NA values: 56015 ## IV : 0.006819851 ## Variable: num_actv_bc_tl is numeric, Number of missing/NA values: 56015 ## IV : 0.01471619 ## Variable: num_actv_rev_tl is numeric, Number of missing/NA values: 56015 ## IV : 0.03353568 ## Variable: num_bc_sats is numeric, Number of missing/NA values: 46723 ## IV : 0.005841431 ## Variable: num_bc_tl is numeric, Number of missing/NA values: 56015 ## IV : 0.007157188 ## Variable: num_il_tl is numeric, Number of missing/NA values: 56015 ## IV : 0.005147452 ## Variable: num_op_rev_tl is numeric, Number of missing/NA values: 56015 ## IV : 0.01095223 ## Variable: num_rev_accts is numeric, Number of missing/NA values: 56015 ## IV : 0.004930698 ## Variable: num_rev_tl_bal_gt_0 is numeric, Number of missing/NA values: 56015 ## IV : 0.03221086 ## Variable: num_sats is numeric, Number of missing/NA values: 46723 ## IV : 0.008577643 ## Variable: num_tl_120dpd_2m is numeric, Variable skipped. ## Variable: num_tl_30dpd is numeric, Variable skipped. ## Variable: num_tl_90g_dpd_24m is numeric, Number of missing/NA values: 56015 ## IV : 0.005525681 ## Variable: num_tl_op_past_12m is numeric, Number of missing/NA values: 56015 ## IV : 0.04852394 ## Variable: pct_tl_nvr_dlq is numeric, Number of missing/NA values: 56139 ## IV : 0.005569665 ## Variable: percent_bc_gt_75 is numeric, Number of missing/NA values: 50862 ## IV : 0.0325666 ## Variable: pub_rec_bankruptcies is numeric, Number of missing/NA values: 1114 ## IV : 0.003680394 ## Variable: tax_liens is numeric, Variable skipped. ## Variable: tot_hi_cred_lim is numeric, Number of missing/NA values: 56015 ## IV : 0.05002856 ## Variable: total_bal_ex_mort is numeric, Number of missing/NA values: 39839 ## IV : 0.006069149 ## Variable: total_bc_limit is numeric, Number of missing/NA values: 39839 ## IV : 0.04118286 ## Variable: total_il_high_credit_limit is numeric, Variable skipped. ## Variable: revol_bal_joint is numeric, Variable skipped. ## Variable: disbursement_method is a factor, IV : 4.121812e-05 ## Variable: issue_d2 is numeric, Number of missing/NA values: 0 ## IV : 0.04086939 ## Variable: issue_d3 is numeric, Number of missing/NA values: 0 ## IV : 0.04086939 ## Variable: earliest_cr_line2 is numeric, Number of missing/NA values: 23 ## IV : 0.002263311 ## Variable: earliest_cr_line3 is numeric, Number of missing/NA values: 23 ## IV : 0.01460377 ## Variable: isGoodLoan proc.time() - startTime ## user system elapsed ## 435.527 2.884 459.102 saveRDS(informationValues, &quot;datasets/informationValues100.rds&quot;) saveRDS(listBins, &quot;datasets/listBins100.rds&quot;) 3.3.2 Select relevant variables It is considered that information value below 2% is useless. bestBins &lt;- listBins %&gt;% filter(IV &gt;= 0.02) bestBins %&gt;% select(variable, IV) %&gt;% mutate(IV = round(IV, digits = 5)) %&gt;% arrange(desc(IV)) %&gt;% slice(1:10) ## # A tibble: 10 x 2 ## variable IV ## &lt;chr&gt; &lt;dbl&gt; ## 1 sub_grade 0.494 ## 2 int_rate 0.465 ## 3 grade 0.460 ## 4 term 0.173 ## 5 dti 0.0744 ## 6 verification_status 0.0568 ## 7 avg_cur_bal 0.0543 ## 8 tot_hi_cred_lim 0.0500 ## 9 num_tl_op_past_12m 0.0485 ## 10 mort_acc 0.0438 However, we should ignore the variables that would not be available at the time the credit scoring is performed. bestBins &lt;- bestBins %&gt;% filter(!(variable %in% c( &quot;loanID&quot;, &quot;term&quot;, &quot;int_rate&quot;, &quot;creditMargin&quot;, &quot;loan_status&quot;, &quot;grade&quot;, &quot;sub_grade&quot;, &quot;grade_num&quot;, &quot;sub_grade_num&quot;, &quot;emp_length&quot;, &quot;home_ownership&quot;, &quot;monthDefault&quot;, &quot;principal_loss_pct&quot;, &quot;creditMargin&quot;, &quot;monthDefault&quot;, &quot;isGoodLoan&quot;))) saveRDS(bestBins, &quot;datasets/bestBins100.rds&quot;) The 10 best variables that will retain are in the following table. Interestingly, the square and cubic powers of the issue date are retained. bestBins %&gt;% select(variable, IV) %&gt;% mutate(IV = round(IV, digits = 5)) %&gt;% arrange(desc(IV)) %&gt;% slice(1:10) ## # A tibble: 10 x 2 ## variable IV ## &lt;chr&gt; &lt;dbl&gt; ## 1 dti 0.0744 ## 2 verification_status 0.0568 ## 3 avg_cur_bal 0.0543 ## 4 tot_hi_cred_lim 0.0500 ## 5 num_tl_op_past_12m 0.0485 ## 6 mort_acc 0.0438 ## 7 total_bc_limit 0.0412 ## 8 issue_d2 0.0409 ## 9 issue_d3 0.0409 ## 10 issue_d 0.0408 And the 10 worst (but retained) variables are: bestBins %&gt;% select(variable, IV) %&gt;% mutate(IV = round(IV, digits = 5)) %&gt;% arrange(IV) %&gt;% slice(1:10) ## # A tibble: 10 x 2 ## variable IV ## &lt;chr&gt; &lt;dbl&gt; ## 1 max_bal_bc 0.0212 ## 2 revol_util 0.0255 ## 3 open_rv_12m 0.0265 ## 4 inq_last_6mths 0.0265 ## 5 mo_sin_old_rev_tl_op 0.0270 ## 6 mths_since_recent_bc 0.0273 ## 7 mo_sin_rcnt_rev_tl_op 0.0296 ## 8 bc_open_to_buy 0.0305 ## 9 bc_util 0.0305 ## 10 num_rev_tl_bal_gt_0 0.0322 3.3.3 Create data table with only binary variables (transform every bin to a 0/1 value) For each variable, create new variables for each bin in the WoE table of that variable. # Variable will contain all the best characteristics. Every continuous variable is reformatted # into factors reflecting the appropriate bins allFactorsAsCharacteristics &lt;- loansTraining[,&quot;loanID&quot;] allFactorsAsBins &lt;- loansTraining[,&quot;loanID&quot;] for (index in 1:nrow(bestBins)) { #for (index in 1:27) { name &lt;- bestBins$variable[index][[1]] cat(&quot;--------------------&quot;, index, &quot;--&quot;, name, &quot;\\n&quot;) ltIndex &lt;- which(names(loansTraining) == name) characteristic &lt;- categoriseFromWoE(df = loansTraining[, ltIndex], varName = name, woeTable = bestBins$WoE[index][[1]]) bins &lt;- categoriseFromWoE.Wide(df = loansTraining[, ltIndex], varName = name, woeTable = bestBins$WoE[index][[1]]) allFactorsAsCharacteristics &lt;- allFactorsAsCharacteristics %&gt;% cbind(characteristic) allFactorsAsBins &lt;- allFactorsAsBins %&gt;% cbind(bins) } ## -------------------- 1 -- loan_amnt ## -------------------- 2 -- verification_status ## -------------------- 3 -- issue_d ## -------------------- 4 -- dti ## -------------------- 5 -- inq_last_6mths ## -------------------- 6 -- revol_util ## -------------------- 7 -- open_rv_12m ## -------------------- 8 -- open_rv_24m ## -------------------- 9 -- max_bal_bc ## -------------------- 10 -- avg_cur_bal ## -------------------- 11 -- bc_open_to_buy ## -------------------- 12 -- bc_util ## -------------------- 13 -- mo_sin_old_rev_tl_op ## -------------------- 14 -- mo_sin_rcnt_rev_tl_op ## -------------------- 15 -- mo_sin_rcnt_tl ## -------------------- 16 -- mort_acc ## -------------------- 17 -- mths_since_recent_bc ## -------------------- 18 -- mths_since_recent_inq ## -------------------- 19 -- num_actv_rev_tl ## -------------------- 20 -- num_rev_tl_bal_gt_0 ## -------------------- 21 -- num_tl_op_past_12m ## -------------------- 22 -- percent_bc_gt_75 ## -------------------- 23 -- tot_hi_cred_lim ## -------------------- 24 -- total_bc_limit ## -------------------- 25 -- issue_d2 ## -------------------- 26 -- issue_d3 saveRDS(allFactorsAsCharacteristics, &quot;datasets/allCharacteristics100.rds&quot;) ; saveRDS(allFactorsAsBins, &quot;datasets/allBins100.rds&quot;) 3.3.4 Comparison of individual characteristics [TODO] Present data by order of IV Sort WoE buildup for key IV re-train secures the lowest Akaike criterion and will be chosen. On this test, the best variables are: SORT BY IV. Then WoE for the first few ones. loansBinning &lt;- loans20 %&gt;% mutate( home_ownership = as_factor(home_ownership), emp_length = as_factor(emp_length) ) best10 &lt;- bestBins %&gt;% arrange(desc(IV)) %&gt;% slice(1:10) 3.3.4.1 dti plotBinWoE &lt;- function(n = 1) { vName &lt;- best10[n,]$variable if (best10[n,]$type == &quot;numeric&quot;) { best10[n,]$WoE[[1]] %&gt;% arrange(WoE) %&gt;% ggplot(aes(Name, WoE)) + geom_col(col = &quot;blue&quot;, fill = &quot;lightblue&quot;) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle(vName) } else { best10[n,]$WoE[[1]] %&gt;% arrange(WoE) %&gt;% ggplot(aes(Name, WoE)) + geom_col(col = &quot;blue&quot;, fill = &quot;lightblue&quot;) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle(vName) } } plotBinWoE(10) 3.3.4.2 Home ownership resultHome &lt;- WoETable( df = loansBinning, x = &quot;home_ownership&quot;, y = &quot;isGoodLoan&quot;, maxCategories = 20 ) resultHome ## $IV ## [1] 0.03159041 ## ## $type ## [1] &quot;categorical&quot; ## ## $table ## # A tibble: 6 x 19 ## home_ownership Name Count nGood nBad cumCount cumGood cumBad pctCount pctGood pctBad OddsInBin LnOddsInBin WoEInBin IVInBin ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ANY ANY 48 41 7 48 41 7 2.30e-4 2.46e-4 1.66e-4 5.86 1.77 1.77 0 ## 2 MORTGAGE MORT… 103381 85422 17959 103429 85463 17966 4.95e-1 5.12e-1 4.27e-1 4.76 1.56 1.56 0 ## 3 NONE NONE 6 5 1 103435 85468 17967 2.87e-5 2.99e-5 2.38e-5 5. 1.61 1.61 0 ## 4 OTHER OTHER 25 20 5 103460 85488 17972 1.20e-4 1.20e-4 1.19e-4 4. 1.39 1.39 0 ## 5 OWN OWN 22153 17646 4507 125613 103134 22479 1.06e-1 1.06e-1 1.07e-1 3.92 1.36 1.36 0 ## 6 RENT RENT 83403 63839 19564 209016 166973 42043 3.99e-1 3.82e-1 4.65e-1 3.26 1.18 1.18 0 ## # … with 4 more variables: WoE &lt;dbl&gt;, IV &lt;dbl&gt;, pctGoodBin &lt;dbl&gt;, pctBadBin &lt;dbl&gt; resultHome$IV ## [1] 0.03159041 3.3.4.3 Verification Status resultVerif &lt;- WoETable( df = loansBinning, x = &quot;verification_status&quot;, y = &quot;isGoodLoan&quot;, maxCategories = 20 ) resultVerif ## $IV ## [1] 0.05906488 ## ## $type ## [1] &quot;categorical&quot; ## ## $table ## # A tibble: 3 x 19 ## verification_st… Name Count nGood nBad cumCount cumGood cumBad pctCount pctGood pctBad OddsInBin LnOddsInBin WoEInBin IVInBin ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Not Verified Not … 62900 53692 9208 62900 53692 9208 0.301 0.322 0.219 5.83 1.76 1.76 0 ## 2 Source Verified Sour… 80857 63762 17095 143757 117454 26303 0.387 0.382 0.407 3.73 1.32 1.32 0 ## 3 Verified Veri… 65259 49519 15740 209016 166973 42043 0.312 0.297 0.374 3.15 1.15 1.15 0 ## # … with 4 more variables: WoE &lt;dbl&gt;, IV &lt;dbl&gt;, pctGoodBin &lt;dbl&gt;, pctBadBin &lt;dbl&gt; resultVerif$IV ## [1] 0.05906488 3.3.4.4 Purpose resultHome &lt;- WoETable( df = loansBinning, x = &quot;purpose&quot;, y = &quot;isGoodLoan&quot;, maxCategories = 20 ) resultHome ## $IV ## [1] 0.01762216 ## ## $type ## [1] &quot;categorical&quot; ## ## $table ## # A tibble: 14 x 19 ## purpose Name Count nGood nBad cumCount cumGood cumBad pctCount pctGood pctBad OddsInBin LnOddsInBin WoEInBin IVInBin ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 car car 2245 1917 328 2245 1917 328 0.0107 1.15e-2 7.80e-3 5.84 1.77 1.77 0 ## 2 credit… cred… 45514 37704 7810 47759 39621 8138 0.218 2.26e-1 1.86e-1 4.83 1.57 1.57 0 ## 3 debt_c… debt… 121629 95832 25797 169388 135453 33935 0.582 5.74e-1 6.14e-1 3.71 1.31 1.31 0 ## 4 educat… educ… 71 57 14 169459 135510 33949 0.000340 3.41e-4 3.33e-4 4.07 1.40 1.40 0 ## 5 home_i… home… 13711 11216 2495 183170 146726 36444 0.0656 6.72e-2 5.93e-2 4.50 1.50 1.50 0 ## 6 house house 1141 904 237 184311 147630 36681 0.00546 5.41e-3 5.64e-3 3.81 1.34 1.34 0 ## 7 major_… majo… 4505 3664 841 188816 151294 37522 0.0216 2.19e-2 2.00e-2 4.36 1.47 1.47 0 ## 8 medical medi… 2405 1872 533 191221 153166 38055 0.0115 1.12e-2 1.27e-2 3.51 1.26 1.26 0 ## 9 moving movi… 1505 1129 376 192726 154295 38431 0.00720 6.76e-3 8.94e-3 3.00 1.10 1.10 0 ## 10 other other 12001 9425 2576 204727 163720 41007 0.0574 5.64e-2 6.13e-2 3.66 1.30 1.30 0 ## 11 renewa… rene… 134 107 27 204861 163827 41034 0.000641 6.41e-4 6.42e-4 3.96 1.38 1.38 0 ## 12 small_… smal… 2374 1688 686 207235 165515 41720 0.0114 1.01e-2 1.63e-2 2.46 0.900 0.900 0 ## 13 vacati… vaca… 1412 1137 275 208647 166652 41995 0.00676 6.81e-3 6.54e-3 4.13 1.42 1.42 0 ## 14 wedding wedd… 369 321 48 209016 166973 42043 0.00177 1.92e-3 1.14e-3 6.69 1.90 1.90 0 ## # … with 4 more variables: WoE &lt;dbl&gt;, IV &lt;dbl&gt;, pctGoodBin &lt;dbl&gt;, pctBadBin &lt;dbl&gt; resultHome$IV ## [1] 0.01762216 3.3.4.5 Sub grade resultSubgrade &lt;- WoETable( df = loansBinning, x = &quot;sub_grade&quot;, y = &quot;isGoodLoan&quot;, maxCategories = 50 ) resultSubgrade ## $IV ## [1] 0.4980104 ## ## $type ## [1] &quot;categorical&quot; ## ## $table ## # A tibble: 35 x 19 ## sub_grade Name Count nGood nBad cumCount cumGood cumBad pctCount pctGood pctBad OddsInBin LnOddsInBin WoEInBin IVInBin WoE ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A1 A1 6501 6297 204 6501 6297 204 0.0311 0.0377 0.00485 30.9 3.43 3.43 0 2.05 ## 2 A2 A2 5620 5344 276 12121 11641 480 0.0269 0.0320 0.00656 19.4 2.96 2.96 0 1.58 ## 3 A3 A3 5889 5582 307 18010 17223 787 0.0282 0.0334 0.00730 18.2 2.90 2.90 0 1.52 ## 4 A4 A4 8159 7578 581 26169 24801 1368 0.0390 0.0454 0.0138 13.0 2.57 2.57 0 1.19 ## 5 A5 A5 10020 9171 849 36189 33972 2217 0.0479 0.0549 0.0202 10.8 2.38 2.38 0 1.00 ## 6 B1 B1 10934 9743 1191 47123 43715 3408 0.0523 0.0584 0.0283 8.18 2.10 2.10 0 0.723 ## 7 B2 B2 11345 10101 1244 58468 53816 4652 0.0543 0.0605 0.0296 8.12 2.09 2.09 0 0.715 ## 8 B3 B3 12838 11186 1652 71306 65002 6304 0.0614 0.0670 0.0393 6.77 1.91 1.91 0 0.534 ## 9 B4 B4 12895 10959 1936 84201 75961 8240 0.0617 0.0656 0.0460 5.66 1.73 1.73 0 0.354 ## 10 B5 B5 12882 10749 2133 97083 86710 10373 0.0616 0.0644 0.0507 5.04 1.62 1.62 0 0.238 ## # … with 25 more rows, and 3 more variables: IV &lt;dbl&gt;, pctGoodBin &lt;dbl&gt;, pctBadBin &lt;dbl&gt; resultSubgrade$IV ## [1] 0.4980104 3.3.4.6 Employment years resultEmp &lt;- WoETable( df = loansBinning, x = &quot;emp_length&quot;, y = &quot;isGoodLoan&quot;, maxCategories = 20 ) resultEmp ## $IV ## [1] NaN ## ## $type ## [1] &quot;categorical&quot; ## ## $table ## # A tibble: 9 x 19 ## emp_length Name Count nGood nBad cumCount cumGood cumBad pctCount pctGood pctBad OddsInBin LnOddsInBin WoEInBin IVInBin ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2 2 19170 15398 3772 19170 15398 3772 0.0917 0.0922 0.0897 4.08 1.41 1.41 0 ## 2 3 3 16645 13222 3423 35815 28620 7195 0.0796 0.0792 0.0814 3.86 1.35 1.35 0 ## 3 4 4 12601 10185 2416 48416 38805 9611 0.0603 0.0610 0.0575 4.22 1.44 1.44 0 ## 4 5 5 13032 10426 2606 61448 49231 12217 0.0623 0.0624 0.0620 4.00 1.39 1.39 0 ## 5 6 6 9815 7944 1871 71263 57175 14088 0.0470 0.0476 0.0445 4.25 1.45 1.45 0 ## 6 7 7 9295 7409 1886 80558 64584 15974 0.0445 0.0444 0.0449 3.93 1.37 1.37 0 ## 7 8 8 9487 7567 1920 90045 72151 17894 0.0454 0.0453 0.0457 3.94 1.37 1.37 0 ## 8 9 9 7675 6172 1503 97720 78323 19397 0.0367 0.0370 0.0357 4.11 1.41 1.41 0 ## 9 0 0 0 0 0 97720 78323 19397 0 0 0 NaN NaN NaN NaN ## # … with 4 more variables: WoE &lt;dbl&gt;, IV &lt;dbl&gt;, pctGoodBin &lt;dbl&gt;, pctBadBin &lt;dbl&gt; resultEmp$IV ## [1] NaN 3.3.4.7 Bank card utilisation resultBC &lt;- WoETable( df = loansBinning, x = &quot;bc_util&quot;, y = &quot;isGoodLoan&quot;, p = 0.05 ) ## Number of missing/NA values: 10370 resultBC ## $IV ## [1] 0.02918858 ## ## $type ## [1] &quot;numeric&quot; ## ## $table ## # A tibble: 7 x 23 ## CutNumber CutPoint name Min Max Count nGood nBad cumCount cumGood cumBad pctCount pctGood pctBad OddsInBin LnOddsInBin ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 31.5 &quot;&quot; -Inf 31.5 37880 31697 6183 37880 31697 6183 0.181 0.190 0.147 5.13 1.63 ## 2 2 52.2 &quot;&quot; 31.5 52.2 38014 30989 7025 75894 62686 13208 0.182 0.186 0.167 4.41 1.48 ## 3 3 76.1 &quot;&quot; 52.2 76.1 52106 41337 10769 128000 104023 23977 0.249 0.248 0.256 3.84 1.35 ## 4 4 90.8 &quot;&quot; 76.1 90.8 36497 28541 7956 164497 132564 31933 0.175 0.171 0.189 3.59 1.28 ## 5 5 95.4 &quot;&quot; 90.8 95.4 14346 10999 3347 178843 143563 35280 0.0686 0.0659 0.0796 3.29 1.19 ## 6 6 203. &quot;&quot; 95.4 203. 19803 14780 5023 198646 158343 40303 0.0947 0.0885 0.119 2.94 1.08 ## 7 7 NA &lt;NA&gt; NA NA 10370 8630 1740 209016 166973 42043 0.0496 0.0517 0.0414 4.96 1.60 ## # … with 7 more variables: WoEInBin &lt;dbl&gt;, IVInBin &lt;dbl&gt;, WoE &lt;dbl&gt;, IV &lt;dbl&gt;, Name &lt;chr&gt;, pctGoodBin &lt;dbl&gt;, pctBadBin &lt;dbl&gt; resultBC$IV ## [1] 0.02918858 3.3.4.8 State resultState &lt;- WoETable( df = loansBinning, x = &quot;addr_state&quot;, y = &quot;isGoodLoan&quot;, maxCategories = 100 ) resultState ## $IV ## [1] 0.01744293 ## ## $type ## [1] &quot;categorical&quot; ## ## $table ## # A tibble: 51 x 19 ## addr_state Name Count nGood nBad cumCount cumGood cumBad pctCount pctGood pctBad OddsInBin LnOddsInBin WoEInBin IVInBin ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AK AK 442 345 97 442 345 97 0.00211 0.00207 0.00231 3.56 1.27 1.27 0 ## 2 AL AL 2545 1973 572 2987 2318 669 0.0122 0.0118 0.0136 3.45 1.24 1.24 0 ## 3 AR AR 1543 1175 368 4530 3493 1037 0.00738 0.00704 0.00875 3.19 1.16 1.16 0 ## 4 AZ AZ 5214 4224 990 9744 7717 2027 0.0249 0.0253 0.0235 4.27 1.45 1.45 0 ## 5 CA CA 30732 24682 6050 40476 32399 8077 0.147 0.148 0.144 4.08 1.41 1.41 0 ## 6 CO CO 4633 3908 725 45109 36307 8802 0.0222 0.0234 0.0172 5.39 1.68 1.68 0 ## 7 CT CT 3024 2483 541 48133 38790 9343 0.0145 0.0149 0.0129 4.59 1.52 1.52 0 ## 8 DC DC 531 461 70 48664 39251 9413 0.00254 0.00276 0.00166 6.59 1.88 1.88 0 ## 9 DE DE 594 468 126 49258 39719 9539 0.00284 0.00280 0.00300 3.71 1.31 1.31 0 ## 10 FL FL 14906 11726 3180 64164 51445 12719 0.0713 0.0702 0.0756 3.69 1.30 1.30 0 ## # … with 41 more rows, and 4 more variables: WoE &lt;dbl&gt;, IV &lt;dbl&gt;, pctGoodBin &lt;dbl&gt;, pctBadBin &lt;dbl&gt; resultState$IV ## [1] 0.01744293 3.3.4.9 Annual income which(names(loansBinning) == &quot;annual_inc_joint&quot;) ## [1] 25 resultInc &lt;- WoETable( df = loansBinning, x = &quot;annual_inc_joint&quot;, y = &quot;isGoodLoan&quot;, p = 0.05 ) resultHome ## $IV ## [1] 0.01762216 ## ## $type ## [1] &quot;categorical&quot; ## ## $table ## # A tibble: 14 x 19 ## purpose Name Count nGood nBad cumCount cumGood cumBad pctCount pctGood pctBad OddsInBin LnOddsInBin WoEInBin IVInBin ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 car car 2245 1917 328 2245 1917 328 0.0107 1.15e-2 7.80e-3 5.84 1.77 1.77 0 ## 2 credit… cred… 45514 37704 7810 47759 39621 8138 0.218 2.26e-1 1.86e-1 4.83 1.57 1.57 0 ## 3 debt_c… debt… 121629 95832 25797 169388 135453 33935 0.582 5.74e-1 6.14e-1 3.71 1.31 1.31 0 ## 4 educat… educ… 71 57 14 169459 135510 33949 0.000340 3.41e-4 3.33e-4 4.07 1.40 1.40 0 ## 5 home_i… home… 13711 11216 2495 183170 146726 36444 0.0656 6.72e-2 5.93e-2 4.50 1.50 1.50 0 ## 6 house house 1141 904 237 184311 147630 36681 0.00546 5.41e-3 5.64e-3 3.81 1.34 1.34 0 ## 7 major_… majo… 4505 3664 841 188816 151294 37522 0.0216 2.19e-2 2.00e-2 4.36 1.47 1.47 0 ## 8 medical medi… 2405 1872 533 191221 153166 38055 0.0115 1.12e-2 1.27e-2 3.51 1.26 1.26 0 ## 9 moving movi… 1505 1129 376 192726 154295 38431 0.00720 6.76e-3 8.94e-3 3.00 1.10 1.10 0 ## 10 other other 12001 9425 2576 204727 163720 41007 0.0574 5.64e-2 6.13e-2 3.66 1.30 1.30 0 ## 11 renewa… rene… 134 107 27 204861 163827 41034 0.000641 6.41e-4 6.42e-4 3.96 1.38 1.38 0 ## 12 small_… smal… 2374 1688 686 207235 165515 41720 0.0114 1.01e-2 1.63e-2 2.46 0.900 0.900 0 ## 13 vacati… vaca… 1412 1137 275 208647 166652 41995 0.00676 6.81e-3 6.54e-3 4.13 1.42 1.42 0 ## 14 wedding wedd… 369 321 48 209016 166973 42043 0.00177 1.92e-3 1.14e-3 6.69 1.90 1.90 0 ## # … with 4 more variables: WoE &lt;dbl&gt;, IV &lt;dbl&gt;, pctGoodBin &lt;dbl&gt;, pctBadBin &lt;dbl&gt; resultHome$iv ## NULL 3.3.4.10 Loan amount resultAmnt &lt;- WoETable( df = loansBinning, x = &quot;loan_amnt&quot;, y = &quot;isGoodLoan&quot;, p = 0.05 ) ## Number of missing/NA values: 0 resultAmnt ## $IV ## [1] 0.03442168 ## ## $type ## [1] &quot;numeric&quot; ## ## $table ## # A tibble: 7 x 23 ## CutNumber CutPoint name Min Max Count nGood nBad cumCount cumGood cumBad pctCount pctGood pctBad OddsInBin LnOddsInBin ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 3500 &quot;&quot; -Inf 3500 12109 10325 1784 12109 10325 1784 0.0579 0.0618 0.0424 5.79 1.76 ## 2 2 9000 &quot;&quot; 3500 9000 54266 45162 9104 66375 55487 10888 0.260 0.270 0.217 4.96 1.60 ## 3 3 10000 &quot;&quot; 9000 10000 20022 16170 3852 86397 71657 14740 0.0958 0.0968 0.0916 4.20 1.43 ## 4 4 14975 &quot;&quot; 10000 14975 33242 26250 6992 119639 97907 21732 0.159 0.157 0.166 3.75 1.32 ## 5 5 15000 &quot;&quot; 14975 15000 10817 8743 2074 130456 106650 23806 0.0518 0.0524 0.0493 4.22 1.44 ## 6 6 28000 &quot;&quot; 15000 28000 60284 46570 13714 190740 153220 37520 0.288 0.279 0.326 3.40 1.22 ## 7 7 40000 &quot;&quot; 28000 40000 18276 13753 4523 209016 166973 42043 0.0874 0.0824 0.108 3.04 1.11 ## # … with 7 more variables: WoEInBin &lt;dbl&gt;, IVInBin &lt;dbl&gt;, WoE &lt;dbl&gt;, IV &lt;dbl&gt;, Name &lt;chr&gt;, pctGoodBin &lt;dbl&gt;, pctBadBin &lt;dbl&gt; resultAmnt$IV ## [1] 0.03442168 3.4 Logistic Regression 3.4.1 Logistic regression using the SpeedGLM package NOTE: speedglm has a select() function which would shadow dplyr::select(), so it is only used fully qualified to avoid any collision. # Cleanup and reload # Training results to speed up analysis # load(&quot;datasets/GLModelResults.rda&quot;) loansTraining &lt;- readRDS(&quot;datasets/LoansTraining.rds&quot;) # Take the allBins dataset (without `loanID`) # Add the desired response allFactorsAsCharacteristics &lt;- readRDS(&quot;datasets/allCharacteristics100.rds&quot;) allFactorsAsBins &lt;- readRDS(&quot;datasets/allBins100.rds&quot;) loanSampleBins &lt;- allFactorsAsBins %&gt;% select(-loanID) %&gt;% cbind(loansTraining$isGoodLoan) %&gt;% rename(isGoodLoan = &quot;loansTraining$isGoodLoan&quot;) %&gt;% mutate(isGoodLoan = if_else(isGoodLoan, 1, 0)) %&gt;% as.data.frame() loanSampleCharacteristics &lt;- allFactorsAsCharacteristics %&gt;% select(-loanID) %&gt;% cbind(loansTraining$isGoodLoan) %&gt;% rename(isGoodLoan = &quot;loansTraining$isGoodLoan&quot;) %&gt;% mutate(isGoodLoan = if_else(isGoodLoan, 1, 0)) %&gt;% as.data.frame() rm(loansTraining) gc(full = TRUE) ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 2836124 151.5 6816128 364.1 6816128 364.1 ## Vcells 453171745 3457.5 1151772154 8787.4 1826494161 13935.1 ncol(loanSampleBins) ## [1] 222 ncol(loanSampleCharacteristics) ## [1] 27 3.4.2 Remove identical bins namesCharacteristics &lt;- names(loanSampleCharacteristics) namesBins &lt;- names(loanSampleBins) # Starting list of names # &gt; The following two variables are only useful if all the bins have been given their own column (if a # &gt; characteristic has 7 factors, that creates 7 bins and column). # Running GLM would give a number of NAs if some columns are linearly dependant (in our case # actually equal). A &quot;trick&quot; to identify them is to run a hash digest on each column and spot # identical hashes The original variables were not identical, but when split into categories, they # can become identical. For example, if no income is provided (income=NA category), no # debt-to-income ratio can be calculated (dti=NA). duplicateNames &lt;- loanSampleBins[duplicated(lapply(loanSampleBins, digest::digest))] %&gt;% names() duplicateNames ## [1] &quot;(open_rv_24m) open_rv_24m=NA&quot; &quot;(max_bal_bc) max_bal_bc=NA&quot; ## [3] &quot;(bc_util) -Inf&lt;bc_util&lt;=31.5&quot; &quot;(bc_util) 31.5&lt;bc_util&lt;=38.8&quot; ## [5] &quot;(bc_util) 38.8&lt;bc_util&lt;=46.1&quot; &quot;(bc_util) 46.1&lt;bc_util&lt;=53.9&quot; ## [7] &quot;(bc_util) 53.9&lt;bc_util&lt;=72.5&quot; &quot;(bc_util) 72.5&lt;bc_util&lt;=87.6&quot; ## [9] &quot;(bc_util) 87.6&lt;bc_util&lt;=91.9&quot; &quot;(bc_util) 91.9&lt;bc_util&lt;=97.9&quot; ## [11] &quot;(bc_util) 97.9&lt;bc_util&lt;=339.6&quot; &quot;(bc_util) bc_util=NA&quot; ## [13] &quot;(mo_sin_rcnt_rev_tl_op) mo_sin_rcnt_rev_tl_op=NA&quot; &quot;(num_actv_rev_tl) num_actv_rev_tl=NA&quot; ## [15] &quot;(num_rev_tl_bal_gt_0) num_rev_tl_bal_gt_0=NA&quot; &quot;(num_tl_op_past_12m) num_tl_op_past_12m=NA&quot; ## [17] &quot;(tot_hi_cred_lim) tot_hi_cred_lim=NA&quot; &quot;(total_bc_limit) total_bc_limit=NA&quot; ## [19] &quot;(issue_d2) 200.694&lt;issue_d2&lt;=215.111&quot; &quot;(issue_d2) 215.111&lt;issue_d2&lt;=258.674&quot; ## [21] &quot;(issue_d2) 258.674&lt;issue_d2&lt;=277.778&quot; &quot;(issue_d2) 277.778&lt;issue_d2&lt;=315.062&quot; ## [23] &quot;(issue_d2) 315.062&lt;issue_d2&lt;=357.84&quot; &quot;(issue_d3) -Inf&lt;issue_d3&lt;=2599.609&quot; ## [25] &quot;(issue_d3) 2599.609&lt;issue_d3&lt;=2843.171&quot; &quot;(issue_d3) 2843.171&lt;issue_d3&lt;=3154.963&quot; ## [27] &quot;(issue_d3) 3154.963&lt;issue_d3&lt;=4160.334&quot; &quot;(issue_d3) 4160.334&lt;issue_d3&lt;=4629.63&quot; ## [29] &quot;(issue_d3) 4629.63&lt;issue_d3&lt;=5592.359&quot; &quot;(issue_d3) 5592.359&lt;issue_d3&lt;=6769.145&quot; # Remove any categories uniformaly constant (only 0) # # This is important when working on a small extract of the dataset for variables that are seldom # used (e.g. customers from certain states). zeroColumnsNames &lt;- loanSampleBins[, colSums(loanSampleBins) == 0] %&gt;% names() 3.4.3 First training on variables previously selected on their Information Value We use speedglm being quick. Note that alternatives were also tried: glm crashed on even small extracts of the dataset. glmnet returns errors that were not understandable or documented on the internet. 3.4.3.1 GLM on characteristics gc(full = TRUE) ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 2836006 151.5 6816128 364.1 6816128 364.1 ## Vcells 453172043 3457.5 1151772154 8787.4 1826494161 13935.1 # About 700 sec wall-time to complete training dataset # The dataset is the sample less duplicate, less zero-ed columns { doMC::registerDoMC(cores = 1) # Too many processes push over 32GB startTime &lt;- proc.time() loansData &lt;- loanSampleCharacteristics %&gt;% select(-one_of( c(duplicateNames, zeroColumnsNames))) SGLM_C_train &lt;- speedglm::speedglm(isGoodLoan ~ ., data = loansData, family = binomial()) doMC::registerDoMC(cores = NULL) cat(proc.time() - startTime, &quot;\\n&quot;) } ## 152.174 8.799 173.566 0 0 summary(SGLM_C_train) ## Generalized Linear Model of class &#39;speedglm&#39;: ## ## Call: speedglm::speedglm(formula = isGoodLoan ~ ., data = loansData, family = binomial()) ## ## Coefficients: ## ------------------------------------------------------------------ ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 1.654651 0.027022 61.2330 0.00e+00 *** ## loan_amnt14975&lt;loan_amnt&lt;=15000 -0.611612 0.016493 -37.0834 5.20e-301 *** ## loan_amnt9000&lt;loan_amnt&lt;=10000 -0.423648 0.014555 -29.1068 2.94e-186 *** ## loan_amnt12000&lt;loan_amnt&lt;=14975 -0.657958 0.015413 -42.6873 0.00e+00 *** ## loan_amnt15000&lt;loan_amnt&lt;=17000 -0.785494 0.015970 -49.1862 0.00e+00 *** ## loan_amnt3500&lt;loan_amnt&lt;=9000 -0.176897 0.012956 -13.6540 1.91e-42 *** ## loan_amnt19950&lt;loan_amnt&lt;=28000 -0.922807 0.013695 -67.3806 0.00e+00 *** ## loan_amnt28000&lt;loan_amnt&lt;=40000 -1.161735 0.015222 -76.3171 0.00e+00 *** ## loan_amnt10000&lt;loan_amnt&lt;=12000 -0.561516 0.014458 -38.8382 0.00e+00 *** ## loan_amnt17000&lt;loan_amnt&lt;=19950 -0.883419 0.015922 -55.4846 0.00e+00 *** ## verification_statusSource Verified -0.212522 0.006704 -31.6993 1.59e-220 *** ## verification_statusVerified -0.284086 0.007080 -40.1275 0.00e+00 *** ## issue_d-Inf&lt;issue_d&lt;=14.167 0.571031 0.017279 33.0479 1.67e-239 *** ## issue_d14.667&lt;issue_d&lt;=16.083 0.304914 0.012108 25.1839 6.01e-140 *** ## issue_d16.083&lt;issue_d&lt;=16.667 -0.056860 0.009120 -6.2344 4.53e-10 *** ## issue_d14.167&lt;issue_d&lt;=14.667 0.375426 0.015807 23.7501 1.10e-124 *** ## issue_d17.75&lt;issue_d&lt;=18.917 0.362928 0.013544 26.7952 3.67e-158 *** ## dti0.156&lt;dti&lt;=0.178 -0.158876 0.010902 -14.5727 4.19e-48 *** ## dti0.122&lt;dti&lt;=0.143 -0.059598 0.011283 -5.2821 1.28e-07 *** ## dti0.192&lt;dti&lt;=0.217 -0.250862 0.010760 -23.3148 3.14e-120 *** ## dti0.254&lt;dti&lt;=0.272 -0.434550 0.012870 -33.7648 6.48e-250 *** ## dti0.299&lt;dti&lt;=9.99 -0.657574 0.010587 -62.1126 0.00e+00 *** ## dti0.178&lt;dti&lt;=0.192 -0.200020 0.012599 -15.8759 9.31e-57 *** ## dti0.272&lt;dti&lt;=0.299 -0.491943 0.012061 -40.7896 0.00e+00 *** ## dti0.097&lt;dti&lt;=0.122 -0.026908 0.011341 -2.3727 1.77e-02 * ## dti0.236&lt;dti&lt;=0.254 -0.372892 0.012484 -29.8692 4.95e-196 *** ## dti0.143&lt;dti&lt;=0.156 -0.119758 0.013051 -9.1763 4.46e-20 *** ## dti0.217&lt;dti&lt;=0.236 -0.330228 0.011854 -27.8574 8.77e-171 *** ## dtidti=NA -0.257596 0.164234 -1.5685 1.17e-01 ## inq_last_6mths-Inf&lt;inq_last_6mths&lt;=0 0.202236 0.010651 18.9869 2.19e-80 *** ## inq_last_6mths0&lt;inq_last_6mths&lt;=1 0.096644 0.008981 10.7611 5.25e-27 *** ## inq_last_6mths2&lt;inq_last_6mths&lt;=33 -0.146377 0.012374 -11.8294 2.75e-32 *** ## inq_last_6mthsinq_last_6mths=NA 0.357904 0.746709 0.4793 6.32e-01 ## revol_util0.217&lt;revol_util&lt;=0.316 0.010713 0.014609 0.7333 4.63e-01 ## revol_util0.718&lt;revol_util&lt;=0.869 -0.216150 0.017190 -12.5740 2.93e-36 *** ## revol_util0.869&lt;revol_util&lt;=3.666 -0.309763 0.018638 -16.6196 5.03e-62 *** ## revol_util0.479&lt;revol_util&lt;=0.569 -0.116696 0.016627 -7.0183 2.25e-12 *** ## revol_util0.569&lt;revol_util&lt;=0.718 -0.148698 0.016462 -9.0327 1.68e-19 *** ## revol_util0.388&lt;revol_util&lt;=0.479 -0.080468 0.016286 -4.9408 7.78e-07 *** ## revol_util0.147&lt;revol_util&lt;=0.217 0.018170 0.016165 1.1240 2.61e-01 ## revol_util0.316&lt;revol_util&lt;=0.388 -0.029066 0.016419 -1.7702 7.67e-02 . ## revol_utilrevol_util=NA -0.325272 0.105784 -3.0749 2.11e-03 ** ## open_rv_12mopen_rv_12m=NA -0.052021 0.016200 -3.2111 1.32e-03 ** ## open_rv_12m-Inf&lt;open_rv_12m&lt;=0 -0.072098 0.013569 -5.3134 1.08e-07 *** ## open_rv_12m2&lt;open_rv_12m&lt;=28 0.168254 0.015514 10.8455 2.09e-27 *** ## open_rv_12m1&lt;open_rv_12m&lt;=2 0.082332 0.012798 6.4331 1.25e-10 *** ## open_rv_24mopen_rv_24m=NA NA NA NA NA ## open_rv_24m1&lt;open_rv_24m&lt;=2 -0.040201 0.013740 -2.9259 3.43e-03 ** ## open_rv_24m3&lt;open_rv_24m&lt;=5 -0.171765 0.015503 -11.0797 1.57e-28 *** ## open_rv_24m2&lt;open_rv_24m&lt;=3 -0.124506 0.015078 -8.2577 1.48e-16 *** ## open_rv_24m-Inf&lt;open_rv_24m&lt;=0 -0.086165 0.018857 -4.5693 4.89e-06 *** ## open_rv_24m5&lt;open_rv_24m&lt;=53 -0.264156 0.018018 -14.6610 1.15e-48 *** ## max_bal_bcmax_bal_bc=NA NA NA NA NA ## max_bal_bc7905&lt;max_bal_bc&lt;=776843 -0.013343 0.011801 -1.1307 2.58e-01 ## max_bal_bc5122&lt;max_bal_bc&lt;=7905 0.003012 0.011053 0.2725 7.85e-01 ## avg_cur_balavg_cur_bal=NA -0.949400 0.535525 -1.7728 7.63e-02 . ## avg_cur_bal11363&lt;avg_cur_bal&lt;=14047 -0.031547 0.014191 -2.2231 2.62e-02 * ## avg_cur_bal27395&lt;avg_cur_bal&lt;=41609 -0.088727 0.018088 -4.9052 9.33e-07 *** ## avg_cur_bal14047&lt;avg_cur_bal&lt;=21129 -0.068323 0.013534 -5.0484 4.46e-07 *** ## avg_cur_bal21129&lt;avg_cur_bal&lt;=27395 -0.090694 0.016671 -5.4403 5.32e-08 *** ## avg_cur_bal8012&lt;avg_cur_bal&lt;=11363 -0.008267 0.011130 -0.7427 4.58e-01 ## avg_cur_bal41609&lt;avg_cur_bal&lt;=800008 -0.076770 0.022773 -3.3711 7.49e-04 *** ## bc_open_to_buy0.315&lt;bc_open_to_buy&lt;=0.388 0.027298 0.014245 1.9162 5.53e-02 . ## bc_open_to_buy0.979&lt;bc_open_to_buy&lt;=3.396 -0.101314 0.021487 -4.7151 2.42e-06 *** ## bc_open_to_buy0.461&lt;bc_open_to_buy&lt;=0.539 0.087466 0.014658 5.9673 2.41e-09 *** ## bc_open_to_buy0.876&lt;bc_open_to_buy&lt;=0.919 0.200794 0.019174 10.4722 1.16e-25 *** ## bc_open_to_buy0.725&lt;bc_open_to_buy&lt;=0.876 0.225314 0.015733 14.3210 1.62e-46 *** ## bc_open_to_buy0.539&lt;bc_open_to_buy&lt;=0.725 0.142411 0.013729 10.3728 3.30e-25 *** ## bc_open_to_buybc_open_to_buy=NA -0.293741 0.089194 -3.2933 9.90e-04 *** ## bc_open_to_buy0.388&lt;bc_open_to_buy&lt;=0.461 0.062577 0.014531 4.3065 1.66e-05 *** ## bc_open_to_buy0.919&lt;bc_open_to_buy&lt;=0.979 0.081235 0.019246 4.2209 2.43e-05 *** ## bc_util31.5&lt;bc_util&lt;=38.8 NA NA NA NA ## bc_util97.9&lt;bc_util&lt;=339.6 NA NA NA NA ## bc_util46.1&lt;bc_util&lt;=53.9 NA NA NA NA ## bc_util87.6&lt;bc_util&lt;=91.9 NA NA NA NA ## bc_util72.5&lt;bc_util&lt;=87.6 NA NA NA NA ## bc_util53.9&lt;bc_util&lt;=72.5 NA NA NA NA ## bc_utilbc_util=NA NA NA NA NA ## bc_util38.8&lt;bc_util&lt;=46.1 NA NA NA NA ## bc_util91.9&lt;bc_util&lt;=97.9 NA NA NA NA ## mo_sin_old_rev_tl_opmo_sin_old_rev_tl_op=NA -8.640285 16.181331 -0.5340 5.93e-01 ## mo_sin_old_rev_tl_op212&lt;mo_sin_old_rev_tl_op&lt;=852 0.044524 0.007339 6.0664 1.31e-09 *** ## mo_sin_old_rev_tl_op82&lt;mo_sin_old_rev_tl_op&lt;=132 -0.088202 0.007738 -11.3983 4.27e-30 *** ## mo_sin_old_rev_tl_op132&lt;mo_sin_old_rev_tl_op&lt;=143 -0.049584 0.011767 -4.2139 2.51e-05 *** ## mo_sin_old_rev_tl_op-Inf&lt;mo_sin_old_rev_tl_op&lt;=58 -0.293715 0.011417 -25.7264 5.92e-146 *** ## mo_sin_old_rev_tl_op58&lt;mo_sin_old_rev_tl_op&lt;=82 -0.167112 0.011999 -13.9270 4.34e-44 *** ## mo_sin_old_rev_tl_op143&lt;mo_sin_old_rev_tl_op&lt;=154 -0.033960 0.012092 -2.8085 4.98e-03 ** ## mo_sin_rcnt_rev_tl_opmo_sin_rcnt_rev_tl_op=NA NA NA NA NA ## mo_sin_rcnt_rev_tl_op4&lt;mo_sin_rcnt_rev_tl_op&lt;=7 -0.088233 0.018420 -4.7902 1.67e-06 *** ## mo_sin_rcnt_rev_tl_op7&lt;mo_sin_rcnt_rev_tl_op&lt;=9 -0.153633 0.019716 -7.7923 6.58e-15 *** ## mo_sin_rcnt_rev_tl_op9&lt;mo_sin_rcnt_rev_tl_op&lt;=16 -0.196814 0.017880 -11.0077 3.51e-28 *** ## mo_sin_rcnt_rev_tl_op16&lt;mo_sin_rcnt_rev_tl_op&lt;=20 -0.198438 0.021067 -9.4195 4.53e-21 *** ## mo_sin_rcnt_rev_tl_op3&lt;mo_sin_rcnt_rev_tl_op&lt;=4 -0.043725 0.019807 -2.2075 2.73e-02 * ## mo_sin_rcnt_rev_tl_op20&lt;mo_sin_rcnt_rev_tl_op&lt;=28 -0.144915 0.020829 -6.9574 3.46e-12 *** ## mo_sin_rcnt_rev_tl_op-Inf&lt;mo_sin_rcnt_rev_tl_op&lt;=1 -0.041782 0.024580 -1.6998 8.92e-02 . ## mo_sin_rcnt_rev_tl_op28&lt;mo_sin_rcnt_rev_tl_op&lt;=438 -0.109213 0.021447 -5.0923 3.54e-07 *** ## mo_sin_rcnt_rev_tl_op1&lt;mo_sin_rcnt_rev_tl_op&lt;=2 0.050357 0.022129 2.2756 2.29e-02 * ## mo_sin_rcnt_tlmo_sin_rcnt_tl=NA 9.277562 16.190846 0.5730 5.67e-01 ## mo_sin_rcnt_tl5&lt;mo_sin_rcnt_tl&lt;=7 0.104581 0.015179 6.8900 5.58e-12 *** ## mo_sin_rcnt_tl7&lt;mo_sin_rcnt_tl&lt;=9 0.145049 0.016676 8.6980 3.38e-18 *** ## mo_sin_rcnt_tl3&lt;mo_sin_rcnt_tl&lt;=4 0.064671 0.017181 3.7641 1.67e-04 *** ## mo_sin_rcnt_tl11&lt;mo_sin_rcnt_tl&lt;=14 0.162630 0.021632 7.5178 5.57e-14 *** ## mo_sin_rcnt_tl-Inf&lt;mo_sin_rcnt_tl&lt;=1 0.031869 0.020662 1.5423 1.23e-01 ## mo_sin_rcnt_tl9&lt;mo_sin_rcnt_tl&lt;=11 0.179566 0.017338 10.3570 3.89e-25 *** ## mo_sin_rcnt_tl1&lt;mo_sin_rcnt_tl&lt;=2 -0.011416 0.017458 -0.6539 5.13e-01 ## mo_sin_rcnt_tl4&lt;mo_sin_rcnt_tl&lt;=5 0.110631 0.016327 6.7760 1.24e-11 *** ## mo_sin_rcnt_tl21&lt;mo_sin_rcnt_tl&lt;=314 0.160153 0.029004 5.5217 3.36e-08 *** ## mo_sin_rcnt_tl14&lt;mo_sin_rcnt_tl&lt;=21 0.209792 0.027451 7.6424 2.13e-14 *** ## mort_acc2&lt;mort_acc&lt;=3 0.177831 0.010684 16.6438 3.36e-62 *** ## mort_acc1&lt;mort_acc&lt;=2 0.145860 0.009290 15.7002 1.51e-55 *** ## mort_acc0&lt;mort_acc&lt;=1 0.068731 0.008331 8.2497 1.59e-16 *** ## mort_accmort_acc=NA 0.190708 0.038050 5.0121 5.38e-07 *** ## mort_acc3&lt;mort_acc&lt;=5 0.210186 0.010893 19.2958 5.83e-83 *** ## mort_acc5&lt;mort_acc&lt;=47 0.259600 0.015064 17.2330 1.50e-66 *** ## mths_since_recent_bc35&lt;mths_since_recent_bc&lt;=56 0.274236 0.015404 17.8026 6.75e-71 *** ## mths_since_recent_bc56&lt;mths_since_recent_bc&lt;=639 0.367205 0.015573 23.5790 6.33e-123 *** ## mths_since_recent_bc7&lt;mths_since_recent_bc&lt;=15 0.099056 0.012802 7.7376 1.01e-14 *** ## mths_since_recent_bc15&lt;mths_since_recent_bc&lt;=21 0.147053 0.014378 10.2277 1.49e-24 *** ## mths_since_recent_bc4&lt;mths_since_recent_bc&lt;=7 0.052988 0.014330 3.6978 2.17e-04 *** ## mths_since_recent_bc21&lt;mths_since_recent_bc&lt;=28 0.188287 0.015366 12.2539 1.60e-34 *** ## mths_since_recent_bcmths_since_recent_bc=NA 0.537903 0.085140 6.3179 2.65e-10 *** ## mths_since_recent_bc-Inf&lt;mths_since_recent_bc&lt;=2 -0.071835 0.015680 -4.5814 4.62e-06 *** ## mths_since_recent_bc28&lt;mths_since_recent_bc&lt;=35 0.211629 0.016642 12.7168 4.77e-37 *** ## mths_since_recent_inq4&lt;mths_since_recent_inq&lt;=5 0.152236 0.013564 11.2239 3.11e-29 *** ## mths_since_recent_inq16&lt;mths_since_recent_inq&lt;=25 0.171868 0.014558 11.8056 3.65e-32 *** ## mths_since_recent_inq8&lt;mths_since_recent_inq&lt;=10 0.121769 0.014386 8.4647 2.57e-17 *** ## mths_since_recent_inq5&lt;mths_since_recent_inq&lt;=8 0.119398 0.011539 10.3470 4.32e-25 *** ## mths_since_recent_inq2&lt;mths_since_recent_inq&lt;=3 0.122257 0.012381 9.8749 5.35e-23 *** ## mths_since_recent_inq1&lt;mths_since_recent_inq&lt;=2 0.088954 0.011877 7.4896 6.91e-14 *** ## mths_since_recent_inqmths_since_recent_inq=NA 0.230252 0.014271 16.1338 1.48e-58 *** ## mths_since_recent_inq10&lt;mths_since_recent_inq&lt;=16 0.135504 0.012815 10.5737 3.95e-26 *** ## mths_since_recent_inq3&lt;mths_since_recent_inq&lt;=4 0.148106 0.012924 11.4601 2.09e-30 *** ## mths_since_recent_inq-Inf&lt;mths_since_recent_inq&lt;=0 -0.063732 0.011249 -5.6655 1.47e-08 *** ## num_actv_rev_tlnum_actv_rev_tl=NA NA NA NA NA ## num_actv_rev_tl4&lt;num_actv_rev_tl&lt;=5 -0.072060 0.054707 -1.3172 1.88e-01 ## num_actv_rev_tl2&lt;num_actv_rev_tl&lt;=3 0.031014 0.046970 0.6603 5.09e-01 ## num_actv_rev_tl7&lt;num_actv_rev_tl&lt;=8 -0.124795 0.060773 -2.0535 4.00e-02 * ## num_actv_rev_tl10&lt;num_actv_rev_tl&lt;=63 -0.116954 0.063720 -1.8354 6.64e-02 . ## num_actv_rev_tl6&lt;num_actv_rev_tl&lt;=7 -0.117490 0.058766 -1.9993 4.56e-02 * ## num_actv_rev_tl5&lt;num_actv_rev_tl&lt;=6 -0.044321 0.056745 -0.7810 4.35e-01 ## num_actv_rev_tl3&lt;num_actv_rev_tl&lt;=4 -0.016133 0.051744 -0.3118 7.55e-01 ## num_actv_rev_tl8&lt;num_actv_rev_tl&lt;=10 -0.124593 0.061187 -2.0363 4.17e-02 * ## num_rev_tl_bal_gt_0num_rev_tl_bal_gt_0=NA NA NA NA NA ## num_rev_tl_bal_gt_04&lt;num_rev_tl_bal_gt_0&lt;=5 -0.069984 0.054597 -1.2818 2.00e-01 ## num_rev_tl_bal_gt_02&lt;num_rev_tl_bal_gt_0&lt;=3 -0.069306 0.046793 -1.4811 1.39e-01 ## num_rev_tl_bal_gt_07&lt;num_rev_tl_bal_gt_0&lt;=8 -0.160233 0.060799 -2.6355 8.40e-03 ** ## num_rev_tl_bal_gt_010&lt;num_rev_tl_bal_gt_0&lt;=45 -0.333749 0.064018 -5.2134 1.85e-07 *** ## num_rev_tl_bal_gt_06&lt;num_rev_tl_bal_gt_0&lt;=7 -0.118130 0.058731 -2.0114 4.43e-02 * ## num_rev_tl_bal_gt_05&lt;num_rev_tl_bal_gt_0&lt;=6 -0.153250 0.056654 -2.7050 6.83e-03 ** ## num_rev_tl_bal_gt_03&lt;num_rev_tl_bal_gt_0&lt;=4 -0.083148 0.051615 -1.6109 1.07e-01 ## num_rev_tl_bal_gt_08&lt;num_rev_tl_bal_gt_0&lt;=10 -0.205465 0.061274 -3.3532 7.99e-04 *** ## num_tl_op_past_12mnum_tl_op_past_12m=NA NA NA NA NA ## num_tl_op_past_12m1&lt;num_tl_op_past_12m&lt;=2 -0.095229 0.008319 -11.4468 2.44e-30 *** ## num_tl_op_past_12m2&lt;num_tl_op_past_12m&lt;=3 -0.204745 0.009423 -21.7286 1.10e-104 *** ## num_tl_op_past_12m-Inf&lt;num_tl_op_past_12m&lt;=0 0.023845 0.021102 1.1300 2.58e-01 ## num_tl_op_past_12m4&lt;num_tl_op_past_12m&lt;=30 -0.346750 0.012180 -28.4698 2.77e-178 *** ## num_tl_op_past_12m3&lt;num_tl_op_past_12m&lt;=4 -0.289847 0.011108 -26.0928 4.40e-150 *** ## percent_bc_gt_750.958&lt;percent_bc_gt_75&lt;=1 -0.237377 0.015067 -15.7553 6.32e-56 *** ## percent_bc_gt_750.346&lt;percent_bc_gt_75&lt;=0.522 -0.245893 0.010829 -22.7070 3.82e-114 *** ## percent_bc_gt_750.682&lt;percent_bc_gt_75&lt;=0.958 -0.381802 0.014143 -26.9951 1.69e-160 *** ## percent_bc_gt_750.522&lt;percent_bc_gt_75&lt;=0.682 -0.314362 0.012726 -24.7025 1.00e-134 *** ## percent_bc_gt_750.034&lt;percent_bc_gt_75&lt;=0.259 -0.128643 0.010266 -12.5314 5.03e-36 *** ## percent_bc_gt_75percent_bc_gt_75=NA -0.036402 0.105889 -0.3438 7.31e-01 ## percent_bc_gt_750.259&lt;percent_bc_gt_75&lt;=0.346 -0.178834 0.011988 -14.9175 2.54e-50 *** ## tot_hi_cred_limtot_hi_cred_lim=NA NA NA NA NA ## tot_hi_cred_lim131793&lt;tot_hi_cred_lim&lt;=179071 0.236126 0.012159 19.4205 5.18e-84 *** ## tot_hi_cred_lim242055&lt;tot_hi_cred_lim&lt;=298516 0.486773 0.016293 29.8765 3.97e-196 *** ## tot_hi_cred_lim179071&lt;tot_hi_cred_lim&lt;=208761 0.343525 0.015691 21.8937 2.98e-106 *** ## tot_hi_cred_lim102535&lt;tot_hi_cred_lim&lt;=131793 0.194877 0.011558 16.8601 8.84e-64 *** ## tot_hi_cred_lim208761&lt;tot_hi_cred_lim&lt;=242055 0.404383 0.016448 24.5849 1.83e-133 *** ## tot_hi_cred_lim298516&lt;tot_hi_cred_lim&lt;=383997 0.563844 0.017600 32.0358 3.46e-225 *** ## tot_hi_cred_lim487388&lt;tot_hi_cred_lim&lt;=9999999 0.775532 0.023321 33.2549 1.73e-242 *** ## tot_hi_cred_lim383997&lt;tot_hi_cred_lim&lt;=487388 0.625857 0.020511 30.5134 1.73e-204 *** ## total_bc_limit20950&lt;total_bc_limit&lt;=24806 0.619885 0.013616 45.5268 0.00e+00 *** ## total_bc_limit4478&lt;total_bc_limit&lt;=9405 0.233076 0.009441 24.6882 1.43e-134 *** ## total_bc_limit34756&lt;total_bc_limit&lt;=47175 0.821077 0.014337 57.2692 0.00e+00 *** ## total_bc_limit13970&lt;total_bc_limit&lt;=18174 0.506909 0.011480 44.1556 0.00e+00 *** ## total_bc_limit9405&lt;total_bc_limit&lt;=11360 0.354744 0.012379 28.6562 1.34e-180 *** ## total_bc_limittotal_bc_limit=NA NA NA NA NA ## total_bc_limit29471&lt;total_bc_limit&lt;=34756 0.733224 0.015208 48.2117 0.00e+00 *** ## total_bc_limit47175&lt;total_bc_limit&lt;=1105500 0.993462 0.015229 65.2335 0.00e+00 *** ## total_bc_limit11360&lt;total_bc_limit&lt;=13970 0.430396 0.012023 35.7971 1.23e-280 *** ## total_bc_limit24806&lt;total_bc_limit&lt;=29471 0.683273 0.014328 47.6872 0.00e+00 *** ## total_bc_limit18174&lt;total_bc_limit&lt;=20950 0.570324 0.013874 41.1086 0.00e+00 *** ## issue_d2-Inf&lt;issue_d2&lt;=189.062 0.015175 0.014364 1.0565 2.91e-01 ## issue_d2215.111&lt;issue_d2&lt;=258.674 NA NA NA NA ## issue_d2258.674&lt;issue_d2&lt;=277.778 NA NA NA NA ## issue_d2200.694&lt;issue_d2&lt;=215.111 NA NA NA NA ## issue_d2315.062&lt;issue_d2&lt;=357.84 NA NA NA NA ## issue_d2189.062&lt;issue_d2&lt;=200.694 NA NA NA NA ## issue_d3-Inf&lt;issue_d3&lt;=2599.609 NA NA NA NA ## issue_d33154.963&lt;issue_d3&lt;=4160.334 NA NA NA NA ## issue_d34160.334&lt;issue_d3&lt;=4629.63 NA NA NA NA ## issue_d32843.171&lt;issue_d3&lt;=3154.963 NA NA NA NA ## issue_d35592.359&lt;issue_d3&lt;=6769.145 NA NA NA NA ## issue_d32599.609&lt;issue_d3&lt;=2843.171 NA NA NA NA ## ## ------------------------------------------------------------------- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## --- ## null df: 1045083; null deviance: 1048231; ## residuals df: 1044916; residuals deviance: 976701.2; ## # obs.: 1045084; # non-zero weighted obs.: 1045084; ## AIC: 977037.2; log Likelihood: -488350.6; ## RSS: 1043064; dispersion: 1; iterations: 5; ## rank: 168; max tolerance: 4.98e-09; convergence: TRUE. # There are a number of NA estimates that need to be removed by removing indivual bins length( which(is.na(summary(SGLM_C_train)$coefficient$Estimate)) ) ## [1] 28 saveRDS(SGLM_C_train, &quot;datasets/SGLM_C_train.rds&quot;) 3.4.3.2 GLM on bins gc(full = TRUE) ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 2836626 151.5 6816128 364.1 6816128 364.1 ## Vcells 453205208 3457.7 1382206584 10545.4 1826494161 13935.1 # About 700 sec wall-time to complete training dataset # The dataset is the sample less duplicate, less zero-ed columns { doMC::registerDoMC(cores = 1) # Too many processes push over 32GB startTime &lt;- proc.time() loansData &lt;- loanSampleBins SGLM_B_train &lt;- speedglm::speedglm(isGoodLoan ~ ., data = loansData, family = binomial()) doMC::registerDoMC(cores = NULL) cat(proc.time() - startTime, &quot;\\n&quot;) } ## 168.02 13.458 226.813 0 0 saveRDS(SGLM_B_train, &quot;datasets/SGLM_B_train.rds&quot;) # There are a number of NA estimates that need to be removed by removing indivual bins speedglm:::summary.speedglm(SGLM_B_train)$coefficients %&gt;% as.data.frame() %&gt;% rownames_to_column(var = &quot;binName&quot;) %&gt;% filter(is.na(Estimate)) %&gt;% slice(1:10) ## binName Estimate Std. Error z value Pr(&gt;|z|) ## 1 `(loan_amnt) 28000&lt;loan_amnt&lt;=40000` NA NA NA NA ## 2 `(verification_status) verification_status=Verified` NA NA NA NA ## 3 `(issue_d) 17.75&lt;issue_d&lt;=18.917` NA NA NA NA ## 4 `(dti) dti=NA` NA NA NA NA ## 5 `(inq_last_6mths) inq_last_6mths=NA` NA NA NA NA ## 6 `(revol_util) revol_util=NA` NA NA NA NA ## 7 `(open_rv_12m) open_rv_12m=NA` NA NA NA NA ## 8 `(open_rv_24m) 5&lt;open_rv_24m&lt;=53` NA NA NA NA ## 9 `(open_rv_24m) open_rv_24m=NA` NA NA NA NA ## 10 `(max_bal_bc) 7905&lt;max_bal_bc&lt;=776843` NA NA NA NA speedglm:::summary.speedglm(SGLM_B_train)$coefficients %&gt;% as.data.frame() %&gt;% rownames_to_column(var = &quot;binName&quot;) %&gt;% rename(p = &quot;Pr(&gt;|z|)&quot;, z = &quot;z value&quot;) %&gt;% arrange(desc(z)) %&gt;% slice(1:10) ## binName Estimate Std. Error z p ## 1 `(loan_amnt) 3500&lt;loan_amnt&lt;=9000` 0.9848386 0.0108316 90.9228 0.00e+00 ## 2 `(loan_amnt) -Inf&lt;loan_amnt&lt;=3500` 1.1617352 0.0152225 76.3171 0.00e+00 ## 3 `(loan_amnt) 9000&lt;loan_amnt&lt;=10000` 0.7380869 0.0124309 59.3751 0.00e+00 ## 4 `(loan_amnt) 10000&lt;loan_amnt&lt;=12000` 0.6002188 0.0121587 49.3652 0.00e+00 ## 5 `(verification_status) verification_status=Not Verified` 0.2840857 0.0070796 40.1275 0.00e+00 ## 6 `(loan_amnt) 14975&lt;loan_amnt&lt;=15000` 0.5501235 0.0142603 38.5774 0.00e+00 ## 7 `(loan_amnt) 12000&lt;loan_amnt&lt;=14975` 0.5037774 0.0131783 38.2277 0.00e+00 ## 8 `(num_tl_op_past_12m) 0&lt;num_tl_op_past_12m&lt;=1` 0.3467503 0.0121796 28.4698 2.77e-178 ## 9 `(loan_amnt) 15000&lt;loan_amnt&lt;=17000` 0.3762410 0.0135998 27.6652 1.83e-168 ## 10 `(mort_acc) 5&lt;mort_acc&lt;=47` 1.0623545 0.0423491 25.0856 7.14e-139 # Does the model throw NAs? They are produced not only for identical variables, but also co-linear # combinations. Let us select those variables: NAsFirstTraining &lt;- # Take the results (just the estimated coefficients) from the model tibble( name = rownames(summary(SGLM_B_train)$coefficient), estimate = summary(SGLM_B_train)$coefficient$Estimate ) %&gt;% # Reformat the names to be the same as in the bins mutate(name = stringr::str_remove_all(name, &quot;\\`&quot;)) %&gt;% # Make sure that repsonse is not deleted by mistake and list all NAs filter(name != &quot;isGoodLoan&quot; &amp; is.na(estimate)) NAsFirstTraining &lt;- NAsFirstTraining$name 3.4.4 Second training gc(full = TRUE) ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 2838703 151.7 6816128 364.1 6816128 364.1 ## Vcells 453263099 3458.2 1326982320 10124.1 1826494161 13935.1 # Start the model training again { startTime &lt;- proc.time() doMC::registerDoMC(cores = 2) # Too many processes push over 32GB if more than 2 loansData &lt;- loanSampleBins %&gt;% select(-one_of( c(duplicateNames, zeroColumnsNames, NAsFirstTraining))) SGLM_B_retrain &lt;- speedglm::speedglm(isGoodLoan ~ ., data = loansData, family = binomial()) doMC::registerDoMC(cores = NULL) cat(proc.time() - startTime) } ## 146.937 15.37 217.314 0 0 saveRDS(SGLM_B_retrain, &quot;datasets/SGLM_B_retrain.rds&quot;) speedglm:::summary.speedglm(SGLM_B_retrain)$coefficients %&gt;% as.data.frame() %&gt;% rownames_to_column(var = &quot;binName&quot;) %&gt;% rename(p = &quot;Pr(&gt;|z|)&quot;, z = &quot;z value&quot;) %&gt;% arrange(desc(z)) %&gt;% slice(1:10) ## binName Estimate Std. Error z p ## 1 `(loan_amnt) 3500&lt;loan_amnt&lt;=9000` 0.9848386 0.0108316 90.9228 0.00e+00 ## 2 `(loan_amnt) -Inf&lt;loan_amnt&lt;=3500` 1.1617352 0.0152225 76.3171 0.00e+00 ## 3 `(loan_amnt) 9000&lt;loan_amnt&lt;=10000` 0.7380869 0.0124309 59.3751 0.00e+00 ## 4 `(loan_amnt) 10000&lt;loan_amnt&lt;=12000` 0.6002188 0.0121587 49.3652 0.00e+00 ## 5 `(verification_status) verification_status=Not Verified` 0.2840857 0.0070796 40.1275 0.00e+00 ## 6 `(loan_amnt) 14975&lt;loan_amnt&lt;=15000` 0.5501235 0.0142603 38.5774 0.00e+00 ## 7 `(loan_amnt) 12000&lt;loan_amnt&lt;=14975` 0.5037774 0.0131783 38.2277 0.00e+00 ## 8 `(num_tl_op_past_12m) 0&lt;num_tl_op_past_12m&lt;=1` 0.3467503 0.0121796 28.4698 2.77e-178 ## 9 `(loan_amnt) 15000&lt;loan_amnt&lt;=17000` 0.3762410 0.0135998 27.6652 1.83e-168 ## 10 `(mort_acc) 5&lt;mort_acc&lt;=47` 1.0623545 0.0423491 25.0856 7.14e-139 # Just in case, new NAs popped up. Then select variables whose significance value is under 2 sigmas. NAsSecondTraining &lt;- tibble( name = rownames(summary(SGLM_B_retrain)$coefficient), estimate = summary(SGLM_B_retrain)$coefficient$Estimate, zValue = abs(summary(SGLM_B_retrain)$coefficient$&quot;z value&quot;) ) %&gt;% mutate(name = stringr::str_remove_all(name, &quot;\\`&quot;)) %&gt;% filter(name != &quot;isGoodLoan&quot;) %&gt;% # Remove stray NAs or anything less than 2 sigmas filter(is.na(estimate) | zValue &lt; 2) NAsSecondTraining &lt;- NAsSecondTraining$name 3.4.5 Third training gc(full = TRUE) ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 2839877 151.7 6816128 364.1 6816128 364.1 ## Vcells 453307703 3458.5 1273967028 9719.6 1826494161 13935.1 # Start the model training again. About 350 sec. { startTime &lt;- proc.time() doMC::registerDoMC(cores = 2) loansData &lt;- loanSampleBins %&gt;% select(-one_of( c( duplicateNames, zeroColumnsNames, NAsFirstTraining, NAsSecondTraining ))) SGLM_B_reretrain &lt;- speedglm::speedglm(isGoodLoan ~ ., data = loansData, family = binomial()) doMC::registerDoMC(cores = NULL) cat(proc.time() - startTime) } ## 51.353 4.384 72.893 0 0 saveRDS(SGLM_B_reretrain, &quot;datasets/SGLM_B_reretrain.rds&quot;) speedglm:::summary.speedglm(SGLM_B_reretrain)$coefficients %&gt;% as.data.frame() %&gt;% rownames_to_column(var = &quot;binName&quot;) %&gt;% rename(p = &quot;Pr(&gt;|z|)&quot;, z = &quot;z value&quot;) %&gt;% arrange(desc(z)) %&gt;% slice(1:10) ## binName Estimate Std. Error z p ## 1 `(loan_amnt) 3500&lt;loan_amnt&lt;=9000` 0.9383885 0.0107265 87.4833 0.00e+00 ## 2 `(loan_amnt) -Inf&lt;loan_amnt&lt;=3500` 1.1079606 0.0151211 73.2723 0.00e+00 ## 3 `(loan_amnt) 9000&lt;loan_amnt&lt;=10000` 0.7026804 0.0123379 56.9531 0.00e+00 ## 4 `(loan_amnt) 10000&lt;loan_amnt&lt;=12000` 0.5616891 0.0120636 46.5606 0.00e+00 ## 5 `(verification_status) verification_status=Not Verified` 0.3225105 0.0070171 45.9606 0.00e+00 ## 6 `(num_tl_op_past_12m) -Inf&lt;num_tl_op_past_12m&lt;=0` 0.5700935 0.0133125 42.8238 0.00e+00 ## 7 `(num_tl_op_past_12m) 0&lt;num_tl_op_past_12m&lt;=1` 0.4623390 0.0112317 41.1636 0.00e+00 ## 8 `(loan_amnt) 14975&lt;loan_amnt&lt;=15000` 0.5296854 0.0141852 37.3408 3.57e-305 ## 9 `(num_rev_tl_bal_gt_0) -Inf&lt;num_rev_tl_bal_gt_0&lt;=2` 0.4810422 0.0129686 37.0927 3.68e-301 ## 10 `(loan_amnt) 12000&lt;loan_amnt&lt;=14975` 0.4583936 0.0130818 35.0405 5.44e-269 NAsThirdTraining &lt;- tibble( name = rownames(summary(SGLM_B_reretrain)$coefficient), estimate = summary(SGLM_B_reretrain)$coefficient$Estimate, zValue = abs(summary(SGLM_B_reretrain)$coefficient$&quot;z value&quot;) ) %&gt;% mutate(name = stringr::str_remove_all(name, &quot;\\`&quot;)) %&gt;% filter(name != &quot;isGoodLoan&quot;) %&gt;% # Remove stray NAs (Shouldn&#39;t be any) or less than 2 sigmas filter(is.na(estimate) | zValue &lt; 2) NAsThirdTraining &lt;- NAsThirdTraining$name speedglm:::summary.speedglm(SGLM_B_train) ## Generalized Linear Model of class &#39;speedglm&#39;: ## ## Call: speedglm::speedglm(formula = isGoodLoan ~ ., data = loansData, family = binomial()) ## ## Coefficients: ## ------------------------------------------------------------------ ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.611369 0.757976 0.8066 4.20e-01 ## `(loan_amnt) -Inf&lt;loan_amnt&lt;=3500` 1.161735 0.015222 76.3171 0.00e+00 *** ## `(loan_amnt) 3500&lt;loan_amnt&lt;=9000` 0.984839 0.010832 90.9228 0.00e+00 *** ## `(loan_amnt) 9000&lt;loan_amnt&lt;=10000` 0.738087 0.012431 59.3751 0.00e+00 *** ## `(loan_amnt) 10000&lt;loan_amnt&lt;=12000` 0.600219 0.012159 49.3652 0.00e+00 *** ## `(loan_amnt) 12000&lt;loan_amnt&lt;=14975` 0.503777 0.013178 38.2277 0.00e+00 *** ## `(loan_amnt) 14975&lt;loan_amnt&lt;=15000` 0.550123 0.014260 38.5774 0.00e+00 *** ## `(loan_amnt) 15000&lt;loan_amnt&lt;=17000` 0.376241 0.013600 27.6652 1.83e-168 *** ## `(loan_amnt) 17000&lt;loan_amnt&lt;=19950` 0.278316 0.013441 20.7065 3.03e-95 *** ## `(loan_amnt) 19950&lt;loan_amnt&lt;=28000` 0.238928 0.010063 23.7424 1.32e-124 *** ## `(loan_amnt) 28000&lt;loan_amnt&lt;=40000` NA NA NA NA ## `(verification_status) verification_status=Not Verified` 0.284086 0.007080 40.1275 0.00e+00 *** ## `(verification_status) verification_status=Source Verified` 0.071564 0.006072 11.7861 4.60e-32 *** ## `(verification_status) verification_status=Verified` NA NA NA NA ## `(issue_d) -Inf&lt;issue_d&lt;=14.167` 0.208104 0.020191 10.3070 6.55e-25 *** ## `(issue_d) 14.167&lt;issue_d&lt;=14.667` 0.012499 0.018921 0.6606 5.09e-01 ## `(issue_d) 14.667&lt;issue_d&lt;=16.083` -0.058014 0.015928 -3.6423 2.70e-04 *** ## `(issue_d) 16.083&lt;issue_d&lt;=16.667` -0.419787 0.013772 -30.4804 4.74e-204 *** ## `(issue_d) 16.667&lt;issue_d&lt;=17.75` -0.362928 0.013544 -26.7952 3.67e-158 *** ## `(issue_d) 17.75&lt;issue_d&lt;=18.917` NA NA NA NA ## `(dti) -Inf&lt;dti&lt;=0.097` 0.257596 0.164234 1.5685 1.17e-01 ## `(dti) 0.097&lt;dti&lt;=0.122` 0.230688 0.164341 1.4037 1.60e-01 ## `(dti) 0.122&lt;dti&lt;=0.143` 0.197998 0.164336 1.2048 2.28e-01 ## `(dti) 0.143&lt;dti&lt;=0.156` 0.137838 0.164463 0.8381 4.02e-01 ## `(dti) 0.156&lt;dti&lt;=0.178` 0.098720 0.164307 0.6008 5.48e-01 ## `(dti) 0.178&lt;dti&lt;=0.192` 0.057576 0.164427 0.3502 7.26e-01 ## `(dti) 0.192&lt;dti&lt;=0.217` 0.006734 0.164296 0.0410 9.67e-01 ## `(dti) 0.217&lt;dti&lt;=0.236` -0.072632 0.164370 -0.4419 6.59e-01 ## `(dti) 0.236&lt;dti&lt;=0.254` -0.115296 0.164416 -0.7012 4.83e-01 ## `(dti) 0.254&lt;dti&lt;=0.272` -0.176954 0.164443 -1.0761 2.82e-01 ## `(dti) 0.272&lt;dti&lt;=0.299` -0.234347 0.164382 -1.4256 1.54e-01 ## `(dti) 0.299&lt;dti&lt;=9.99` -0.399978 0.164280 -2.4347 1.49e-02 * ## `(dti) dti=NA` NA NA NA NA ## `(inq_last_6mths) -Inf&lt;inq_last_6mths&lt;=0` -0.155668 0.746685 -0.2085 8.35e-01 ## `(inq_last_6mths) 0&lt;inq_last_6mths&lt;=1` -0.261259 0.746688 -0.3499 7.26e-01 ## `(inq_last_6mths) 1&lt;inq_last_6mths&lt;=2` -0.357904 0.746709 -0.4793 6.32e-01 ## `(inq_last_6mths) 2&lt;inq_last_6mths&lt;=33` -0.504281 0.746733 -0.6753 4.99e-01 ## `(inq_last_6mths) inq_last_6mths=NA` NA NA NA NA ## `(revol_util) -Inf&lt;revol_util&lt;=0.147` 0.325272 0.105784 3.0749 2.11e-03 ** ## `(revol_util) 0.147&lt;revol_util&lt;=0.217` 0.343442 0.106003 3.2399 1.20e-03 ** ## `(revol_util) 0.217&lt;revol_util&lt;=0.316` 0.335985 0.105556 3.1830 1.46e-03 ** ## `(revol_util) 0.316&lt;revol_util&lt;=0.388` 0.296206 0.105563 2.8060 5.02e-03 ** ## `(revol_util) 0.388&lt;revol_util&lt;=0.479` 0.244804 0.105419 2.3222 2.02e-02 * ## `(revol_util) 0.479&lt;revol_util&lt;=0.569` 0.208576 0.105384 1.9792 4.78e-02 * ## `(revol_util) 0.569&lt;revol_util&lt;=0.718` 0.176574 0.105285 1.6771 9.35e-02 . ## `(revol_util) 0.718&lt;revol_util&lt;=0.869` 0.109122 0.105317 1.0361 3.00e-01 ## `(revol_util) 0.869&lt;revol_util&lt;=3.666` 0.015509 0.105422 0.1471 8.83e-01 ## `(revol_util) revol_util=NA` NA NA NA NA ## `(open_rv_12m) -Inf&lt;open_rv_12m&lt;=0` -0.297576 0.022644 -13.1415 1.91e-39 *** ## `(open_rv_12m) 0&lt;open_rv_12m&lt;=1` -0.225478 0.020716 -10.8841 1.37e-27 *** ## `(open_rv_12m) 1&lt;open_rv_12m&lt;=2` -0.143146 0.020217 -7.0805 1.44e-12 *** ## `(open_rv_12m) 2&lt;open_rv_12m&lt;=28` -0.057224 0.018371 -3.1149 1.84e-03 ** ## `(open_rv_12m) open_rv_12m=NA` NA NA NA NA ## `(open_rv_24m) -Inf&lt;open_rv_24m&lt;=0` 0.177991 0.023177 7.6795 1.60e-14 *** ## `(open_rv_24m) 0&lt;open_rv_24m&lt;=1` 0.264156 0.018018 14.6610 1.15e-48 *** ## `(open_rv_24m) 1&lt;open_rv_24m&lt;=2` 0.223955 0.016594 13.4963 1.64e-41 *** ## `(open_rv_24m) 2&lt;open_rv_24m&lt;=3` 0.139651 0.015792 8.8432 9.30e-19 *** ## `(open_rv_24m) 3&lt;open_rv_24m&lt;=5` 0.092391 0.013802 6.6942 2.17e-11 *** ## `(open_rv_24m) 5&lt;open_rv_24m&lt;=53` NA NA NA NA ## `(open_rv_24m) open_rv_24m=NA` NA NA NA NA ## `(max_bal_bc) -Inf&lt;max_bal_bc&lt;=5122` 0.013343 0.011801 1.1307 2.58e-01 ## `(max_bal_bc) 5122&lt;max_bal_bc&lt;=7905` 0.016355 0.013234 1.2358 2.17e-01 ## `(max_bal_bc) 7905&lt;max_bal_bc&lt;=776843` NA NA NA NA ## `(max_bal_bc) max_bal_bc=NA` NA NA NA NA ## `(avg_cur_bal) -Inf&lt;avg_cur_bal&lt;=8012` 0.949400 0.535525 1.7728 7.63e-02 . ## `(avg_cur_bal) 8012&lt;avg_cur_bal&lt;=11363` 0.941134 0.535580 1.7572 7.89e-02 . ## `(avg_cur_bal) 11363&lt;avg_cur_bal&lt;=14047` 0.917853 0.535633 1.7136 8.66e-02 . ## `(avg_cur_bal) 14047&lt;avg_cur_bal&lt;=21129` 0.881077 0.535589 1.6451 1.00e-01 ## `(avg_cur_bal) 21129&lt;avg_cur_bal&lt;=27395` 0.858706 0.535650 1.6031 1.09e-01 ## `(avg_cur_bal) 27395&lt;avg_cur_bal&lt;=41609` 0.860674 0.535660 1.6068 1.08e-01 ## `(avg_cur_bal) 41609&lt;avg_cur_bal&lt;=800008` 0.872631 0.535693 1.6290 1.03e-01 ## `(avg_cur_bal) avg_cur_bal=NA` NA NA NA NA ## `(bc_open_to_buy) -Inf&lt;bc_open_to_buy&lt;=0.315` 0.293741 0.089194 3.2933 9.90e-04 *** ## `(bc_open_to_buy) 0.315&lt;bc_open_to_buy&lt;=0.388` 0.321039 0.089784 3.5757 3.49e-04 *** ## `(bc_open_to_buy) 0.388&lt;bc_open_to_buy&lt;=0.461` 0.356318 0.089700 3.9723 7.12e-05 *** ## `(bc_open_to_buy) 0.461&lt;bc_open_to_buy&lt;=0.539` 0.381208 0.089608 4.2542 2.10e-05 *** ## `(bc_open_to_buy) 0.539&lt;bc_open_to_buy&lt;=0.725` 0.436152 0.089276 4.8855 1.03e-06 *** ## `(bc_open_to_buy) 0.725&lt;bc_open_to_buy&lt;=0.876` 0.519055 0.089279 5.8139 6.11e-09 *** ## `(bc_open_to_buy) 0.876&lt;bc_open_to_buy&lt;=0.919` 0.494536 0.089687 5.5140 3.51e-08 *** ## `(bc_open_to_buy) 0.919&lt;bc_open_to_buy&lt;=0.979` 0.374976 0.089520 4.1888 2.80e-05 *** ## `(bc_open_to_buy) 0.979&lt;bc_open_to_buy&lt;=3.396` 0.192427 0.089901 2.1404 3.23e-02 * ## `(bc_open_to_buy) bc_open_to_buy=NA` NA NA NA NA ## `(bc_util) -Inf&lt;bc_util&lt;=31.5` NA NA NA NA ## `(bc_util) 31.5&lt;bc_util&lt;=38.8` NA NA NA NA ## `(bc_util) 38.8&lt;bc_util&lt;=46.1` NA NA NA NA ## `(bc_util) 46.1&lt;bc_util&lt;=53.9` NA NA NA NA ## `(bc_util) 53.9&lt;bc_util&lt;=72.5` NA NA NA NA ## `(bc_util) 72.5&lt;bc_util&lt;=87.6` NA NA NA NA ## `(bc_util) 87.6&lt;bc_util&lt;=91.9` NA NA NA NA ## `(bc_util) 91.9&lt;bc_util&lt;=97.9` NA NA NA NA ## `(bc_util) 97.9&lt;bc_util&lt;=339.6` NA NA NA NA ## `(bc_util) bc_util=NA` NA NA NA NA ## `(mo_sin_old_rev_tl_op) -Inf&lt;mo_sin_old_rev_tl_op&lt;=58` 8.237357 16.181311 0.5091 6.11e-01 ## `(mo_sin_old_rev_tl_op) 58&lt;mo_sin_old_rev_tl_op&lt;=82` 8.363960 16.181312 0.5169 6.05e-01 ## `(mo_sin_old_rev_tl_op) 82&lt;mo_sin_old_rev_tl_op&lt;=132` 8.442870 16.181309 0.5218 6.02e-01 ## `(mo_sin_old_rev_tl_op) 132&lt;mo_sin_old_rev_tl_op&lt;=143` 8.481488 16.181312 0.5242 6.00e-01 ## `(mo_sin_old_rev_tl_op) 143&lt;mo_sin_old_rev_tl_op&lt;=154` 8.497112 16.181312 0.5251 6.00e-01 ## `(mo_sin_old_rev_tl_op) 154&lt;mo_sin_old_rev_tl_op&lt;=212` 8.531072 16.181309 0.5272 5.98e-01 ## `(mo_sin_old_rev_tl_op) 212&lt;mo_sin_old_rev_tl_op&lt;=852` 8.575596 16.181309 0.5300 5.96e-01 ## `(mo_sin_old_rev_tl_op) mo_sin_old_rev_tl_op=NA` NA NA NA NA ## `(mo_sin_rcnt_rev_tl_op) -Inf&lt;mo_sin_rcnt_rev_tl_op&lt;=1` 0.067431 0.024585 2.7427 6.09e-03 ** ## `(mo_sin_rcnt_rev_tl_op) 1&lt;mo_sin_rcnt_rev_tl_op&lt;=2` 0.159570 0.022099 7.2206 5.18e-13 *** ## `(mo_sin_rcnt_rev_tl_op) 2&lt;mo_sin_rcnt_rev_tl_op&lt;=3` 0.109213 0.021447 5.0923 3.54e-07 *** ## `(mo_sin_rcnt_rev_tl_op) 3&lt;mo_sin_rcnt_rev_tl_op&lt;=4` 0.065488 0.021375 3.0638 2.19e-03 ** ## `(mo_sin_rcnt_rev_tl_op) 4&lt;mo_sin_rcnt_rev_tl_op&lt;=7` 0.020980 0.017764 1.1810 2.38e-01 ## `(mo_sin_rcnt_rev_tl_op) 7&lt;mo_sin_rcnt_rev_tl_op&lt;=9` -0.044420 0.018650 -2.3817 1.72e-02 * ## `(mo_sin_rcnt_rev_tl_op) 9&lt;mo_sin_rcnt_rev_tl_op&lt;=16` -0.087601 0.015866 -5.5213 3.36e-08 *** ## `(mo_sin_rcnt_rev_tl_op) 16&lt;mo_sin_rcnt_rev_tl_op&lt;=20` -0.089226 0.018602 -4.7966 1.61e-06 *** ## `(mo_sin_rcnt_rev_tl_op) 20&lt;mo_sin_rcnt_rev_tl_op&lt;=28` -0.035702 0.016195 -2.2046 2.75e-02 * ## `(mo_sin_rcnt_rev_tl_op) 28&lt;mo_sin_rcnt_rev_tl_op&lt;=438` NA NA NA NA ## `(mo_sin_rcnt_rev_tl_op) mo_sin_rcnt_rev_tl_op=NA` NA NA NA NA ## `(mo_sin_rcnt_tl) -Inf&lt;mo_sin_rcnt_tl&lt;=1` -9.267616 16.190843 -0.5724 5.67e-01 ## `(mo_sin_rcnt_tl) 1&lt;mo_sin_rcnt_tl&lt;=2` -9.310900 16.190839 -0.5751 5.65e-01 ## `(mo_sin_rcnt_tl) 2&lt;mo_sin_rcnt_tl&lt;=3` -9.299484 16.190839 -0.5744 5.66e-01 ## `(mo_sin_rcnt_tl) 3&lt;mo_sin_rcnt_tl&lt;=4` -9.234814 16.190839 -0.5704 5.68e-01 ## `(mo_sin_rcnt_tl) 4&lt;mo_sin_rcnt_tl&lt;=5` -9.188853 16.190838 -0.5675 5.70e-01 ## `(mo_sin_rcnt_tl) 5&lt;mo_sin_rcnt_tl&lt;=7` -9.194903 16.190837 -0.5679 5.70e-01 ## `(mo_sin_rcnt_tl) 7&lt;mo_sin_rcnt_tl&lt;=9` -9.154435 16.190838 -0.5654 5.72e-01 ## `(mo_sin_rcnt_tl) 9&lt;mo_sin_rcnt_tl&lt;=11` -9.119918 16.190837 -0.5633 5.73e-01 ## `(mo_sin_rcnt_tl) 11&lt;mo_sin_rcnt_tl&lt;=14` -9.136855 16.190842 -0.5643 5.73e-01 ## `(mo_sin_rcnt_tl) 14&lt;mo_sin_rcnt_tl&lt;=21` -9.089693 16.190844 -0.5614 5.75e-01 ## `(mo_sin_rcnt_tl) 21&lt;mo_sin_rcnt_tl&lt;=314` -9.139331 16.190850 -0.5645 5.72e-01 ## `(mo_sin_rcnt_tl) mo_sin_rcnt_tl=NA` NA NA NA NA ## `(mort_acc) -Inf&lt;mort_acc&lt;=0` 0.802754 0.040241 19.9489 1.53e-88 *** ## `(mort_acc) 0&lt;mort_acc&lt;=1` 0.871485 0.040707 21.4087 1.11e-101 *** ## `(mort_acc) 1&lt;mort_acc&lt;=2` 0.948614 0.040890 23.1989 4.67e-119 *** ## `(mort_acc) 2&lt;mort_acc&lt;=3` 0.980585 0.041179 23.8127 2.47e-125 *** ## `(mort_acc) 3&lt;mort_acc&lt;=5` 1.012940 0.041149 24.6162 8.48e-134 *** ## `(mort_acc) 5&lt;mort_acc&lt;=47` 1.062355 0.042349 25.0856 7.14e-139 *** ## `(mort_acc) mort_acc=NA` NA NA NA NA ## `(mths_since_recent_bc) -Inf&lt;mths_since_recent_bc&lt;=2` -0.609738 0.085215 -7.1553 8.35e-13 *** ## `(mths_since_recent_bc) 2&lt;mths_since_recent_bc&lt;=4` -0.537903 0.085140 -6.3179 2.65e-10 *** ## `(mths_since_recent_bc) 4&lt;mths_since_recent_bc&lt;=7` -0.484915 0.084918 -5.7104 1.13e-08 *** ## `(mths_since_recent_bc) 7&lt;mths_since_recent_bc&lt;=15` -0.438846 0.084588 -5.1880 2.13e-07 *** ## `(mths_since_recent_bc) 15&lt;mths_since_recent_bc&lt;=21` -0.390850 0.084748 -4.6119 3.99e-06 *** ## `(mths_since_recent_bc) 21&lt;mths_since_recent_bc&lt;=28` -0.349616 0.084838 -4.1210 3.77e-05 *** ## `(mths_since_recent_bc) 28&lt;mths_since_recent_bc&lt;=35` -0.326274 0.084880 -3.8439 1.21e-04 *** ## `(mths_since_recent_bc) 35&lt;mths_since_recent_bc&lt;=56` -0.263667 0.084531 -3.1192 1.81e-03 ** ## `(mths_since_recent_bc) 56&lt;mths_since_recent_bc&lt;=639` -0.170697 0.083773 -2.0376 4.16e-02 * ## `(mths_since_recent_bc) mths_since_recent_bc=NA` NA NA NA NA ## `(mths_since_recent_inq) -Inf&lt;mths_since_recent_inq&lt;=0` -0.293984 0.014706 -19.9906 6.65e-89 *** ## `(mths_since_recent_inq) 0&lt;mths_since_recent_inq&lt;=1` -0.230252 0.014271 -16.1338 1.48e-58 *** ## `(mths_since_recent_inq) 1&lt;mths_since_recent_inq&lt;=2` -0.141297 0.014900 -9.4831 2.47e-21 *** ## `(mths_since_recent_inq) 2&lt;mths_since_recent_inq&lt;=3` -0.107995 0.015177 -7.1155 1.12e-12 *** ## `(mths_since_recent_inq) 3&lt;mths_since_recent_inq&lt;=4` -0.082146 0.015504 -5.2983 1.17e-07 *** ## `(mths_since_recent_inq) 4&lt;mths_since_recent_inq&lt;=5` -0.078016 0.015939 -4.8947 9.84e-07 *** ## `(mths_since_recent_inq) 5&lt;mths_since_recent_inq&lt;=8` -0.110854 0.012278 -9.0289 1.73e-19 *** ## `(mths_since_recent_inq) 8&lt;mths_since_recent_inq&lt;=10` -0.108483 0.013954 -7.7746 7.57e-15 *** ## `(mths_since_recent_inq) 10&lt;mths_since_recent_inq&lt;=16` -0.094748 0.012128 -7.8122 5.62e-15 *** ## `(mths_since_recent_inq) 16&lt;mths_since_recent_inq&lt;=25` -0.058384 0.013707 -4.2595 2.05e-05 *** ## `(mths_since_recent_inq) mths_since_recent_inq=NA` NA NA NA NA ## `(num_actv_rev_tl) -Inf&lt;num_actv_rev_tl&lt;=2` 0.116954 0.063720 1.8354 6.64e-02 . ## `(num_actv_rev_tl) 2&lt;num_actv_rev_tl&lt;=3` 0.147969 0.052555 2.8155 4.87e-03 ** ## `(num_actv_rev_tl) 3&lt;num_actv_rev_tl&lt;=4` 0.100821 0.046787 2.1549 3.12e-02 * ## `(num_actv_rev_tl) 4&lt;num_actv_rev_tl&lt;=5` 0.044894 0.043170 1.0399 2.98e-01 ## `(num_actv_rev_tl) 5&lt;num_actv_rev_tl&lt;=6` 0.072634 0.040943 1.7740 7.61e-02 . ## `(num_actv_rev_tl) 6&lt;num_actv_rev_tl&lt;=7` -0.000536 0.039420 -0.0136 9.89e-01 ## `(num_actv_rev_tl) 7&lt;num_actv_rev_tl&lt;=8` -0.007841 0.038113 -0.2057 8.37e-01 ## `(num_actv_rev_tl) 8&lt;num_actv_rev_tl&lt;=10` -0.007639 0.032398 -0.2358 8.14e-01 ## `(num_actv_rev_tl) 10&lt;num_actv_rev_tl&lt;=63` NA NA NA NA ## `(num_actv_rev_tl) num_actv_rev_tl=NA` NA NA NA NA ## `(num_rev_tl_bal_gt_0) -Inf&lt;num_rev_tl_bal_gt_0&lt;=2` 0.333749 0.064018 5.2134 1.85e-07 *** ## `(num_rev_tl_bal_gt_0) 2&lt;num_rev_tl_bal_gt_0&lt;=3` 0.264443 0.052877 5.0011 5.70e-07 *** ## `(num_rev_tl_bal_gt_0) 3&lt;num_rev_tl_bal_gt_0&lt;=4` 0.250602 0.047162 5.3137 1.07e-07 *** ## `(num_rev_tl_bal_gt_0) 4&lt;num_rev_tl_bal_gt_0&lt;=5` 0.263765 0.043580 6.0524 1.43e-09 *** ## `(num_rev_tl_bal_gt_0) 5&lt;num_rev_tl_bal_gt_0&lt;=6` 0.180500 0.041356 4.3645 1.27e-05 *** ## `(num_rev_tl_bal_gt_0) 6&lt;num_rev_tl_bal_gt_0&lt;=7` 0.215620 0.039877 5.4072 6.40e-08 *** ## `(num_rev_tl_bal_gt_0) 7&lt;num_rev_tl_bal_gt_0&lt;=8` 0.173516 0.038619 4.4930 7.02e-06 *** ## `(num_rev_tl_bal_gt_0) 8&lt;num_rev_tl_bal_gt_0&lt;=10` 0.128285 0.032900 3.8992 9.65e-05 *** ## `(num_rev_tl_bal_gt_0) 10&lt;num_rev_tl_bal_gt_0&lt;=45` NA NA NA NA ## `(num_rev_tl_bal_gt_0) num_rev_tl_bal_gt_0=NA` NA NA NA NA ## `(num_tl_op_past_12m) -Inf&lt;num_tl_op_past_12m&lt;=0` 0.370595 0.024070 15.3966 1.72e-53 *** ## `(num_tl_op_past_12m) 0&lt;num_tl_op_past_12m&lt;=1` 0.346750 0.012180 28.4698 2.77e-178 *** ## `(num_tl_op_past_12m) 1&lt;num_tl_op_past_12m&lt;=2` 0.251521 0.011189 22.4796 6.57e-112 *** ## `(num_tl_op_past_12m) 2&lt;num_tl_op_past_12m&lt;=3` 0.142006 0.010785 13.1664 1.37e-39 *** ## `(num_tl_op_past_12m) 3&lt;num_tl_op_past_12m&lt;=4` 0.056903 0.011245 5.0604 4.18e-07 *** ## `(num_tl_op_past_12m) 4&lt;num_tl_op_past_12m&lt;=30` NA NA NA NA ## `(num_tl_op_past_12m) num_tl_op_past_12m=NA` NA NA NA NA ## `(percent_bc_gt_75) -Inf&lt;percent_bc_gt_75&lt;=0.034` 0.036402 0.105889 0.3438 7.31e-01 ## `(percent_bc_gt_75) 0.034&lt;percent_bc_gt_75&lt;=0.259` -0.092241 0.106188 -0.8687 3.85e-01 ## `(percent_bc_gt_75) 0.259&lt;percent_bc_gt_75&lt;=0.346` -0.142432 0.106288 -1.3401 1.80e-01 ## `(percent_bc_gt_75) 0.346&lt;percent_bc_gt_75&lt;=0.522` -0.209492 0.106061 -1.9752 4.82e-02 * ## `(percent_bc_gt_75) 0.522&lt;percent_bc_gt_75&lt;=0.682` -0.277961 0.106214 -2.6170 8.87e-03 ** ## `(percent_bc_gt_75) 0.682&lt;percent_bc_gt_75&lt;=0.958` -0.345400 0.106306 -3.2491 1.16e-03 ** ## `(percent_bc_gt_75) 0.958&lt;percent_bc_gt_75&lt;=1` -0.200975 0.106012 -1.8958 5.80e-02 . ## `(percent_bc_gt_75) percent_bc_gt_75=NA` NA NA NA NA ## `(tot_hi_cred_lim) -Inf&lt;tot_hi_cred_lim&lt;=102535` -0.775532 0.023321 -33.2549 1.73e-242 *** ## `(tot_hi_cred_lim) 102535&lt;tot_hi_cred_lim&lt;=131793` -0.580656 0.022895 -25.3621 6.62e-142 *** ## `(tot_hi_cred_lim) 131793&lt;tot_hi_cred_lim&lt;=179071` -0.539407 0.021021 -25.6606 3.22e-145 *** ## `(tot_hi_cred_lim) 179071&lt;tot_hi_cred_lim&lt;=208761` -0.432007 0.021429 -20.1595 2.22e-90 *** ## `(tot_hi_cred_lim) 208761&lt;tot_hi_cred_lim&lt;=242055` -0.371150 0.020816 -17.8298 4.15e-71 *** ## `(tot_hi_cred_lim) 242055&lt;tot_hi_cred_lim&lt;=298516` -0.288759 0.019181 -15.0543 3.23e-51 *** ## `(tot_hi_cred_lim) 298516&lt;tot_hi_cred_lim&lt;=383997` -0.211688 0.018212 -11.6238 3.12e-31 *** ## `(tot_hi_cred_lim) 383997&lt;tot_hi_cred_lim&lt;=487388` -0.149676 0.018865 -7.9342 2.12e-15 *** ## `(tot_hi_cred_lim) 487388&lt;tot_hi_cred_lim&lt;=9999999` NA NA NA NA ## `(tot_hi_cred_lim) tot_hi_cred_lim=NA` NA NA NA NA ## `(total_bc_limit) -Inf&lt;total_bc_limit&lt;=4478` -0.993462 0.015229 -65.2335 0.00e+00 *** ## `(total_bc_limit) 4478&lt;total_bc_limit&lt;=9405` -0.760385 0.013700 -55.5004 0.00e+00 *** ## `(total_bc_limit) 9405&lt;total_bc_limit&lt;=11360` -0.638718 0.015271 -41.8247 0.00e+00 *** ## `(total_bc_limit) 11360&lt;total_bc_limit&lt;=13970` -0.563065 0.014606 -38.5497 0.00e+00 *** ## `(total_bc_limit) 13970&lt;total_bc_limit&lt;=18174` -0.486552 0.013650 -35.6459 2.73e-278 *** ## `(total_bc_limit) 18174&lt;total_bc_limit&lt;=20950` -0.423138 0.015281 -27.6909 8.98e-169 *** ## `(total_bc_limit) 20950&lt;total_bc_limit&lt;=24806` -0.373576 0.014667 -25.4697 4.27e-143 *** ## `(total_bc_limit) 24806&lt;total_bc_limit&lt;=29471` -0.310188 0.014937 -20.7666 8.67e-96 *** ## `(total_bc_limit) 29471&lt;total_bc_limit&lt;=34756` -0.260238 0.015397 -16.9016 4.38e-64 *** ## `(total_bc_limit) 34756&lt;total_bc_limit&lt;=47175` -0.172385 0.013941 -12.3657 4.01e-35 *** ## `(total_bc_limit) 47175&lt;total_bc_limit&lt;=1105500` NA NA NA NA ## `(total_bc_limit) total_bc_limit=NA` NA NA NA NA ## `(issue_d2) -Inf&lt;issue_d2&lt;=189.062` 0.015175 0.014364 1.0565 2.91e-01 ## `(issue_d2) 189.062&lt;issue_d2&lt;=200.694` NA NA NA NA ## `(issue_d2) 200.694&lt;issue_d2&lt;=215.111` NA NA NA NA ## `(issue_d2) 215.111&lt;issue_d2&lt;=258.674` NA NA NA NA ## `(issue_d2) 258.674&lt;issue_d2&lt;=277.778` NA NA NA NA ## `(issue_d2) 277.778&lt;issue_d2&lt;=315.062` NA NA NA NA ## `(issue_d2) 315.062&lt;issue_d2&lt;=357.84` NA NA NA NA ## `(issue_d3) -Inf&lt;issue_d3&lt;=2599.609` NA NA NA NA ## `(issue_d3) 2599.609&lt;issue_d3&lt;=2843.171` NA NA NA NA ## `(issue_d3) 2843.171&lt;issue_d3&lt;=3154.963` NA NA NA NA ## `(issue_d3) 3154.963&lt;issue_d3&lt;=4160.334` NA NA NA NA ## `(issue_d3) 4160.334&lt;issue_d3&lt;=4629.63` NA NA NA NA ## `(issue_d3) 4629.63&lt;issue_d3&lt;=5592.359` NA NA NA NA ## `(issue_d3) 5592.359&lt;issue_d3&lt;=6769.145` NA NA NA NA ## ## ------------------------------------------------------------------- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## --- ## null df: 1045083; null deviance: 1048231; ## residuals df: 1044916; residuals deviance: 976701.2; ## # obs.: 1045084; # non-zero weighted obs.: 1045084; ## AIC: 977037.2; log Likelihood: -488350.6; ## RSS: 1043064; dispersion: 1; iterations: 5; ## rank: 168; max tolerance: 4.98e-09; convergence: TRUE. # AIC = 977037.2 # Log likelihood = -488350.6 speedglm:::summary.speedglm(SGLM_B_reretrain) ## Generalized Linear Model of class &#39;speedglm&#39;: ## ## Call: speedglm::speedglm(formula = isGoodLoan ~ ., data = loansData, family = binomial()) ## ## Coefficients: ## ------------------------------------------------------------------ ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.64039 0.019861 32.2431 4.40e-228 *** ## `(loan_amnt) -Inf&lt;loan_amnt&lt;=3500` 1.10796 0.015121 73.2723 0.00e+00 *** ## `(loan_amnt) 3500&lt;loan_amnt&lt;=9000` 0.93839 0.010726 87.4833 0.00e+00 *** ## `(loan_amnt) 9000&lt;loan_amnt&lt;=10000` 0.70268 0.012338 56.9531 0.00e+00 *** ## `(loan_amnt) 10000&lt;loan_amnt&lt;=12000` 0.56169 0.012064 46.5606 0.00e+00 *** ## `(loan_amnt) 12000&lt;loan_amnt&lt;=14975` 0.45839 0.013082 35.0405 5.44e-269 *** ## `(loan_amnt) 14975&lt;loan_amnt&lt;=15000` 0.52969 0.014185 37.3408 3.57e-305 *** ## `(loan_amnt) 15000&lt;loan_amnt&lt;=17000` 0.34043 0.013520 25.1786 6.87e-140 *** ## `(loan_amnt) 17000&lt;loan_amnt&lt;=19950` 0.24032 0.013357 17.9918 2.26e-72 *** ## `(loan_amnt) 19950&lt;loan_amnt&lt;=28000` 0.22283 0.010012 22.2567 9.71e-110 *** ## `(verification_status) verification_status=Not Verified` 0.32251 0.007017 45.9606 0.00e+00 *** ## `(verification_status) verification_status=Source Verified` 0.10753 0.005988 17.9583 4.13e-72 *** ## `(issue_d) -Inf&lt;issue_d&lt;=14.167` 0.19954 0.010447 19.1010 2.48e-81 *** ## `(issue_d) 14.667&lt;issue_d&lt;=16.083` -0.05187 0.008491 -6.1085 1.01e-09 *** ## `(issue_d) 16.083&lt;issue_d&lt;=16.667` -0.41059 0.011328 -36.2468 1.12e-287 *** ## `(issue_d) 16.667&lt;issue_d&lt;=17.75` -0.36143 0.011081 -32.6172 2.34e-233 *** ## `(dti) 0.299&lt;dti&lt;=9.99` -0.42326 0.007897 -53.6008 0.00e+00 *** ## `(revol_util) -Inf&lt;revol_util&lt;=0.147` 0.26612 0.015380 17.3028 4.48e-67 *** ## `(revol_util) 0.147&lt;revol_util&lt;=0.217` 0.23979 0.015891 15.0894 1.90e-51 *** ## `(revol_util) 0.217&lt;revol_util&lt;=0.316` 0.20448 0.011942 17.1221 1.01e-65 *** ## `(revol_util) 0.316&lt;revol_util&lt;=0.388` 0.15118 0.011109 13.6087 3.56e-42 *** ## `(revol_util) 0.388&lt;revol_util&lt;=0.479` 0.08991 0.008988 10.0032 1.48e-23 *** ## `(open_rv_12m) -Inf&lt;open_rv_12m&lt;=0` -0.33627 0.019429 -17.3078 4.11e-67 *** ## `(open_rv_12m) 0&lt;open_rv_12m&lt;=1` -0.24267 0.017149 -14.1505 1.85e-45 *** ## `(open_rv_12m) 1&lt;open_rv_12m&lt;=2` -0.13405 0.016511 -8.1188 4.71e-16 *** ## `(open_rv_12m) 2&lt;open_rv_12m&lt;=28` -0.02477 0.014092 -1.7578 7.88e-02 . ## `(open_rv_24m) -Inf&lt;open_rv_24m&lt;=0` 0.21090 0.022340 9.4402 3.72e-21 *** ## `(open_rv_24m) 0&lt;open_rv_24m&lt;=1` 0.29822 0.017808 16.7471 5.94e-63 *** ## `(open_rv_24m) 1&lt;open_rv_24m&lt;=2` 0.24708 0.016441 15.0279 4.82e-51 *** ## `(open_rv_24m) 2&lt;open_rv_24m&lt;=3` 0.15733 0.015669 10.0413 1.00e-23 *** ## `(open_rv_24m) 3&lt;open_rv_24m&lt;=5` 0.10573 0.013710 7.7121 1.24e-14 *** ## `(bc_open_to_buy) -Inf&lt;bc_open_to_buy&lt;=0.315` 0.35942 0.066245 5.4256 5.77e-08 *** ## `(bc_open_to_buy) 0.315&lt;bc_open_to_buy&lt;=0.388` 0.35527 0.066826 5.3164 1.06e-07 *** ## `(bc_open_to_buy) 0.388&lt;bc_open_to_buy&lt;=0.461` 0.37089 0.066665 5.5636 2.64e-08 *** ## `(bc_open_to_buy) 0.461&lt;bc_open_to_buy&lt;=0.539` 0.38326 0.066482 5.7649 8.17e-09 *** ## `(bc_open_to_buy) 0.539&lt;bc_open_to_buy&lt;=0.725` 0.39699 0.066009 6.0141 1.81e-09 *** ## `(bc_open_to_buy) 0.725&lt;bc_open_to_buy&lt;=0.876` 0.40323 0.066050 6.1050 1.03e-09 *** ## `(bc_open_to_buy) 0.876&lt;bc_open_to_buy&lt;=0.919` 0.33279 0.066538 5.0015 5.69e-07 *** ## `(bc_open_to_buy) 0.919&lt;bc_open_to_buy&lt;=0.979` 0.18281 0.066118 2.7649 5.69e-03 ** ## `(bc_open_to_buy) 0.979&lt;bc_open_to_buy&lt;=3.396` -0.02193 0.066441 -0.3301 7.41e-01 ## `(mo_sin_rcnt_rev_tl_op) -Inf&lt;mo_sin_rcnt_rev_tl_op&lt;=1` 0.02121 0.012625 1.6796 9.30e-02 . ## `(mo_sin_rcnt_rev_tl_op) 1&lt;mo_sin_rcnt_rev_tl_op&lt;=2` 0.07100 0.013128 5.4085 6.36e-08 *** ## `(mo_sin_rcnt_rev_tl_op) 2&lt;mo_sin_rcnt_rev_tl_op&lt;=3` 0.02405 0.013232 1.8174 6.92e-02 . ## `(mo_sin_rcnt_rev_tl_op) 3&lt;mo_sin_rcnt_rev_tl_op&lt;=4` 0.02963 0.013417 2.2087 2.72e-02 * ## `(mo_sin_rcnt_rev_tl_op) 7&lt;mo_sin_rcnt_rev_tl_op&lt;=9` -0.01695 0.011849 -1.4302 1.53e-01 ## `(mo_sin_rcnt_rev_tl_op) 9&lt;mo_sin_rcnt_rev_tl_op&lt;=16` -0.07866 0.009868 -7.9714 1.57e-15 *** ## `(mo_sin_rcnt_rev_tl_op) 16&lt;mo_sin_rcnt_rev_tl_op&lt;=20` -0.09308 0.014689 -6.3371 2.34e-10 *** ## `(mo_sin_rcnt_rev_tl_op) 20&lt;mo_sin_rcnt_rev_tl_op&lt;=28` -0.05295 0.013644 -3.8808 1.04e-04 *** ## `(mort_acc) -Inf&lt;mort_acc&lt;=0` 0.80077 0.036082 22.1932 4.00e-109 *** ## `(mort_acc) 0&lt;mort_acc&lt;=1` 0.92056 0.036353 25.3225 1.81e-141 *** ## `(mort_acc) 1&lt;mort_acc&lt;=2` 1.01742 0.036415 27.9399 8.74e-172 *** ## `(mort_acc) 2&lt;mort_acc&lt;=3` 1.06480 0.036620 29.0769 7.03e-186 *** ## `(mort_acc) 3&lt;mort_acc&lt;=5` 1.10583 0.036453 30.3356 3.89e-202 *** ## `(mort_acc) 5&lt;mort_acc&lt;=47` 1.16868 0.037536 31.1351 8.06e-213 *** ## `(mths_since_recent_bc) -Inf&lt;mths_since_recent_bc&lt;=2` -0.64469 0.070952 -9.0863 1.02e-19 *** ## `(mths_since_recent_bc) 2&lt;mths_since_recent_bc&lt;=4` -0.56402 0.070864 -7.9591 1.73e-15 *** ## `(mths_since_recent_bc) 4&lt;mths_since_recent_bc&lt;=7` -0.49657 0.070424 -7.0511 1.77e-12 *** ## `(mths_since_recent_bc) 7&lt;mths_since_recent_bc&lt;=15` -0.45193 0.070215 -6.4363 1.22e-10 *** ## `(mths_since_recent_bc) 15&lt;mths_since_recent_bc&lt;=21` -0.41463 0.070419 -5.8880 3.91e-09 *** ## `(mths_since_recent_bc) 21&lt;mths_since_recent_bc&lt;=28` -0.37287 0.070541 -5.2859 1.25e-07 *** ## `(mths_since_recent_bc) 28&lt;mths_since_recent_bc&lt;=35` -0.35380 0.070697 -5.0044 5.60e-07 *** ## `(mths_since_recent_bc) 35&lt;mths_since_recent_bc&lt;=56` -0.28475 0.070276 -4.0519 5.08e-05 *** ## `(mths_since_recent_bc) 56&lt;mths_since_recent_bc&lt;=639` -0.17252 0.069578 -2.4796 1.32e-02 * ## `(mths_since_recent_inq) -Inf&lt;mths_since_recent_inq&lt;=0` -0.45972 0.012796 -35.9263 1.19e-282 *** ## `(mths_since_recent_inq) 0&lt;mths_since_recent_inq&lt;=1` -0.38775 0.012420 -31.2198 5.75e-214 *** ## `(mths_since_recent_inq) 1&lt;mths_since_recent_inq&lt;=2` -0.29301 0.013200 -22.1981 3.58e-109 *** ## `(mths_since_recent_inq) 2&lt;mths_since_recent_inq&lt;=3` -0.25035 0.013564 -18.4570 4.58e-76 *** ## `(mths_since_recent_inq) 3&lt;mths_since_recent_inq&lt;=4` -0.20422 0.013977 -14.6112 2.38e-48 *** ## `(mths_since_recent_inq) 4&lt;mths_since_recent_inq&lt;=5` -0.18047 0.014343 -12.5831 2.62e-36 *** ## `(mths_since_recent_inq) 5&lt;mths_since_recent_inq&lt;=8` -0.14669 0.011848 -12.3804 3.34e-35 *** ## `(mths_since_recent_inq) 8&lt;mths_since_recent_inq&lt;=10` -0.10755 0.013784 -7.8026 6.07e-15 *** ## `(mths_since_recent_inq) 10&lt;mths_since_recent_inq&lt;=16` -0.10442 0.011941 -8.7446 2.24e-18 *** ## `(mths_since_recent_inq) 16&lt;mths_since_recent_inq&lt;=25` -0.06943 0.013577 -5.1141 3.15e-07 *** ## `(num_actv_rev_tl) 2&lt;num_actv_rev_tl&lt;=3` 0.09152 0.033155 2.7604 5.77e-03 ** ## `(num_actv_rev_tl) 3&lt;num_actv_rev_tl&lt;=4` 0.06114 0.028129 2.1737 2.97e-02 * ## `(num_rev_tl_bal_gt_0) -Inf&lt;num_rev_tl_bal_gt_0&lt;=2` 0.48104 0.012969 37.0927 3.68e-301 *** ## `(num_rev_tl_bal_gt_0) 2&lt;num_rev_tl_bal_gt_0&lt;=3` 0.34749 0.034237 10.1496 3.33e-24 *** ## `(num_rev_tl_bal_gt_0) 3&lt;num_rev_tl_bal_gt_0&lt;=4` 0.31390 0.029416 10.6713 1.39e-26 *** ## `(num_rev_tl_bal_gt_0) 4&lt;num_rev_tl_bal_gt_0&lt;=5` 0.32824 0.011256 29.1626 5.78e-187 *** ## `(num_rev_tl_bal_gt_0) 5&lt;num_rev_tl_bal_gt_0&lt;=6` 0.26724 0.011439 23.3616 1.05e-120 *** ## `(num_rev_tl_bal_gt_0) 6&lt;num_rev_tl_bal_gt_0&lt;=7` 0.23323 0.011982 19.4651 2.17e-84 *** ## `(num_rev_tl_bal_gt_0) 7&lt;num_rev_tl_bal_gt_0&lt;=8` 0.18045 0.012817 14.0786 5.14e-45 *** ## `(num_rev_tl_bal_gt_0) 8&lt;num_rev_tl_bal_gt_0&lt;=10` 0.13086 0.012003 10.9023 1.12e-27 *** ## `(num_tl_op_past_12m) -Inf&lt;num_tl_op_past_12m&lt;=0` 0.57009 0.013312 42.8238 0.00e+00 *** ## `(num_tl_op_past_12m) 0&lt;num_tl_op_past_12m&lt;=1` 0.46234 0.011232 41.1636 0.00e+00 *** ## `(num_tl_op_past_12m) 1&lt;num_tl_op_past_12m&lt;=2` 0.32881 0.010578 31.0833 4.05e-212 *** ## `(num_tl_op_past_12m) 2&lt;num_tl_op_past_12m&lt;=3` 0.19327 0.010336 18.6991 5.03e-78 *** ## `(num_tl_op_past_12m) 3&lt;num_tl_op_past_12m&lt;=4` 0.08567 0.010927 7.8403 4.49e-15 *** ## `(percent_bc_gt_75) 0.522&lt;percent_bc_gt_75&lt;=0.682` -0.11542 0.008918 -12.9429 2.58e-38 *** ## `(percent_bc_gt_75) 0.682&lt;percent_bc_gt_75&lt;=0.958` -0.17389 0.009611 -18.0935 3.58e-73 *** ## `(tot_hi_cred_lim) -Inf&lt;tot_hi_cred_lim&lt;=102535` -0.67056 0.013971 -47.9982 0.00e+00 *** ## `(tot_hi_cred_lim) 102535&lt;tot_hi_cred_lim&lt;=131793` -0.53327 0.016095 -33.1323 1.02e-240 *** ## `(tot_hi_cred_lim) 131793&lt;tot_hi_cred_lim&lt;=179071` -0.50812 0.015210 -33.4079 1.05e-244 *** ## `(tot_hi_cred_lim) 179071&lt;tot_hi_cred_lim&lt;=208761` -0.41743 0.016960 -24.6125 9.28e-134 *** ## `(tot_hi_cred_lim) 208761&lt;tot_hi_cred_lim&lt;=242055` -0.36953 0.016854 -21.9249 1.50e-106 *** ## `(tot_hi_cred_lim) 242055&lt;tot_hi_cred_lim&lt;=298516` -0.29341 0.015680 -18.7128 3.90e-78 *** ## `(tot_hi_cred_lim) 298516&lt;tot_hi_cred_lim&lt;=383997` -0.21795 0.015550 -14.0163 1.24e-44 *** ## `(tot_hi_cred_lim) 383997&lt;tot_hi_cred_lim&lt;=487388` -0.15086 0.017194 -8.7738 1.73e-18 *** ## `(total_bc_limit) -Inf&lt;total_bc_limit&lt;=4478` -0.99491 0.013929 -71.4271 0.00e+00 *** ## `(total_bc_limit) 4478&lt;total_bc_limit&lt;=9405` -0.76318 0.012543 -60.8465 0.00e+00 *** ## `(total_bc_limit) 9405&lt;total_bc_limit&lt;=11360` -0.64216 0.014401 -44.5908 0.00e+00 *** ## `(total_bc_limit) 11360&lt;total_bc_limit&lt;=13970` -0.56875 0.013804 -41.2007 0.00e+00 *** ## `(total_bc_limit) 13970&lt;total_bc_limit&lt;=18174` -0.49285 0.012950 -38.0576 0.00e+00 *** ## `(total_bc_limit) 18174&lt;total_bc_limit&lt;=20950` -0.43128 0.014759 -29.2212 1.04e-187 *** ## `(total_bc_limit) 20950&lt;total_bc_limit&lt;=24806` -0.38256 0.014233 -26.8782 3.95e-159 *** ## `(total_bc_limit) 24806&lt;total_bc_limit&lt;=29471` -0.31852 0.014604 -21.8113 1.81e-105 *** ## `(total_bc_limit) 29471&lt;total_bc_limit&lt;=34756` -0.26949 0.015151 -17.7866 8.98e-71 *** ## `(total_bc_limit) 34756&lt;total_bc_limit&lt;=47175` -0.18062 0.013781 -13.1068 3.01e-39 *** ## ## ------------------------------------------------------------------- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## --- ## null df: 1045083; null deviance: 1048231; ## residuals df: 1044976; residuals deviance: 982741; ## # obs.: 1045084; # non-zero weighted obs.: 1045084; ## AIC: 982957; log Likelihood: -491370.5; ## RSS: 1044655; dispersion: 1; iterations: 4; ## rank: 108; max tolerance: 9.52e-10; convergence: TRUE. # AIC = 982957 # Log likelihood = -491370.5 # speedglm:::summary.speedglm(SGLM_B_reretrain) ## Generalized Linear Model of class &#39;speedglm&#39;: ## ## Call: speedglm::speedglm(formula = isGoodLoan ~ ., data = loansData, family = binomial()) ## ## Coefficients: ## ------------------------------------------------------------------ ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.64039 0.019861 32.2431 4.40e-228 *** ## `(loan_amnt) -Inf&lt;loan_amnt&lt;=3500` 1.10796 0.015121 73.2723 0.00e+00 *** ## `(loan_amnt) 3500&lt;loan_amnt&lt;=9000` 0.93839 0.010726 87.4833 0.00e+00 *** ## `(loan_amnt) 9000&lt;loan_amnt&lt;=10000` 0.70268 0.012338 56.9531 0.00e+00 *** ## `(loan_amnt) 10000&lt;loan_amnt&lt;=12000` 0.56169 0.012064 46.5606 0.00e+00 *** ## `(loan_amnt) 12000&lt;loan_amnt&lt;=14975` 0.45839 0.013082 35.0405 5.44e-269 *** ## `(loan_amnt) 14975&lt;loan_amnt&lt;=15000` 0.52969 0.014185 37.3408 3.57e-305 *** ## `(loan_amnt) 15000&lt;loan_amnt&lt;=17000` 0.34043 0.013520 25.1786 6.87e-140 *** ## `(loan_amnt) 17000&lt;loan_amnt&lt;=19950` 0.24032 0.013357 17.9918 2.26e-72 *** ## `(loan_amnt) 19950&lt;loan_amnt&lt;=28000` 0.22283 0.010012 22.2567 9.71e-110 *** ## `(verification_status) verification_status=Not Verified` 0.32251 0.007017 45.9606 0.00e+00 *** ## `(verification_status) verification_status=Source Verified` 0.10753 0.005988 17.9583 4.13e-72 *** ## `(issue_d) -Inf&lt;issue_d&lt;=14.167` 0.19954 0.010447 19.1010 2.48e-81 *** ## `(issue_d) 14.667&lt;issue_d&lt;=16.083` -0.05187 0.008491 -6.1085 1.01e-09 *** ## `(issue_d) 16.083&lt;issue_d&lt;=16.667` -0.41059 0.011328 -36.2468 1.12e-287 *** ## `(issue_d) 16.667&lt;issue_d&lt;=17.75` -0.36143 0.011081 -32.6172 2.34e-233 *** ## `(dti) 0.299&lt;dti&lt;=9.99` -0.42326 0.007897 -53.6008 0.00e+00 *** ## `(revol_util) -Inf&lt;revol_util&lt;=0.147` 0.26612 0.015380 17.3028 4.48e-67 *** ## `(revol_util) 0.147&lt;revol_util&lt;=0.217` 0.23979 0.015891 15.0894 1.90e-51 *** ## `(revol_util) 0.217&lt;revol_util&lt;=0.316` 0.20448 0.011942 17.1221 1.01e-65 *** ## `(revol_util) 0.316&lt;revol_util&lt;=0.388` 0.15118 0.011109 13.6087 3.56e-42 *** ## `(revol_util) 0.388&lt;revol_util&lt;=0.479` 0.08991 0.008988 10.0032 1.48e-23 *** ## `(open_rv_12m) -Inf&lt;open_rv_12m&lt;=0` -0.33627 0.019429 -17.3078 4.11e-67 *** ## `(open_rv_12m) 0&lt;open_rv_12m&lt;=1` -0.24267 0.017149 -14.1505 1.85e-45 *** ## `(open_rv_12m) 1&lt;open_rv_12m&lt;=2` -0.13405 0.016511 -8.1188 4.71e-16 *** ## `(open_rv_12m) 2&lt;open_rv_12m&lt;=28` -0.02477 0.014092 -1.7578 7.88e-02 . ## `(open_rv_24m) -Inf&lt;open_rv_24m&lt;=0` 0.21090 0.022340 9.4402 3.72e-21 *** ## `(open_rv_24m) 0&lt;open_rv_24m&lt;=1` 0.29822 0.017808 16.7471 5.94e-63 *** ## `(open_rv_24m) 1&lt;open_rv_24m&lt;=2` 0.24708 0.016441 15.0279 4.82e-51 *** ## `(open_rv_24m) 2&lt;open_rv_24m&lt;=3` 0.15733 0.015669 10.0413 1.00e-23 *** ## `(open_rv_24m) 3&lt;open_rv_24m&lt;=5` 0.10573 0.013710 7.7121 1.24e-14 *** ## `(bc_open_to_buy) -Inf&lt;bc_open_to_buy&lt;=0.315` 0.35942 0.066245 5.4256 5.77e-08 *** ## `(bc_open_to_buy) 0.315&lt;bc_open_to_buy&lt;=0.388` 0.35527 0.066826 5.3164 1.06e-07 *** ## `(bc_open_to_buy) 0.388&lt;bc_open_to_buy&lt;=0.461` 0.37089 0.066665 5.5636 2.64e-08 *** ## `(bc_open_to_buy) 0.461&lt;bc_open_to_buy&lt;=0.539` 0.38326 0.066482 5.7649 8.17e-09 *** ## `(bc_open_to_buy) 0.539&lt;bc_open_to_buy&lt;=0.725` 0.39699 0.066009 6.0141 1.81e-09 *** ## `(bc_open_to_buy) 0.725&lt;bc_open_to_buy&lt;=0.876` 0.40323 0.066050 6.1050 1.03e-09 *** ## `(bc_open_to_buy) 0.876&lt;bc_open_to_buy&lt;=0.919` 0.33279 0.066538 5.0015 5.69e-07 *** ## `(bc_open_to_buy) 0.919&lt;bc_open_to_buy&lt;=0.979` 0.18281 0.066118 2.7649 5.69e-03 ** ## `(bc_open_to_buy) 0.979&lt;bc_open_to_buy&lt;=3.396` -0.02193 0.066441 -0.3301 7.41e-01 ## `(mo_sin_rcnt_rev_tl_op) -Inf&lt;mo_sin_rcnt_rev_tl_op&lt;=1` 0.02121 0.012625 1.6796 9.30e-02 . ## `(mo_sin_rcnt_rev_tl_op) 1&lt;mo_sin_rcnt_rev_tl_op&lt;=2` 0.07100 0.013128 5.4085 6.36e-08 *** ## `(mo_sin_rcnt_rev_tl_op) 2&lt;mo_sin_rcnt_rev_tl_op&lt;=3` 0.02405 0.013232 1.8174 6.92e-02 . ## `(mo_sin_rcnt_rev_tl_op) 3&lt;mo_sin_rcnt_rev_tl_op&lt;=4` 0.02963 0.013417 2.2087 2.72e-02 * ## `(mo_sin_rcnt_rev_tl_op) 7&lt;mo_sin_rcnt_rev_tl_op&lt;=9` -0.01695 0.011849 -1.4302 1.53e-01 ## `(mo_sin_rcnt_rev_tl_op) 9&lt;mo_sin_rcnt_rev_tl_op&lt;=16` -0.07866 0.009868 -7.9714 1.57e-15 *** ## `(mo_sin_rcnt_rev_tl_op) 16&lt;mo_sin_rcnt_rev_tl_op&lt;=20` -0.09308 0.014689 -6.3371 2.34e-10 *** ## `(mo_sin_rcnt_rev_tl_op) 20&lt;mo_sin_rcnt_rev_tl_op&lt;=28` -0.05295 0.013644 -3.8808 1.04e-04 *** ## `(mort_acc) -Inf&lt;mort_acc&lt;=0` 0.80077 0.036082 22.1932 4.00e-109 *** ## `(mort_acc) 0&lt;mort_acc&lt;=1` 0.92056 0.036353 25.3225 1.81e-141 *** ## `(mort_acc) 1&lt;mort_acc&lt;=2` 1.01742 0.036415 27.9399 8.74e-172 *** ## `(mort_acc) 2&lt;mort_acc&lt;=3` 1.06480 0.036620 29.0769 7.03e-186 *** ## `(mort_acc) 3&lt;mort_acc&lt;=5` 1.10583 0.036453 30.3356 3.89e-202 *** ## `(mort_acc) 5&lt;mort_acc&lt;=47` 1.16868 0.037536 31.1351 8.06e-213 *** ## `(mths_since_recent_bc) -Inf&lt;mths_since_recent_bc&lt;=2` -0.64469 0.070952 -9.0863 1.02e-19 *** ## `(mths_since_recent_bc) 2&lt;mths_since_recent_bc&lt;=4` -0.56402 0.070864 -7.9591 1.73e-15 *** ## `(mths_since_recent_bc) 4&lt;mths_since_recent_bc&lt;=7` -0.49657 0.070424 -7.0511 1.77e-12 *** ## `(mths_since_recent_bc) 7&lt;mths_since_recent_bc&lt;=15` -0.45193 0.070215 -6.4363 1.22e-10 *** ## `(mths_since_recent_bc) 15&lt;mths_since_recent_bc&lt;=21` -0.41463 0.070419 -5.8880 3.91e-09 *** ## `(mths_since_recent_bc) 21&lt;mths_since_recent_bc&lt;=28` -0.37287 0.070541 -5.2859 1.25e-07 *** ## `(mths_since_recent_bc) 28&lt;mths_since_recent_bc&lt;=35` -0.35380 0.070697 -5.0044 5.60e-07 *** ## `(mths_since_recent_bc) 35&lt;mths_since_recent_bc&lt;=56` -0.28475 0.070276 -4.0519 5.08e-05 *** ## `(mths_since_recent_bc) 56&lt;mths_since_recent_bc&lt;=639` -0.17252 0.069578 -2.4796 1.32e-02 * ## `(mths_since_recent_inq) -Inf&lt;mths_since_recent_inq&lt;=0` -0.45972 0.012796 -35.9263 1.19e-282 *** ## `(mths_since_recent_inq) 0&lt;mths_since_recent_inq&lt;=1` -0.38775 0.012420 -31.2198 5.75e-214 *** ## `(mths_since_recent_inq) 1&lt;mths_since_recent_inq&lt;=2` -0.29301 0.013200 -22.1981 3.58e-109 *** ## `(mths_since_recent_inq) 2&lt;mths_since_recent_inq&lt;=3` -0.25035 0.013564 -18.4570 4.58e-76 *** ## `(mths_since_recent_inq) 3&lt;mths_since_recent_inq&lt;=4` -0.20422 0.013977 -14.6112 2.38e-48 *** ## `(mths_since_recent_inq) 4&lt;mths_since_recent_inq&lt;=5` -0.18047 0.014343 -12.5831 2.62e-36 *** ## `(mths_since_recent_inq) 5&lt;mths_since_recent_inq&lt;=8` -0.14669 0.011848 -12.3804 3.34e-35 *** ## `(mths_since_recent_inq) 8&lt;mths_since_recent_inq&lt;=10` -0.10755 0.013784 -7.8026 6.07e-15 *** ## `(mths_since_recent_inq) 10&lt;mths_since_recent_inq&lt;=16` -0.10442 0.011941 -8.7446 2.24e-18 *** ## `(mths_since_recent_inq) 16&lt;mths_since_recent_inq&lt;=25` -0.06943 0.013577 -5.1141 3.15e-07 *** ## `(num_actv_rev_tl) 2&lt;num_actv_rev_tl&lt;=3` 0.09152 0.033155 2.7604 5.77e-03 ** ## `(num_actv_rev_tl) 3&lt;num_actv_rev_tl&lt;=4` 0.06114 0.028129 2.1737 2.97e-02 * ## `(num_rev_tl_bal_gt_0) -Inf&lt;num_rev_tl_bal_gt_0&lt;=2` 0.48104 0.012969 37.0927 3.68e-301 *** ## `(num_rev_tl_bal_gt_0) 2&lt;num_rev_tl_bal_gt_0&lt;=3` 0.34749 0.034237 10.1496 3.33e-24 *** ## `(num_rev_tl_bal_gt_0) 3&lt;num_rev_tl_bal_gt_0&lt;=4` 0.31390 0.029416 10.6713 1.39e-26 *** ## `(num_rev_tl_bal_gt_0) 4&lt;num_rev_tl_bal_gt_0&lt;=5` 0.32824 0.011256 29.1626 5.78e-187 *** ## `(num_rev_tl_bal_gt_0) 5&lt;num_rev_tl_bal_gt_0&lt;=6` 0.26724 0.011439 23.3616 1.05e-120 *** ## `(num_rev_tl_bal_gt_0) 6&lt;num_rev_tl_bal_gt_0&lt;=7` 0.23323 0.011982 19.4651 2.17e-84 *** ## `(num_rev_tl_bal_gt_0) 7&lt;num_rev_tl_bal_gt_0&lt;=8` 0.18045 0.012817 14.0786 5.14e-45 *** ## `(num_rev_tl_bal_gt_0) 8&lt;num_rev_tl_bal_gt_0&lt;=10` 0.13086 0.012003 10.9023 1.12e-27 *** ## `(num_tl_op_past_12m) -Inf&lt;num_tl_op_past_12m&lt;=0` 0.57009 0.013312 42.8238 0.00e+00 *** ## `(num_tl_op_past_12m) 0&lt;num_tl_op_past_12m&lt;=1` 0.46234 0.011232 41.1636 0.00e+00 *** ## `(num_tl_op_past_12m) 1&lt;num_tl_op_past_12m&lt;=2` 0.32881 0.010578 31.0833 4.05e-212 *** ## `(num_tl_op_past_12m) 2&lt;num_tl_op_past_12m&lt;=3` 0.19327 0.010336 18.6991 5.03e-78 *** ## `(num_tl_op_past_12m) 3&lt;num_tl_op_past_12m&lt;=4` 0.08567 0.010927 7.8403 4.49e-15 *** ## `(percent_bc_gt_75) 0.522&lt;percent_bc_gt_75&lt;=0.682` -0.11542 0.008918 -12.9429 2.58e-38 *** ## `(percent_bc_gt_75) 0.682&lt;percent_bc_gt_75&lt;=0.958` -0.17389 0.009611 -18.0935 3.58e-73 *** ## `(tot_hi_cred_lim) -Inf&lt;tot_hi_cred_lim&lt;=102535` -0.67056 0.013971 -47.9982 0.00e+00 *** ## `(tot_hi_cred_lim) 102535&lt;tot_hi_cred_lim&lt;=131793` -0.53327 0.016095 -33.1323 1.02e-240 *** ## `(tot_hi_cred_lim) 131793&lt;tot_hi_cred_lim&lt;=179071` -0.50812 0.015210 -33.4079 1.05e-244 *** ## `(tot_hi_cred_lim) 179071&lt;tot_hi_cred_lim&lt;=208761` -0.41743 0.016960 -24.6125 9.28e-134 *** ## `(tot_hi_cred_lim) 208761&lt;tot_hi_cred_lim&lt;=242055` -0.36953 0.016854 -21.9249 1.50e-106 *** ## `(tot_hi_cred_lim) 242055&lt;tot_hi_cred_lim&lt;=298516` -0.29341 0.015680 -18.7128 3.90e-78 *** ## `(tot_hi_cred_lim) 298516&lt;tot_hi_cred_lim&lt;=383997` -0.21795 0.015550 -14.0163 1.24e-44 *** ## `(tot_hi_cred_lim) 383997&lt;tot_hi_cred_lim&lt;=487388` -0.15086 0.017194 -8.7738 1.73e-18 *** ## `(total_bc_limit) -Inf&lt;total_bc_limit&lt;=4478` -0.99491 0.013929 -71.4271 0.00e+00 *** ## `(total_bc_limit) 4478&lt;total_bc_limit&lt;=9405` -0.76318 0.012543 -60.8465 0.00e+00 *** ## `(total_bc_limit) 9405&lt;total_bc_limit&lt;=11360` -0.64216 0.014401 -44.5908 0.00e+00 *** ## `(total_bc_limit) 11360&lt;total_bc_limit&lt;=13970` -0.56875 0.013804 -41.2007 0.00e+00 *** ## `(total_bc_limit) 13970&lt;total_bc_limit&lt;=18174` -0.49285 0.012950 -38.0576 0.00e+00 *** ## `(total_bc_limit) 18174&lt;total_bc_limit&lt;=20950` -0.43128 0.014759 -29.2212 1.04e-187 *** ## `(total_bc_limit) 20950&lt;total_bc_limit&lt;=24806` -0.38256 0.014233 -26.8782 3.95e-159 *** ## `(total_bc_limit) 24806&lt;total_bc_limit&lt;=29471` -0.31852 0.014604 -21.8113 1.81e-105 *** ## `(total_bc_limit) 29471&lt;total_bc_limit&lt;=34756` -0.26949 0.015151 -17.7866 8.98e-71 *** ## `(total_bc_limit) 34756&lt;total_bc_limit&lt;=47175` -0.18062 0.013781 -13.1068 3.01e-39 *** ## ## ------------------------------------------------------------------- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## --- ## null df: 1045083; null deviance: 1048231; ## residuals df: 1044976; residuals deviance: 982741; ## # obs.: 1045084; # non-zero weighted obs.: 1045084; ## AIC: 982957; log Likelihood: -491370.5; ## RSS: 1044655; dispersion: 1; iterations: 4; ## rank: 108; max tolerance: 9.52e-10; convergence: TRUE. # AIC = 982957 # log Likelihood = -491370.5 3.5 Model result 3.5.1 Final list of variables # Saved at the end of the modeling file SGLM_B_train &lt;- readRDS(&quot;datasets/SGLM_B_train.rds&quot;) SGLM_B_retrain &lt;- readRDS(&quot;datasets/SGLM_B_retrain.rds&quot;) SGLM_B_reretrain &lt;- readRDS(&quot;datasets/SGLM_B_reretrain.rds&quot;) # Model to use GLModel &lt;- SGLM_B_retrain # List of model variables modelNames &lt;- attr(GLModel$coefficients, &quot;names&quot;) %&gt;% enframe(x = .) %&gt;% rename(variableName = &quot;value&quot;) %&gt;% select(variableName) %&gt;% mutate(variableName = str_remove_all(variableName, &quot;\\`&quot;)) # and their coefficients in the model (the summary function for speedglm objects is not exported and # bookdown seems to have a problem with that). sumSpeed &lt;- speedglm:::summary.speedglm GLMCoefficients &lt;- sumSpeed(GLModel)$coefficients %&gt;% as_tibble() %&gt;% cbind(modelNames) %&gt;% rename( zValue = &quot;z value&quot;, pValue = &quot;Pr(&gt;|z|)&quot;, stdErr = &quot;Std. Error&quot; ) %&gt;% # reorder columns to have names first select(variableName, everything()) 3.5.2 Scoring Scoring expresses the coefficients that were estimated during the logistic regression into points on a scale. The conversion is done using three parameters that are chosen somewhat arbitrarily. the number of points increase / decrease that would reflect halving / doubling the odds of defaulting; an anchoring score reflecting a particular odd. For our purpose, we will choose (\\(Score_{anchor}\\)) 5,000 points being equivalent to 1 in a 20 to default (\\(Odds_{anchor}\\)), i.e. 5,000 points &lt;=&gt; \\(Odds_{Anchor} = \\frac{1 / 20}{1 - 1/20}\\). We will also choose 100 to reflect times 2 change in odds (\\(DoubleOdds\\)). Those choices are completely arbitrary. Basically, the score is a linear representation of the odds. The score is defined by a point (the anchor) and the slope of the line going through that point. Those values will reflect the total estimated score for a borrower (i.e. loan sample). The number of characteristics (information points gathered in a credit application), or number of bins, have to be irrelevant in calculating this score. In other words, if LendingClub were to gather 5 more information points, the score should, mutatis mutandis, be unchanged. (However, we would hope that the quality of the estimated score would improve.) The score per variable needs to be adjusted using the number of information points, that is the number of characteristics. Here, the model has been trained on the number of bins. We first need to determine how many characteristics are used in the model. # The list of characteristics is extracted from the list of bins names. numberOfCharacteristics &lt;- modelNames %&gt;% # List of all names excluding the intercept which is not part of the scoring calculations (it # would mean giving points for free as a base line) filter(variableName != &quot;(Intercept)&quot;) %&gt;% # Extract strings (&quot;[a-zA-Z0-9-_]*&quot;) preceded by an opening bracket (&quot;(?&lt;=\\\\()&quot;) and followed by a # closing bracket (&quot;(?=\\\\))&quot;). (The column names were formatted this way for that purpose.) See # &quot;https://github.com/rstudio/cheatsheets/blob/master/strings.pdf&quot; for details on the regex. mutate(characteristic = str_match(variableName, &quot;(?&lt;=\\\\()[a-zA-Z0-9-_]*(?=\\\\))&quot;)) %&gt;% # We are only interested in how many distinct characteristic there are. distinct(characteristic) %&gt;% nrow() numberOfCharacteristics ## [1] 24 We can now perform the scoring calculation. ProbDefaultAtAnchor &lt;- 1/20 # The model is trained so that the &#39;Good&#39; outcome is that a loan does not default. The odds that # therefore calculated on the probability of no default. ProbAtAnchor &lt;- 1 - ProbDefaultAtAnchor OddsAnchor &lt;- ProbAtAnchor / (1 - ProbAtAnchor) ScoreAnchor &lt;- 2000 # Doubling odds = 100 points DoubleOdds &lt;- 100 ScoreFactor &lt;- OddsAnchor / log(2) # 5,000 points is 20:1 odds of default ScoreOffset &lt;- ScoreAnchor - ScoreFactor * log(OddsAnchor) # Score at the intercept Intercept &lt;- summary(GLModel)$coefficients[&quot;(Intercept)&quot;, &quot;Estimate&quot;] Then we apportion across characteristics. ScorePerVariable &lt;- (ScoreFactor * Intercept + ScoreOffset) / numberOfCharacteristics InterceptPerVariable &lt;- Intercept * ScoreFactor / numberOfCharacteristics GLMScores &lt;- GLMCoefficients %&gt;% mutate( weight = Estimate * ScoreFactor, weightScaled = weight + ScorePerVariable, points = round(weightScaled) ) VERY IMPORTANT: The intercept points have been allocated across all characteristics. Therefore the regression coefficient estimated for the intercept becomes redundant and needs removing. GLMScores[1, &quot;points&quot;] &lt;- 0 Using the model is a simple matrix multiplication: \\(\\text{Loan matrix} \\times \\text{Scorecard weights}\\) 3.6 Training set # Reload the right datasets allFactorsAsBins &lt;- readRDS(&quot;datasets/allBins100.rds&quot;) loansTraining &lt;- readRDS(&quot;datasets/LoansTraining.rds&quot;) loansTest &lt;- readRDS(&quot;datasets/LoansTest.rds&quot;) gc(full = TRUE) ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 2845749 152.0 6816128 364.1 6816128 364.1 ## Vcells 737738080 5628.5 1273967028 9719.6 1826494161 13935.1 # Remove every variable that is not in the list of variables in the model then convert into a matrix allMatrix &lt;- allFactorsAsBins[, !is.na(match( names(allFactorsAsBins), str_remove_all(GLMCoefficients$variableName, &quot;\\`&quot;) ))] %&gt;% as.matrix() # Add a column of 1s for the intercept allMatrix &lt;- cbind(as.vector(rep.int( x = 1, times = dim(allMatrix)[1] )), allMatrix) dim(allMatrix) ## [1] 1045084 168 # Done with this dataset rm(allFactorsAsBins) gc(full = TRUE) ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 2845509 152 6816128 364.1 6816128 364.1 ## Vcells 681825816 5202 1528840433 11664.2 1826494161 13935.1 CoefficientsVector &lt;- GLMCoefficients$Estimate %&gt;% as.matrix() # Score per variable TrainingScorecard &lt;- allMatrix %*% ( GLMScores$points %&gt;% as.matrix() ) dim(allMatrix) ## [1] 1045084 168 dim(GLMScores$points) ## NULL # CHECK: Any variable with NAs? # GLMCoefficients$modelName[which(is.na(CoefficientsVector))] # CoefficientsVector[is.na(CoefficientsVector)] &lt;- 0 # dim(CoefficientsVector) TrainingLogit &lt;- allMatrix %*% CoefficientsVector TrainingLogit &lt;- enframe(TrainingLogit[, 1]) %&gt;% mutate(oddsGood = exp(value), p = 1 / (1 + oddsGood)) %&gt;% cbind(TrainingScorecard) 3.6.1 Histogram of the scores loansTraining %&gt;% cbind(TrainingLogit) %&gt;% filter(between(value, -2, 5)) %&gt;% ggplot(aes(value, col = grade)) + geom_density(adjust = 2) loansTraining %&gt;% cbind(TrainingLogit) %&gt;% ggplot(aes(p, col = grade)) + geom_density(adjust = 2) + scale_x_log10() loansTraining %&gt;% cbind(TrainingLogit) %&gt;% filter(between(oddsGood, 0.1, 100)) %&gt;% ggplot(aes(oddsGood, col = grade)) + geom_density(adjust = 2) + scale_x_log10() The following histogram shows the density plot of the scorecards. Note the log-scale for the score, and the square-root scale for the density. It mirrors the multimodal density distributions of previous visualisations. loansTraining %&gt;% cbind(TrainingLogit) %&gt;% ggplot(aes(TrainingScorecard, col = grade)) + geom_density(adjust = 2) + scale_x_log10() + scale_y_sqrt() 3.7 Test set # Prepare the full test set bestBins &lt;- readRDS(&quot;datasets/bestBins100.rds&quot;) predictionCategories &lt;- loansTest[, &quot;loanID&quot;] for (index in 1:length(bestBins$variable)) { binned &lt;- binner::categoriseFromWoE.Wide( df = loansTest, varName = bestBins$variable[index], woeTable = bestBins$WoE[[index]] ) predictionCategories &lt;- cbind(predictionCategories, binned) } dim(predictionCategories) ## [1] 261272 222 # Retain only the relevant scorecard categories predictionMatrix &lt;- predictionCategories[, !is.na(match( names(predictionCategories), str_remove_all(GLMCoefficients$variableName, &quot;\\`&quot;) ))] %&gt;% as.matrix() predictionMatrix &lt;- cbind(as.vector(rep.int(x = 1, times = dim(predictionMatrix)[1])), predictionMatrix) dim(predictionMatrix) ## [1] 261272 168 TestLogit &lt;- predictionMatrix %*% CoefficientsVector TestLogit &lt;- tibble::enframe(TestLogit[, 1]) %&gt;% mutate( p = 1 / (1 + exp(-value)), oddsGood = if_else(is.infinite(p / (1 - p)), 1e10, p / (1 - p))) predictionScorecard &lt;- predictionMatrix %*% ( GLMScores$points %&gt;% as.matrix() ) loansTest %&gt;% cbind(TestLogit) %&gt;% cbind(predictionScorecard) %&gt;% mutate(scoreBand = floor(predictionScorecard / 50) * 50) %&gt;% filter(predictionScorecard &gt; 0) %&gt;% group_by(scoreBand) %&gt;% summarise(Count = n()) %&gt;% ggplot(aes(scoreBand, Count)) + geom_col(col = &quot;blue&quot;) median(predictionScorecard) ## [1] 1636 Same downward dynamics as training set loansTest %&gt;% cbind(TestLogit) %&gt;% filter(between(value, -2, 5)) %&gt;% ggplot(aes(value, col = grade)) + geom_density(adjust = 2) loansTest %&gt;% cbind(TestLogit) %&gt;% ggplot(aes(p, col = grade)) + geom_density(adjust = 2) + scale_x_log10() loansTest %&gt;% cbind(TestLogit) %&gt;% filter(between(oddsGood, 0.1, 100)) %&gt;% ggplot(aes(oddsGood, col = grade)) + geom_density(adjust = 2) + scale_x_log10() 3.8 Correlation matrix [TODO] 3.9 ROC Curve ROCRPrediction &lt;- ROCR::prediction(TestLogit$value, loansTest$isGoodLoan) ROCRPerformance &lt;- ROCR::performance(ROCRPrediction, &quot;tpr&quot;, &quot;fpr&quot;) ROCRPlot &lt;- tibble(x = ROCRPerformance@x.values[[1]], y = ROCRPerformance@y.values[[1]]) ROCRPlot %&gt;% ggplot(aes(x, y)) + geom_point() stats::ks.test(x = ROCRPlot$x, y = ROCRPlot$y) ## ## Two-sample Kolmogorov-Smirnov test ## ## data: ROCRPlot$x and ROCRPlot$y ## D = 0.25527, p-value &lt; 2.2e-16 ## alternative hypothesis: two-sided str(ROCRPerformance) ## Formal class &#39;performance&#39; [package &quot;ROCR&quot;] with 6 slots ## ..@ x.name : chr &quot;False positive rate&quot; ## ..@ y.name : chr &quot;True positive rate&quot; ## ..@ alpha.name : chr &quot;Cutoff&quot; ## ..@ x.values :List of 1 ## .. ..$ : num [1:255287] 0 0 0 0 0 0 0 0 0 0 ... ## ..@ y.values :List of 1 ## .. ..$ : num [1:255287] 0.00 4.79e-06 9.58e-06 1.44e-05 1.92e-05 ... ## ..@ alpha.values:List of 1 ## .. ..$ : num [1:255287] Inf 4.91 4.8 4.54 4.45 ... 3.10 Bin test set by prediction probEstimates &lt;- if_else(TestLogit$value &lt; 0, 0, TestLogit$value) summary(probEstimates / (1 + probEstimates)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0000 0.5115 0.6030 0.5677 0.6655 0.8307 ↩ "],
["conclusion.html", "Chapter 4 Conclusion", " Chapter 4 Conclusion Is the interest rate proposed by LC high enough? This report was one of those “it-builds-character” endeavour. Facing such a large dataset, it took a very long time before settling to address a particular question. Exploring the data lead to many blind alleys with little interest. As a practical tool, this approach would not work in real life: we have no data on rejected loans. Using this model to accept/reject loans would need more work (using Reject Inference). Currently only look at PD. Extend to LGD with Good Dollars and Bad Dollars instead of Good Loans / Bad Loans Further possible explorations: Address the unbalanced dataset by sampling a number of training samples whose size is identical to the test dataset. Perform PCA beforehand Improve the regularisation of the model parameters. Explore economic cycles/situations as additional entry. We use the entire dataset to estimate the impact of time as a polynomial curve. To assess future loans, this would not be acceptable. Only an online algorithm should be used. For example ARMA/ARIMA, Kalman filtering of the time-trend trajectory. Loss amount where good loan/bad loan proportion is replaced by a good dollar (repaid) / bad dollars (lost) fraction. See SAS Global Forum 2012. The size of the dataset is an issue to apply other techinques. But with stochastics methods, possible other models could be: Tree models which have numerous variations (CART generally, and simple or aggregated boosted decision trees specifically) Neural network "],
["appendix.html", "Appendix 4.1 List of assumptions / limitations regarding the dataset 4.2 Data preparation and formatting 4.3 List of variables 4.4 Calculations of the internal rate of returns and month-to-default 4.5 System version", " Appendix 4.1 List of assumptions / limitations regarding the dataset As mentioned during this report, we had to make numerous assumptions given the lack of clarity of the variable descriptions. Dataset quality: Aside from cents rounding issues, the dataset does not contain any flagrant errors that we could see (e.g. minor error of amount or rate, zipcode). Quality of the variable description is a different matter altogether. Ratings: The day-1 rating is between A1 and (and no lower than) G5. No note is rated lower than E5 after 6 November 2017, and lower than D5 after 30 June 2019. Credit history: Credit history information for the principal borrower relates to pre-approval and not post-funding. This is clear for the joint applicants, but simply an assumption for the principal borrower. Recoveries: Recoveries (if any) are assumed to be paid 3 months after the last scheduled payment date (variable last_pymnt_d) Survival effect: The dataset does not include applications that were rejected by the lender (for whatever reason) or by the borrower (for example because the interest rate quote is too high). It may also be the case that some actual loans were excluded as and when the dataset changed over the years. LIBOR funding rate: we use the 3-year and 5-year swap rates. In reality, we should have used average tenor-weighted swap rates (i.e. ca. 1.5 Y and 2.5 Y). This requires a full swap curve and more calculation than necessary for our purpose. The principles of this report should not be significantly affted by this approximation. We do hope that LendingClub investors receive information of much better quality! 4.2 Data preparation and formatting We used different sources of information: The LendingClub dataset made available on Kaggle; US geographical data about zip and FIPS codes; Market interest rates from the Saint Louis Federal Reserve Bank; and, Macro data from the same source. We here show the code used to prepare the data. It was automatically formatted by RStudio. 4.2.1 LendinClub dataset local({ # # STEP 1: Download the dataset # # Got to https://www.kaggle.com/wendykan/lending-club-loan-data # # Download into the &#39;datasets&#39; subdirectory # Unzip the file. # WARNING: The unzipping will be about 2.4GB # # Name the sql database &quot;datasets/lending_club.sqlite&quot; # # # STEP 2: Prepare the dabase as a tibble # ## ## WARNING: THIS ASSUMES A &#39;datasets&#39; DIRECTORY WAS CREATED ## library(RSQLite) db_conn &lt;- dbConnect(RSQLite::SQLite(), &quot;datasets/lending_club.sqlite&quot;) dbListTables(db_conn) # Returns a 2.96GB data frame lending_club &lt;- dbGetQuery(db_conn, &quot;SELECT * FROM loan&quot;) lending_club &lt;- as_tibble(lending_club) # Close the database dbDisconnect(db_conn) # Compressed to ca.285MB on disk saveRDS(lending_club, &quot;datasets/lending_club.rds&quot;) library(tidyverse) library(lubridate) library(hablar) # Before reformat in case the previous step was already done # lending_club &lt;- readRDS(&quot;datasets/lending_club.rds&quot;) # # str(lending_club) # # Leave the original dataset untouched and work with a copy. lc &lt;- lending_club lc &lt;- lc %&gt;% # Add loan identification number to track the loans across calculations mutate(loanID = row_number()) %&gt;% # Remove useless strings mutate( term = str_remove(term, &quot; months&quot;), emp_length = str_replace(emp_length, &quot;&lt;1&quot;, &quot;0&quot;), emp_length = str_replace(emp_length, &quot;10+&quot;, &quot;10&quot;), emp_length = str_remove(emp_length, &quot;years&quot;) ) %&gt;% # Creates dates out of strings - Parse errors will be raised when no dates. mutate( debt_settlement_flag_date = as_date(dmy( str_c(&quot;1-&quot;, debt_settlement_flag_date) )), earliest_cr_line = as_date(dmy(str_c( &quot;1-&quot;, earliest_cr_line ))), hardship_start_date = as_date(dmy(str_c( &quot;1-&quot;, hardship_start_date ))), hardship_end_date = as_date(dmy(str_c( &quot;1-&quot;, hardship_end_date ))), issue_d = as_date(dmy(str_c(&quot;1-&quot;, issue_d))), last_credit_pull_d = as_date(dmy(str_c( &quot;1-&quot;, last_credit_pull_d ))), last_pymnt_d = as_date(dmy(str_c( &quot;1-&quot;, last_pymnt_d ))), next_pymnt_d = as_date(dmy(str_c( &quot;1-&quot;, next_pymnt_d ))), payment_plan_start_date = as_date(dmy(str_c( &quot;1-&quot;, payment_plan_start_date ))), sec_app_earliest_cr_line = as_date(dmy(str_c( &quot;1-&quot;, sec_app_earliest_cr_line ))), settlement_date = as_date(dmy(str_c( &quot;1-&quot;, settlement_date ))) ) %&gt;% # Bulk type conversion with convert from the `hablar` package convert( # Strings chr(emp_title, title, url, zip_code), # Factors fct( addr_state, application_type, debt_settlement_flag, desc, disbursement_method, grade, hardship_flag, hardship_loan_status, hardship_reason, hardship_status, hardship_type, home_ownership, id, initial_list_status, loan_status, member_id, policy_code, purpose, pymnt_plan, settlement_status, sub_grade, verification_status, verification_status_joint ), # Integers int( acc_now_delinq, acc_open_past_24mths, chargeoff_within_12_mths, collections_12_mths_ex_med, deferral_term, delinq_2yrs, emp_length, hardship_dpd, hardship_length, inq_fi, inq_last_12m, inq_last_6mths, mo_sin_old_il_acct, mo_sin_old_rev_tl_op, mo_sin_rcnt_rev_tl_op, mo_sin_rcnt_tl, mort_acc, mths_since_last_delinq, mths_since_last_major_derog, mths_since_last_record, mths_since_rcnt_il, mths_since_recent_bc, mths_since_recent_bc_dlq, mths_since_recent_inq, mths_since_recent_revol_delinq, num_accts_ever_120_pd, num_actv_bc_tl, num_actv_rev_tl, num_bc_sats, num_bc_tl, num_il_tl, num_op_rev_tl, num_rev_accts, num_rev_tl_bal_gt_0, num_sats, num_tl_120dpd_2m, num_tl_30dpd, num_tl_90g_dpd_24m, num_tl_op_past_12m, open_acc, open_acc_6m, open_act_il, open_il_12m, open_il_24m, open_rv_12m, open_rv_24m, sec_app_chargeoff_within_12_mths, sec_app_collections_12_mths_ex_med, sec_app_inq_last_6mths, sec_app_mort_acc, sec_app_mths_since_last_major_derog, sec_app_num_rev_accts, sec_app_open_acc, sec_app_open_act_il, term ), # Floating point dbl( all_util, annual_inc, annual_inc_joint, avg_cur_bal, bc_open_to_buy, bc_util, collection_recovery_fee, delinq_amnt, dti, dti_joint, funded_amnt, funded_amnt_inv, hardship_amount, hardship_last_payment_amount, hardship_payoff_balance_amount, il_util, installment, int_rate, last_pymnt_amnt, loan_amnt, max_bal_bc, orig_projected_additional_accrued_interest, out_prncp, out_prncp_inv, pct_tl_nvr_dlq, percent_bc_gt_75, pub_rec, pub_rec_bankruptcies, recoveries, revol_bal, revol_bal_joint, revol_util, sec_app_revol_util, settlement_amount, settlement_percentage, tax_liens, tot_coll_amt, tot_cur_bal, tot_hi_cred_lim, total_acc, total_bal_ex_mort, total_bal_il, total_bc_limit, total_cu_tl, total_il_high_credit_limit, total_pymnt, total_pymnt_inv, total_rec_int, total_rec_late_fee, total_rec_prncp, total_rev_hi_lim ) ) %&gt;% # Converts some values to 1/-1 (instead of Boolean) mutate( pymnt_plan = if_else(pymnt_plan == &quot;y&quot;, 1, -1), hardship_flag = if_else(hardship_flag == &quot;Y&quot;, 1, -1), debt_settlement_flag = if_else(debt_settlement_flag == &quot;Y&quot;, 1, -1) ) %&gt;% # Some values are percentages mutate( int_rate = int_rate / 100, dti = dti / 100, dti_joint = dti_joint / 100, revol_util = revol_util / 100, il_util = il_util / 100, all_util = all_util / 100, bc_open_to_buy = bc_util / 100, pct_tl_nvr_dlq = pct_tl_nvr_dlq / 100, percent_bc_gt_75 = percent_bc_gt_75 / 100, sec_app_revol_util = sec_app_revol_util / 100 ) %&gt;% # Create quasi-centered numerical grades out of grade factors with &quot;A&quot; = 3 down to &quot;G&quot; = -3 mutate(grade_num = 4 - as.integer(grade)) %&gt;% # Ditto with sub_grades. &quot;A1&quot; = +3.4, &quot;A3&quot; = +3.0, down to &quot;G3&quot; = -3.0, &quot;G5&quot; = -3.4 mutate(sub_grade_num = 3.6 - as.integer(sub_grade) / 5) %&gt;% # Keep the first 3 digits of the zipcode as numbers mutate(zip_code = as.integer(str_sub(zip_code, 1, 3))) %&gt;% # order by date arrange(issue_d) %&gt;% # Remove empty columns select(-id, -member_id, -url) saveRDS(lc, &quot;datasets/lending_club_reformatted.rds&quot;) # Select loans which have matured or been terminated past_loans &lt;- lc %&gt;% filter( loan_status %in% c( &quot;Charged Off&quot;, &quot;Does not meet the credit policy. Status:Charged Off&quot;, &quot;Does not meet the credit policy. Status:Fully Paid&quot;, &quot;Fully Paid&quot; ) ) saveRDS(past_loans, &quot;datasets/lending_club_reformatted_paid.rds&quot;) }) 4.2.2 Zip codes and FIPS codes The R package zipcode was installed. # # ZIPCodes dataset. # library(zipcode) data(zipcode) zips &lt;- zipcode %&gt;% as_tibble() %&gt;% mutate(zip = as.integer(str_sub(zip, 1, 3))) saveRDS(zips, &quot;datasets/zips.rds&quot;) A csv file containing zip codes, FIPS codes and population information was downloaded from the Simple Maps16 website. local({ kaggleCodes &lt;- read.csv(&quot;datasets/csv/ZIP-COUNTY-FIPS_2017-06.csv&quot;) kaggleCodes &lt;- kaggleCodes %&gt;% as_tibble() %&gt;% mutate(zip = floor(ZIP/100), FIPS = STCOUNTYFP, COUNTYNAME = str_replace(COUNTYNAME, pattern = &quot;County&quot;, replacement = &quot;&quot;), COUNTYNAME = str_replace(COUNTYNAME, pattern = &quot;Borough&quot;, replacement = &quot;&quot;), COUNTYNAME = str_replace(COUNTYNAME, pattern = &quot;Municipio&quot;, replacement = &quot;&quot;), COUNTYNAME = str_replace(COUNTYNAME, pattern = &quot;Parish&quot;, replacement = &quot;&quot;), COUNTYNAME = str_replace(COUNTYNAME, pattern = &quot;Census Area&quot;, replacement = &quot;&quot;)) %&gt;% rename(county = COUNTYNAME) %&gt;% select(zip, county, FIPS) %&gt;% arrange(zip) saveRDS(zipfips, &quot;datasets/kaggleCodes.rds&quot;) }) 4.2.3 Market interest rates Market interest rates (3-year and 5-year swap rates) were download from the Saint Louis Federal Reserve Bank. Datasets are split between before and after the LIBOR fixing scandal. The datasets are merged with disctinct dates. Download sources are: Pre-LIBOR 3-y swap https://fred.stlouisfed.org/series/DSWP3 Post-LIBOR 3-y swap https://fred.stlouisfed.org/series/ICERATES1100USD3Y Pre-LIBOR 5-y swap https://fred.stlouisfed.org/series/MSWP5 Post-LIBOR 5-y swap https://fred.stlouisfed.org/series/ICERATES1100USD5Y local({ LIBOR3Y &lt;- read.csv(&quot;datasets/csv/DSWP3.csv&quot;) %&gt;% as_tibble() %&gt;% filter(DSWP3 != &quot;.&quot;) %&gt;% mutate(DATE = as_date(DATE), RATE3Y = as.numeric(as.character(DSWP3)) / 100) %&gt;% select(DATE, RATE3Y) ICE3Y &lt;- read.csv(&quot;datasets/csv/ICERATES1100USD3Y.csv&quot;) %&gt;% as_tibble() %&gt;% filter(ICERATES1100USD3Y != &quot;.&quot;) %&gt;% mutate(DATE = as_date(DATE), RATE3Y = as.numeric(as.character(ICERATES1100USD3Y)) / 100) %&gt;% select(DATE, RATE3Y) LIBOR5Y &lt;- read.csv(&quot;datasets/csv/DSWP5.csv&quot;) %&gt;% as_tibble() %&gt;% filter(DSWP5 != &quot;.&quot;) %&gt;% mutate(DATE = as_date(DATE), RATE5Y = as.numeric(as.character(DSWP5)) / 100) %&gt;% select(DATE, RATE5Y) ICE5Y &lt;- read.csv(&quot;datasets/csv/ICERATES1100USD5Y.csv&quot;) %&gt;% as_tibble() %&gt;% filter(ICERATES1100USD5Y != &quot;.&quot;) %&gt;% mutate(DATE = as_date(DATE), RATE5Y = as.numeric(as.character(ICERATES1100USD5Y)) / 100) %&gt;% select(DATE, RATE5Y) RATES3Y &lt;- LIBOR3Y %&gt;% rbind(ICE3Y) %&gt;% arrange(DATE) %&gt;% distinct(DATE, .keep_all = TRUE) RATES5Y &lt;- LIBOR5Y %&gt;% rbind(ICE5Y) %&gt;% arrange(DATE) %&gt;% distinct(DATE, .keep_all = TRUE) saveRDS(RATES3Y, &quot;datasets/rates3Y.rds&quot;) saveRDS(RATES5Y, &quot;datasets/rates5Y.rds&quot;) # Note there are 7212 days from 1 Jan 2000 to 30 Sep 2019 # # (ymd(&quot;2000-01-01&quot;) %--% ymd(&quot;2019-09-30&quot;)) %/% days(1) RATES &lt;- tibble(n = seq(0, 7212)) %&gt;% # Create a column with all dates mutate(DATE = ymd(&quot;2000-01-01&quot;) + days(n)) %&gt;% select(-n) %&gt;% # Add all daily 3- then 5-year rates and fill missing down left_join(RATES3Y) %&gt;% fill(RATE3Y, .direction = &quot;down&quot;) %&gt;% left_join(RATES5Y) %&gt;% fill(RATE5Y, .direction = &quot;down&quot;) saveRDS(RATES, &quot;datasets/rates.rds&quot;) }) 4.2.4 Macro-economical data Macro-economical datasets were sourced from the same website as Microsoft Excel files. They were converted as-is to tab-separated csv files with LibreOffice. Median income per household: https://geofred.stlouisfed.org/map/?th=pubugn&amp;cc=5&amp;rc=false&amp;im=fractile&amp;sb&amp;lng=-112.41&amp;lat=44.31&amp;zm=4&amp;sl&amp;sv&amp;am=Average&amp;at=Not%20Seasonally%20Adjusted,%20Annual,%20Dollars&amp;sti=2022&amp;fq=Annual&amp;rt=county&amp;un=lin&amp;dt=2017-01-01 Per capita personal income: https://geofred.stlouisfed.org/map/?th=pubugn&amp;cc=5&amp;rc=false&amp;im=fractile&amp;sb&amp;lng=-112.41&amp;lat=44.31&amp;zm=4&amp;sl&amp;sv&amp;am=Average&amp;at=Not%20Seasonally%20Adjusted,%20Annual,%20Dollars&amp;sti=882&amp;fq=Annual&amp;rt=county&amp;un=lin&amp;dt=2017-01-01 Unemployment: https://geofred.stlouisfed.org/map/?th=rdpu&amp;cc=5&amp;rc=false&amp;im=fractile&amp;sb&amp;lng=-90&amp;lat=40&amp;zm=4&amp;sl&amp;sv&amp;am=Average&amp;at=Not%20Seasonally%20Adjusted,%20Monthly,%20Percent&amp;sti=1224&amp;fq=Monthly&amp;rt=county&amp;un=lin&amp;dt=2019-08-01 local({ ################################################################################################### ## ## Median income per household by FIPS from 2002 to 2017 ## # Prepare median income medianIncome &lt;- # Load the dataset after dropping the first line read.csv( &quot;datasets/csv/GeoFRED_Estimate_of_Median_Household_Income_by_County_Dollars.csv&quot;, sep = &quot;\\t&quot;, skip = 1, stringsAsFactors = FALSE ) %&gt;% # Drops columnsn containing a unique identifier and the FIPS name select(-&quot;Series.ID&quot;, -&quot;Region.Name&quot;) %&gt;% # Rename the relevant column to &#39;FIPS&#39; rename(FIPS = &quot;Region.Code&quot;) %&gt;% # Order by FIPS arrange(FIPS) %&gt;% # Convert to a &#39;long&#39; table, i.e. one column for FIPS, one for date, one for income pivot_longer(cols = starts_with(&quot;X&quot;), names_to = &quot;Date&quot;, values_to = &quot;medianIncome&quot;) %&gt;% # Create actual dates mutate(Date = str_replace(Date, &quot;[X]&quot;, &quot;&quot;), Date = ymd(str_c(Date, &quot;-12-31&quot;))) saveRDS(medianIncome, &quot;datasets/medianincome.rds&quot;) ################################################################################################### ## ## Per capita income by FIPS from 2002 to 2017 ## personalIncome &lt;- # Load the dataset after dropping the first line read.csv( &quot;datasets/csv/GeoFRED_Per_Capita_Personal_Income_by_County_Dollars.csv&quot;, sep = &quot;\\t&quot;, skip = 1, stringsAsFactors = FALSE ) %&gt;% # Drops columnsn containing a unique identifier and the FIPS name select(-&quot;Series.ID&quot;, -&quot;Region.Name&quot;) %&gt;% # Rename the relevant column to &#39;FIPS&#39; rename(FIPS = &quot;Region.Code&quot;) %&gt;% # Order by FIPS arrange(FIPS) %&gt;% # Convert to a &#39;long&#39; table, i.e. one column for FIPS, one for date, one for income pivot_longer(cols = starts_with(&quot;X&quot;), names_to = &quot;Date&quot;, values_to = &quot;personalIncome&quot;) %&gt;% # Create actual dates mutate(Date = str_replace(Date, &quot;[X]&quot;, &quot;&quot;), Date = ymd(str_c(Date, &quot;-12-31&quot;))) saveRDS(personalIncome, &quot;datasets/personalincome.rds&quot;) ################################################################################################### ## ## Unemplyment rate monthly by FIPS from January 2000 to August 2019 ## unemploymentRate &lt;- # Load the dataset after dropping the first line read.csv( &quot;datasets/csv/GeoFRED_Unemployment_Rate_by_County_Percent.csv&quot;, sep = &quot;\\t&quot;, skip = 1, stringsAsFactors = FALSE ) %&gt;% # Drops columnsn containing a unique identifier and the FIPS name select(-&quot;Series.ID&quot;, -&quot;Region.Name&quot;) %&gt;% # Rename the relevant column to &#39;FIPS&#39; rename(FIPS = &quot;Region.Code&quot;) %&gt;% # Order by FIPS arrange(FIPS) %&gt;% mutate_all(as.double) %&gt;% # Convert to a &#39;long&#39; table, i.e. one column for FIPS, one for date, one for income pivot_longer(cols = starts_with(&quot;X&quot;), names_to = &quot;Date&quot;, values_to = &quot;unemploymentRate&quot;, values_ptypes = c(&quot;unemploymentRate&quot;, numeric)) %&gt;% # Converts the content of the Year column to an actual date mutate( Date = str_replace(Date, &quot;[X]&quot;, &quot;&quot;), Date = str_replace(Date, &quot;[.]&quot;, &quot;-&quot;), Date = ymd(str_c(Date, &quot;-1&quot;)) ) saveRDS(unemploymentRate, &quot;datasets/unemployment.rds&quot;) }) 4.3 List of variables This table presents the list of variables provided in the original dataset. The descriptions come from a spreadsheet attached with the dataset and, unfortunately, are not extremely precise and subject to interpretation. We added comments and/or particular interpretations in CAPITAL LETTERS. LC_variable %&gt;% select(variable_name, description) %&gt;% # Format the table. kable( &quot;latex&quot;, caption = &quot;Description of the dataset variables as provided in the dataset downloaded from Kaggle&quot;, booktabs = T, longtable = T, col.names = c(&quot;Variable Name&quot;, &quot;Description&quot;) ) %&gt;% kable_styling(full_width = F, latex_options = c(&quot;repeat_header&quot;)) %&gt;% column_spec(1, width = &quot;7cm&quot;) %&gt;% column_spec(2, width = &quot;7cm&quot;) 4.4 Calculations of the internal rate of returns and month-to-default The following shows two versions of the same code. The R version is provided because of the description of the assignment. However, the R version takes just under a full day to run. A Julia version, which is a direct translation of the R code, runs in about 150s (ca. 500x faster). 4.4.1 R code ################################################################################################### # # Given some numerical parameters describing a loan in the dataset, returns its Internal Rate # of Return. # # In the first instance, the function creates a schedule of payments. # In many cases, the schedule will be extremely simple: a series of 36 or 60 equal instalements. # # But in some cases, a loan repayment are accelerated. Therefore the total amount of interest will # be lower than expected (but this is good for the investor because highe interest rate over # shorter tenor.). # # In other cases, the borrower defaults. Overall payments are less than expected. # # Based on the limited information of the dataset, the function makes educated guesses on the exact schedule. # # WARNING: THIS IS NOT OPTIMISED. RUNNING THIS FOR ALL LOANS (1.3 MLN OF THEM) TAKES CA.20 HOURS !!!! # calculateIRR &lt;- function(loanNumber = 1, loan = 1000, intRate = 0.02, term = 36, totalPaid = 1000, totalPrincipalPaid, totalInterestPaid, recoveries = 0, lateFees = 0, showSchedule = FALSE) { require(tidyverse) # number of monthly payments. # It exceeds 60 months in case recoveries on a 60-month loan takes the schedule after 60 months. nMonths &lt;- 90 # Months after which a loan defaults (normal tenor if no default or early prepayment) monthDefault = term # Note: *100 /100 to calculate in cent because ceiling cannot specify significant digits. installment &lt;- ceiling(100 * loan * intRate / 12 / (1 - 1 / (1 + intRate / 12) ^ term)) / 100 # We create a schedule schedule &lt;- tibble( month = 0:nMonths, monthlyPayment = 0.0, totalPandI = 0.0, totalI = 0.0, totalP = 0.0 ) for (i in 2:(nMonths + 2)) { # Get situation at the end of previous month previousTotalPandI &lt;- as.numeric(schedule[i - 1, &quot;totalPandI&quot;]) previousTotalP &lt;- as.numeric(schedule[i - 1, &quot;totalP&quot;]) previousTotalI &lt;- as.numeric(schedule[i - 1, &quot;totalI&quot;]) # This is the beginning of a new month. First and foremost, the borrower is expected to pay the # accrued interest on amount of principal outstanding. # ceiling doesn&#39;t seem accept to accept significative digits. accruedInterest &lt;- ceiling(100 * (loan - previousTotalP) * intRate / 12) / 100 # If that amount takes the schedule above the total amount of interest shown in the data set, # we should stop the schedule at this point if (previousTotalI + accruedInterest &gt; totalInterestPaid) { # We stop the normal schedule at this date. # Interest is paid (although less than scheduled) schedule[i, &quot;monthlyPayment&quot;] &lt;- totalInterestPaid - previousTotalI # As well as whatever principal is left as per the dataset schedule[i, &quot;monthlyPayment&quot;] &lt;- schedule[i, &quot;monthlyPayment&quot;] + totalPrincipalPaid - previousTotalP # Then 3-month after the last payment date, recoveries and and late fees are paid schedule[i + 3, &quot;monthlyPayment&quot;] &lt;- schedule[i + 3, &quot;monthlyPayment&quot;] + recoveries + lateFees # Not really useful, but for completeness schedule[i, &quot;totalPandI&quot;] &lt;- totalPaid schedule[i, &quot;totalI&quot;] &lt;- totalInterestPaid schedule[i, &quot;totalP&quot;] &lt;- totalPrincipalPaid # If total principal paid is less than borrower, then it is a default, and the monthDefault # is adjusted. if (totalPrincipalPaid &lt; loan) { monthDefault = i } # No more payments to add to the schedule break() } else { # Deal with normal schedule schedule[i, &quot;monthlyPayment&quot;] &lt;- installment schedule[i, &quot;totalPandI&quot;] &lt;- schedule[i - 1, &quot;totalPandI&quot;] + installment schedule[i, &quot;totalI&quot;] &lt;- schedule[i - 1, &quot;totalI&quot;] + accruedInterest schedule[i, &quot;totalP&quot;] &lt;- schedule[i - 1, &quot;totalP&quot;] + installment - accruedInterest } } # At this point schedule[, &quot;monthlyPayment&quot;] contains the schedule of all payments, but needs to # include the initial loan. schedule[1, &quot;monthlyPayment&quot;] &lt;- -loan if (showSchedule) { schedule %&gt;% view() } NPV &lt;- function(interest, cashFlow) { t = 0:(length(cashFlow) - 1) sum(cashFlow / (1 + interest) ^ t) } IRR &lt;- function(CF) { res &lt;- NA try({ res &lt;- uniroot(NPV, c(-0.9, 1), cashFlow = CF)$root }, silent = TRUE) return(res) } return(tibble( loanID = loanNumber, IRR = round(as.numeric(IRR( schedule$monthlyPayment ) * 12), digits = 4), monthDefault = monthDefault )) } loanNumberIRR &lt;- function(loanNumber) { require(tidyverse) l &lt;- loans %&gt;% filter(loanID == loanNumber) calculateIRR( loanNumber = l$loanID, loan = l$funded_amnt, intRate = l$int_rate, term = l$term, totalPaid = l$total_pymnt, totalPrincipalPaid = l$total_rec_prncp, totalInterestPaid = l$total_rec_int, recoveries = l$recoveries, lateFees = l$total_rec_late_fee, showSchedule = TRUE ) } # # Calculate all the IRRs and month of default for all the loans. # WARNING: This takes around a full day to run!!!! # # The actual data was generated by the Julia version, with cross-checks. # Julia version takes about 150 sec on the same unoptimised code. # local({ loansIRR &lt;- loans %&gt;% rowwise() %&gt;% do( calculateIRR( loanNumber = .$loanID, loan = .$funded_amnt, intRate = .$int_rate, term = .$term, totalPaid = .$total_pymnt, totalPrincipalPaid = .$total_rec_prncp, totalInterestPaid = .$total_rec_int, recoveries = .$recoveries, lateFees = .$total_rec_late_fee ) ) saveRDS(loansIRR, &quot;datasets/lending_club_IRRs.rds&quot;) }) 4.4.2 Julia code 4.4.2.1 Internal Rate of Return #################################################################################################### ## ## Prepare datasets ## ## Previously saved from R with: ## lending_club &lt;- readRDS(&quot;lending_club.rds&quot;); write.csv(lending_club, &quot;lending_club.rds&quot;) ## ## WARNING: 1.7GB on disk ## using CSV lendingClub = CSV.read(&quot;datasets/lending_club.csv&quot;; delim = &quot;,&quot;) #################################################################################################### ## ## IRR calculations ## ## Given some numerical parameters describing a loan in the dataset, returns its Internal Rate ## of Return. ## ## In the first instance, the function creates a schedule of payments. ## In many cases, the schedule will be extremely simple: a series of 36 or 60 equal instalements. ## ## But in some cases, a loan repayment are accelerated. Therefore the total amount of interest will ## be lower than expected (but this is good for the investor because highe interest rate over ## shorter tenor.). ## ## In other cases, the borrower defaults. Overall payments are less than expected. ## ## Based on the limited information of the dataset, the function makes educated guesses on the exact ## schedule. ## using DataFrames, Roots function calculateIRR(; loanNumber = 1, loan = 0.0, intRate = 0.0, term = 36, totalPaid = 0.0, totalPrincipalPaid = 0.0, totalInterestPaid = 0.0, recoveries = 0.0, lateFees = 0.0, showSchedule = false) # number of monthly payments. # It exceeds 60 months in case recoveries on a 60-month loan takes the schedule after 60 months. nMonths = 90 # Months after which a loan defaults (normal tenor if no default or early prepayment) monthDefault = term # Note: *100 /100 to calculate in cent because ceiling cannot specify significant digits. installment = ceil(loan * intRate / 12 / (1 - 1 / (1 + intRate / 12) ^ term), digits = 2) # We create a schedule schedule = DataFrame(month = 0:nMonths, monthlyPayment = 0.0, totalPandI = 0.0, totalI = 0.0, totalP = 0.0) for i in 2:(nMonths + 1) # Get situation at the end of previous month previousTotalPandI = schedule[i - 1, :totalPandI] previousTotalP = schedule[i - 1, :totalP] previousTotalI = schedule[i - 1, :totalI] # This is the beginning of a new month. First and foremost, the borrower is expected to pay the # accrued interest on amount of principal outstanding. # The installment is expected to cover that amount of interest and the rest goes to # reducing the principal due outstanding. accruedInterest = ceil((loan - previousTotalP) * intRate / 12; digits = 2) decreasePrincipal = installment - accruedInterest # If that amount takes the schedule above the total amount of interest shown in the data set, # we should stop the schedule at this point # This is a shortcut since we could have a payment higher than the interest due, but not enough # to cover the expected principal repayment. However, it works well in practice. if previousTotalI + accruedInterest &gt; totalInterestPaid # We stop the normal schedule at this date. # Interest is paid (although less than scheduled) schedule[i, :monthlyPayment] = totalInterestPaid - previousTotalI # As well as whatever principal is left as per the dataset schedule[i, :monthlyPayment] = schedule[i, :monthlyPayment] + totalPrincipalPaid - previousTotalP # Then 3-month after the last payment date, recoveries and and later fees are paid schedule[i + 3, :monthlyPayment] = schedule[i + 3, :monthlyPayment] + recoveries + lateFees # Not really useful, but for completeness schedule[i, :totalPandI] = totalPaid schedule[i, :totalI] = totalInterestPaid schedule[i, :totalP] = totalPrincipalPaid # If total principal paid is less than borrower, then it is a default, and the monthDefault # is adjusted. if (totalPrincipalPaid &lt; loan) monthDefault = i end # No more payments to add to the schedule break else # Deal with normal schedule schedule[i, :monthlyPayment] = installment schedule[i, :totalPandI] = schedule[i - 1, :totalPandI] + installment schedule[i, :totalI] = schedule[i - 1, :totalI] + accruedInterest schedule[i, :totalP] = schedule[i - 1, :totalP] + installment - accruedInterest end end # At this point schedule[, :monthlyPayment] contains the schedule of all payments, but needs to # include the initial loan. schedule[1, :monthlyPayment] = -loan if (showSchedule) print(schedule) end cashFlow = schedule[:,:monthlyPayment] ## ## Finding the IRR is equivalent to finding the root such that the NPV of the cash flow is zero. ## Julia has a function (see below) called `find_zero` to do that which requires a function to ## be zeroed. This helper function is defined as NPV. ## function NPV(interest) t = 0:(length(cashFlow) - 1) ## If you are new to Julia, note the dot before the operation. This indicates that the ## operation has to be done element-wise (called `broadcasting` in Julia-ese). ## Otherwise, Julia would try to divide one vector by another vector, which makes no sense. ## This is also exactly the approach taken in Matlab/Octave. return sum(cashFlow ./ (1 + interest) .^ t) end ## Finds the root, catching any problems which would instead return the R equivalent of NA rootInterest = try round(12 * find_zero(NPV, (-0.9, 1.0), Bisection(); xatol = 0.000001); digits = 4) catch e NaN end return(( loanID = loanNumber, IRR = rootInterest, monthDefault = monthDefault )) end ## ## Calculate the IRR and repayment schedule of a particular loan identified by its loanID function loanNumberIRR(loanNumber) l = lc[ lc[:, :Column1] .== loanNumber, :] global lc calculateIRR(loanNumber = l[1, :Column1], loan = l[1, :funded_amnt], intRate = l[1, :int_rate], term =l[1, :tenor], totalPaid = l[1, :total_pymnt], totalPrincipalPaid = l[1, :total_rec_prncp], totalInterestPaid = l[1, :total_rec_int], recoveries = l[1, :recoveries], lateFees = l[1, :total_rec_late_fee], showSchedule = true) end #################################################################################################### ## ## Quick check ## calculateIRR(loanNumber = 1, loan = 5600, intRate = 0.1299, term = 36, totalPaid = 6791.72, totalPrincipalPaid = 5600, totalInterestPaid = 1191.72, recoveries = 0, lateFees = 0, showSchedule = true) calculateIRR(loanNumber = 1, loan = 35000, intRate = 0.1820, term = 60, totalPaid = 26600.1, totalPrincipalPaid = 3874.72, totalInterestPaid = 5225.38, recoveries = 17500, lateFees = 0.0, showSchedule = false) calculateIRR(loanNumber = 1734666, loan = 35000, intRate = 0.0797, term = 36, totalPaid = 1057.04, totalPrincipalPaid = 863.83, totalInterestPaid = 193.72, recoveries = 0, lateFees = 0, showSchedule = false) ## ## Look for the loans which have gone to their end ## indextmp = (lendingClub.loan_status .== &quot;Fully Paid&quot;) .| (lendingClub.loan_status .== &quot;Charged Off&quot;) .| (lendingClub.loan_status .== &quot;Does not meet the credit policy. Status:Charged Off&quot;) .| (lendingClub.loan_status .== &quot;Does not meet the credit policy. Status:Fully Paid&quot;) ## Create the dataset we will use - Should be the same as lending_club_reformatted_paid.rds lc = lendingClub[indextmp, :] ## Select relevant variables to calculate profitability ## Column1 contains the loanID&#39;s cols = [:Column1, :funded_amnt, :int_rate, :term, :total_pymnt, :total_rec_prncp, :total_rec_int, :recoveries, :total_rec_late_fee] lc = select(lc, cols) ## Interest rates as percentage lc[:, :int_rate] = lc[:, :int_rate] ./ 100 ## Create a new column lc[:tenor] = 0 ## that will record the official loan tenor as a number (instead of string) lc[startswith.( lc[:, :term], &quot; 36&quot;), :tenor] .= 36 lc[startswith.( lc[:, :term], &quot; 60&quot;), :tenor] .= 60 ## New data frame to store the results IRR_Result = DataFrame(loanID = zeros(Int64, nrow(lc)), IRR = zeros(Float64, nrow(lc)), monthDefault = zeros(Int64, nrow(lc))) # ~150 sec. to do the whole dataset @time for i in 1:nrow(lc) global IRR_Result # Use multiple-return-value (IRR_Result[i, :loanID], IRR_Result[i, :IRR], IRR_Result[i, :monthDefault]) = calculateIRR( loanNumber = lc[i, :Column1], loan = lc[i, :funded_amnt], intRate = lc[i, :int_rate], term =lc[i, :tenor], totalPaid = lc[i, :total_pymnt], totalPrincipalPaid = lc[i, :total_rec_prncp], totalInterestPaid = lc[i, :total_rec_int], recoveries = lc[i, :recoveries], lateFees = lc[i, :total_rec_late_fee], showSchedule = false) end IRR_Result[1:10,:] # Check loanNumberIRR(171) CSV.write(&quot;datasets/loanIRR.csv&quot;, IRR_Result) 4.4.2.2 Credit margins #################################################################################################### ## ## Prepare datasets ## ## Previously saved from R with: ## lending_club &lt;- readRDS(&quot;lending_club.rds&quot;); write.csv(lending_club, &quot;lending_club.rds&quot;) ## ## WARNING: 1.7GB on disk ## using CSV lendingClub = CSV.read(&quot;datasets/lending_club.csv&quot;; delim = &quot;,&quot;) #################################################################################################### ## ## CREDIT MARGIN ## ## This method of approximating the credit margin is far less sophisticated than what FI&#39;s do. ## ## We need to calculate what the credit margin should be on a defaulted loan to get a nil NPV. ## ## On a risk free loan the CF will be P+I at risk-free on _both_ borrowing and lending sides. ## ## On a defaulted loan, the CF will be: ## borrowing unchanged = P&amp;I at risk-free ## and ## lending P&amp;I at (risk-free + credit margin) until before default, then recoveries+fees. ## ## The principal amortisation profile depends on the credit margin used. We will arbitrarily use ## 20% which is a conservative assumption. ## ## credit risk on that CF should be nil with the right margin when discounted at risk-free. ## ## The function is very similar to the IRR calculation. ## using DataFrames, Roots # number of monthly payments to model # It exceeds 60 months in case recoveries on a 60-month loan takes the schedule after 60 months. const nMonths = 90 # Sculpt credit foncier profiles over 36 and 60 months at 20% per annum. # The profile is expressed as percentage of loan amount function CreateCreditFoncier(;n = 36, riskFree = 0.0) instalment = 1 * riskFree/12 * 1 / (1 - 1 / (1 + riskFree/12) ^ n) # We create a schedule schedule = DataFrame(month = 0:nMonths, payment = 0.0) # Add the day 1 principal outlay schedule[1, :payment] = -1 schedule[2:(n+1), :payment] = instalment return(schedule) end # Solve for the credit margin function CreditMargin(; loanNumber = 1, loan = 1000.0, intRate = 0.05, term = 36, totalPaid = 1000.0, totalPrincipalPaid = 700.0, totalInterestPaid = 50.0, recoveries = 0.0, lateFees = 0.0, riskFree = 0.01, showSchedule = false) # Months after which a loan defaults (normal tenor if no default or early prepayment) monthDefault = term # Monthly instlment instalment = ceil(loan * intRate/12 / (1 - 1 / (1 + intRate/12) ^ term), digits = 2) # Create a blank schedule schedule = DataFrame(month = 0:nMonths, monthlyPayment = 0.0, principalPayment = 0.0, totalPandI = 0.0, totalI = 0.0, totalP = 0.0) for i in 2:(nMonths + 1) # Get situation at the end of previous month previousTotalPandI = schedule[i - 1, :totalPandI] previousTotalP = schedule[i - 1, :totalP] previousTotalI = schedule[i - 1, :totalI] # This is the beginning of a new month. First and foremost, the borrower is expected to pay the # accrued interest on amount of principal outstanding. # The instalment is expected to cover that amount of interest and the rest goes to # reducing the principal due outstanding. accruedInterest = ceil((loan - previousTotalP) * intRate/12; digits = 2) decreasePrincipal = instalment - accruedInterest # If that amount takes the schedule above the total amount of interest shown in the data set, # we should stop the schedule at this point # This is a shortcut since we could have a payment higher than the interest due, but not enough # to cover the expected principal repayment. However, it works well in practice. if previousTotalI + accruedInterest &gt; totalInterestPaid # We stop the normal schedule at this date. # Interest is paid (although less than scheduled) schedule[i, :monthlyPayment] = totalInterestPaid - previousTotalI # Whatever principal is left as per the dataset schedule[i, :monthlyPayment] += totalPrincipalPaid - previousTotalP # Then 3-month after the last payment date, recoveries and and later fees are paid schedule[i + 3, :principalPayment] += recoveries + lateFees # Not really useful, but for completeness schedule[i, :totalPandI] = totalPaid schedule[i, :totalI] = totalInterestPaid schedule[i, :totalP] = totalPrincipalPaid # If total principal paid is less than borrower, then it is a default, and the monthDefault # is adjusted. if (totalPrincipalPaid &lt; loan) monthDefault = i end # No more payments to add to the schedule break else # Deal with normal schedule schedule[i, :monthlyPayment] = instalment schedule[i, :principalPayment] = decreasePrincipal schedule[i, :totalPandI] = schedule[i-1, :totalPandI] + instalment schedule[i, :totalI] = schedule[i-1, :totalI] + accruedInterest schedule[i, :totalP] = schedule[i-1, :totalP] + decreasePrincipal end end # At this point schedule[, :monthlyPayment] contains the schedule of all payments, but needs to # include the initial loan. schedule[1, :principalPayment] = -loan if (showSchedule) println(&quot;Payments&quot;) println(schedule) end # Principal profile on the borrowing side creditFoncier = round.(CreateCreditFoncier(n = term, riskFree = riskFree)[:, :payment] .* loan; digits = 2) # For a given margin, calculate the _net_ NPV between the what is borrowed at the risk-free rate # and what is earned on the loan principal profile (possibly shortned because of default) # carrying an interest of risk-free + credit margin function NetNPV(margin) # We need to store the calculated interest interestSchedule = DataFrame(month = 0:nMonths, interestPayment = 0.0) # For each month, calculate the amount of interest with the credit margin for i in 2:(monthDefault + 1) outstandingPrincipal = sum(schedule[1:(i - 1), :principalPayment]) interestSchedule[i, :interestPayment] = -round((riskFree + margin)/12 * outstandingPrincipal; digits = 2) end # Net final cashflow is: # total principal and interest cashflow on the lending side # less # borrowing profile cashFlow = schedule[:, :principalPayment] .+ interestSchedule[:, :interestPayment] cashFlow = cashFlow .- creditFoncier return sum(cashFlow ./ (1 + riskFree/12) .^ (0:nMonths)) end # rootInterest = round(find_zero(NetNPV, (-0.5, 10), Bisection()); digits = 6) rootInterest = try rootInterest = round(find_zero(NetNPV, (-0.5, 10), Bisection()); digits = 6) catch e NaN end return(( loanID = loanNumber, creditMargin = rootInterest, monthDefault = monthDefault )) end #################################################################################################### ## ## Quick check ## CreditMargin(loanNumber = 1, loan = 5600, intRate = 0.1299, term = 36, totalPaid = 6791.72, totalPrincipalPaid = 5600, totalInterestPaid = 1191.72, recoveries = 0, lateFees = 0, riskFree = 0.02, showSchedule = false) CreditMargin(loanNumber = 1, loan = 35000, intRate = 0.1820, term = 60, totalPaid = 26600.1, totalPrincipalPaid = 3874.72, totalInterestPaid = 5225.38, recoveries = 17500, lateFees = 0.0, riskFree = 0.02, showSchedule = true) CreditMargin(loanNumber = 1734666, loan = 35000, intRate = 0.0797, term = 36, totalPaid = 1057.04, totalPrincipalPaid = 863.83, totalInterestPaid = 193.72, recoveries = 0, lateFees = 0, riskFree = 0.02, showSchedule = true) ## ## Look for the loans which have gone to their end ## indextmp = (lendingClub.loan_status .== &quot;Fully Paid&quot;) .| (lendingClub.loan_status .== &quot;Charged Off&quot;) .| (lendingClub.loan_status .== &quot;Does not meet the credit policy. Status:Charged Off&quot;) .| (lendingClub.loan_status .== &quot;Does not meet the credit policy. Status:Fully Paid&quot;) ## Create the dataset we will use - Should be the same as lending_club_reformatted_paid.rds lc = lendingClub[indextmp, :] ## Select relevant variables to calculate profitability ## Column1 contains the loanID&#39;s cols = [:Column1, :funded_amnt, :int_rate, :term, :total_pymnt, :total_rec_prncp, :total_rec_int, :recoveries, :total_rec_late_fee] lc = select(lc, cols) ## Interest rates as percentage lc[!, :int_rate] = lc[!, :int_rate] ./ 100 ## Create a new column lc[:tenor] = 0 ## that will record the official loan tenor as a number (instead of string) lc[startswith.( lc[!, :term], &quot; 36&quot;), :tenor] .= 36 lc[startswith.( lc[!, :term], &quot; 60&quot;), :tenor] .= 60 ## New data frame to store the results creditMargin_Result = DataFrame(loanID = zeros(Int64, nrow(lc)), creditMargin = zeros(Float64, nrow(lc)), monthDefault = zeros(Int64, nrow(lc))) # ~4,700 sec. to do the whole dataset @time for i in 1:nrow(lc) global creditMargin_Result # Use multiple-return-value # 1h17m runtime (creditMargin_Result[i, :loanID], creditMargin_Result[i, :creditMargin], creditMargin_Result[i, :monthDefault]) = CreditMargin( loanNumber = lc[i, :Column1], loan = lc[i, :funded_amnt], intRate = lc[i, :int_rate], term =lc[i, :tenor], totalPaid = lc[i, :total_pymnt], totalPrincipalPaid = lc[i, :total_rec_prncp], totalInterestPaid = lc[i, :total_rec_int], recoveries = lc[i, :recoveries], lateFees = lc[i, :total_rec_late_fee], riskFree = 0.02, showSchedule = false) end creditMargin_Result[1:10,:] CSV.write(&quot;datasets/CreditMargins.csv&quot;, creditMargin_Result) 4.4.3 Maxima derivation of the cost function PDF1(x, Q) := alpha1( Q) * sqrt( 1 / ( 2 * pi)) * exp( - 1 / 2*(( log( -( x - m1( Q)) / m1( Q)) + sigma1( Q) ^ 2) / sigma1( Q)) ^ 2) / ( -( x - m1(Q)) * sigma1( Q)) ; PDF2(x, Q) := alpha2( Q) * sqrt( 1 / ( 2 * pi)) * exp( - 1 / 2*(( log( -( x - m2( Q)) / m2( Q)) + sigma2( Q) ^ 2) / sigma2( Q)) ^ 2) / ( -( x - m2( Q)) * sigma2( Q)) ; PDF3(x, Q) := alpha3( Q) * sqrt( 1 / ( 2 (* pi)) * exp( - 1 / 2*(( log( -( x - m3( Q)) / m3( Q)) + sigma3( Q) ^ 2) / sigma3( Q)) ^ 2) / ( -( x - m3( Q)) * sigma3( Q)) ; PDF4(x, Q) := alpha4( Q) * sqrt( 1 / ( 2 * pi)) * exp( - 1 / 2*(( log( ( x - m4( Q)) / m4( Q)) + sigma4( Q) ^ 2) / sigma4( Q)) ^ 2) / ( ( x - m4( Q)) * sigma4( Q)) ; alpha1(Q) := am1* Q + an1 ; alpha2(Q) := am2* Q + an2 ; alpha3(Q) := am3* Q + an3 ; alpha4(Q) := am4* Q + an4 ; m1(Q) := mm1* Q + mn1 ; m2(Q) := mm2* Q + mn2 ; m3(Q) := mm3* Q + mn3 ; m4(Q) := mm4* Q + mn4 ; sigma1(Q) := sm1* Q + sn1 ; sigma2(Q) := sm2* Q + sn2 ; sigma3(Q) := sm3* Q + sn3 ; sigma4(Q) := sm4* Q + sn4 ; J(x, Q): = -( x - ( PDF1( x, Q) + PDF2( x, Q) + PDF3( x, Q) + PDF4( x, Q))) ^ 2 ; diff( PDF1(x, Q), Q) ; 4.5 System version Sys.info() ## sysname release ## &quot;Linux&quot; &quot;5.3.0-24-generic&quot; ## version nodename ## &quot;#26-Ubuntu SMP Thu Nov 14 01:33:18 UTC 2019&quot; &quot;x260&quot; ## machine login ## &quot;x86_64&quot; &quot;unknown&quot; ## user effective_user ## &quot;emmanuel&quot; &quot;emmanuel&quot; https://simplemaps.com/data/us-zips↩ "],
["references.html", "References", " References # automatically create a bib database for R packages knitr::write_bib(c(.packages(), &quot;bookdown&quot;, &quot;knitr&quot;, &quot;rmarkdown&quot;), &quot;packages.bib&quot;) "]
]
