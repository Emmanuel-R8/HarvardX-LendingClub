<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Errands and post-mortem | LendingClub Loans Pricing</title>
  <meta name="description" content="HarvardX - PH125.9x Data Science Capstone" />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Errands and post-mortem | LendingClub Loans Pricing" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="HarvardX - PH125.9x Data Science Capstone" />
  <meta name="github-repo" content="Emmanuel_R8/HarvardX-LendingClub" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Errands and post-mortem | LendingClub Loans Pricing" />
  
  <meta name="twitter:description" content="HarvardX - PH125.9x Data Science Capstone" />
  

<meta name="author" content="Emmanuel Rialland - https://github.com/Emmanuel_R8" />


<meta name="date" content="2019-12-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="conclusion.html"/>
<link rel="next" href="appendix.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./introduction.html" target="blank>LendingClub Loans Pricing</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="internal-rate-of-return-credit-margins-and-net-present-values.html"><a href="internal-rate-of-return-credit-margins-and-net-present-values.html"><i class="fa fa-check"></i><b>1</b> Internal Rate of Return, Credit Margins and Net Present Values</a><ul>
<li class="chapter" data-level="1.1" data-path="internal-rate-of-return-credit-margins-and-net-present-values.html"><a href="internal-rate-of-return-credit-margins-and-net-present-values.html#background"><i class="fa fa-check"></i><b>1.1</b> Background</a></li>
<li class="chapter" data-level="1.2" data-path="internal-rate-of-return-credit-margins-and-net-present-values.html"><a href="internal-rate-of-return-credit-margins-and-net-present-values.html#internal-rate-of-return"><i class="fa fa-check"></i><b>1.2</b> Internal Rate of Return</a></li>
<li class="chapter" data-level="1.3" data-path="internal-rate-of-return-credit-margins-and-net-present-values.html"><a href="internal-rate-of-return-credit-margins-and-net-present-values.html#dataset-calculation"><i class="fa fa-check"></i><b>1.3</b> Dataset calculation</a><ul>
<li class="chapter" data-level="1.3.1" data-path="internal-rate-of-return-credit-margins-and-net-present-values.html"><a href="internal-rate-of-return-credit-margins-and-net-present-values.html#irr"><i class="fa fa-check"></i><b>1.3.1</b> IRR</a></li>
<li class="chapter" data-level="1.3.2" data-path="internal-rate-of-return-credit-margins-and-net-present-values.html"><a href="internal-rate-of-return-credit-margins-and-net-present-values.html#credit-margins"><i class="fa fa-check"></i><b>1.3.2</b> Credit Margins</a></li>
<li class="chapter" data-level="1.3.3" data-path="internal-rate-of-return-credit-margins-and-net-present-values.html"><a href="internal-rate-of-return-credit-margins-and-net-present-values.html#npv"><i class="fa fa-check"></i><b>1.3.3</b> NPV</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="dataset.html"><a href="dataset.html"><i class="fa fa-check"></i><b>2</b> Dataset</a><ul>
<li class="chapter" data-level="2.1" data-path="dataset.html"><a href="dataset.html#preamble"><i class="fa fa-check"></i><b>2.1</b> Preamble</a></li>
<li class="chapter" data-level="2.2" data-path="dataset.html"><a href="dataset.html#general-presentation"><i class="fa fa-check"></i><b>2.2</b> General presentation</a><ul>
<li class="chapter" data-level="2.2.1" data-path="dataset.html"><a href="dataset.html#business-volume"><i class="fa fa-check"></i><b>2.2.1</b> Business volume</a></li>
<li class="chapter" data-level="2.2.2" data-path="dataset.html"><a href="dataset.html#loan-lifecyle-and-status"><i class="fa fa-check"></i><b>2.2.2</b> Loan lifecyle and status</a></li>
<li class="chapter" data-level="2.2.3" data-path="dataset.html"><a href="dataset.html#loan-application"><i class="fa fa-check"></i><b>2.2.3</b> Loan application</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="dataset.html"><a href="dataset.html#rates"><i class="fa fa-check"></i><b>2.3</b> Rates</a><ul>
<li class="chapter" data-level="2.3.1" data-path="dataset.html"><a href="dataset.html#sec:feature-engineering"><i class="fa fa-check"></i><b>2.3.1</b> IRR and required credit margins</a></li>
<li class="chapter" data-level="2.3.2" data-path="dataset.html"><a href="dataset.html#choice-of-predictors"><i class="fa fa-check"></i><b>2.3.2</b> Choice of predictors</a></li>
<li class="chapter" data-level="2.3.3" data-path="dataset.html"><a href="dataset.html#interest-rates"><i class="fa fa-check"></i><b>2.3.3</b> Interest rates</a></li>
<li class="chapter" data-level="2.3.4" data-path="dataset.html"><a href="dataset.html#purpose"><i class="fa fa-check"></i><b>2.3.4</b> Purpose</a></li>
<li class="chapter" data-level="2.3.5" data-path="dataset.html"><a href="dataset.html#payments"><i class="fa fa-check"></i><b>2.3.5</b> Payments</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="dataset.html"><a href="dataset.html#net-present-value"><i class="fa fa-check"></i><b>2.4</b> Net present value</a><ul>
<li class="chapter" data-level="2.4.1" data-path="dataset.html"><a href="dataset.html#average-npv-and-credit-margin-by-subgrade"><i class="fa fa-check"></i><b>2.4.1</b> Average NPV and credit margin by subgrade</a></li>
<li class="chapter" data-level="2.4.2" data-path="dataset.html"><a href="dataset.html#distribution-of-principal-losses-by-rating"><i class="fa fa-check"></i><b>2.4.2</b> Distribution of principal losses by rating</a></li>
<li class="chapter" data-level="2.4.3" data-path="dataset.html"><a href="dataset.html#npv-distribution-by-rating"><i class="fa fa-check"></i><b>2.4.3</b> NPV distribution by rating</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="dataset.html"><a href="dataset.html#loan-decision"><i class="fa fa-check"></i><b>2.5</b> Loan decision</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html"><i class="fa fa-check"></i><b>3</b> Logistic Regression Model and Credit Scorecard</a><ul>
<li class="chapter" data-level="3.1" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#logistic-regression"><i class="fa fa-check"></i><b>3.1</b> Logistic Regression</a><ul>
<li class="chapter" data-level="3.1.1" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#data-preparation"><i class="fa fa-check"></i><b>3.1.1</b> Data preparation</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#binning-and-weight-of-evidence"><i class="fa fa-check"></i><b>3.2</b> Binning and Weight of Evidence</a><ul>
<li class="chapter" data-level="3.2.1" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#background-1"><i class="fa fa-check"></i><b>3.2.1</b> Background</a></li>
<li class="chapter" data-level="3.2.2" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#binning"><i class="fa fa-check"></i><b>3.2.2</b> Binning</a></li>
<li class="chapter" data-level="3.2.3" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#woe-and-iv-definitions"><i class="fa fa-check"></i><b>3.2.3</b> WOE and IV definitions</a></li>
<li class="chapter" data-level="3.2.4" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#calculating-woe-and-iv"><i class="fa fa-check"></i><b>3.2.4</b> Calculating WoE and IV</a></li>
<li class="chapter" data-level="3.2.5" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#loop-through-all-variables"><i class="fa fa-check"></i><b>3.2.5</b> Loop through all variables</a></li>
<li class="chapter" data-level="3.2.6" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#select-relevant-variables"><i class="fa fa-check"></i><b>3.2.6</b> Select relevant variables</a></li>
<li class="chapter" data-level="3.2.7" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#create-data-table-with-one-hot-encoding"><i class="fa fa-check"></i><b>3.2.7</b> Create data table with one-hot encoding</a></li>
<li class="chapter" data-level="3.2.8" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#comparison-of-individual-characteristics"><i class="fa fa-check"></i><b>3.2.8</b> Comparison of individual characteristics</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#logistic-regression-1"><i class="fa fa-check"></i><b>3.3</b> Logistic Regression</a><ul>
<li class="chapter" data-level="3.3.1" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#remove-identical-bins"><i class="fa fa-check"></i><b>3.3.1</b> Remove identical bins</a></li>
<li class="chapter" data-level="3.3.2" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#first-model---complete-dataset"><i class="fa fa-check"></i><b>3.3.2</b> First model - complete dataset</a></li>
<li class="chapter" data-level="3.3.3" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#second-training---fitted-model-less-colinear-bins"><i class="fa fa-check"></i><b>3.3.3</b> Second training - fitted model less colinear bins</a></li>
<li class="chapter" data-level="3.3.4" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#third-training---second-fitted-model-less-non-significant-bins"><i class="fa fa-check"></i><b>3.3.4</b> Third training - second fitted model less non-significant bins</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#model-results"><i class="fa fa-check"></i><b>3.4</b> Model results</a><ul>
<li class="chapter" data-level="3.4.1" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#final-list-of-variables"><i class="fa fa-check"></i><b>3.4.1</b> Final list of variables</a></li>
<li class="chapter" data-level="3.4.2" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#scoring"><i class="fa fa-check"></i><b>3.4.2</b> Scoring</a></li>
<li class="chapter" data-level="3.4.3" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#model-scorecard"><i class="fa fa-check"></i><b>3.4.3</b> Model scorecard</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#training-set"><i class="fa fa-check"></i><b>3.5</b> Training set</a><ul>
<li class="chapter" data-level="3.5.1" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#densities-of-the-training-results"><i class="fa fa-check"></i><b>3.5.1</b> Densities of the training results</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#test-set"><i class="fa fa-check"></i><b>3.6</b> Test set</a></li>
<li class="chapter" data-level="3.7" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#confusion-matrix"><i class="fa fa-check"></i><b>3.7</b> Confusion matrix</a></li>
<li class="chapter" data-level="3.8" data-path="logistic-regression-model-and-credit-scorecard.html"><a href="logistic-regression-model-and-credit-scorecard.html#roc-curve"><i class="fa fa-check"></i><b>3.8</b> ROC Curve</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>4</b> Conclusion</a></li>
<li class="chapter" data-level="5" data-path="errands-and-post-mortem.html"><a href="errands-and-post-mortem.html"><i class="fa fa-check"></i><b>5</b> Errands and post-mortem</a><ul>
<li class="chapter" data-level="5.1" data-path="errands-and-post-mortem.html"><a href="errands-and-post-mortem.html#modeling"><i class="fa fa-check"></i><b>5.1</b> Modeling</a></li>
<li class="chapter" data-level="5.2" data-path="errands-and-post-mortem.html"><a href="errands-and-post-mortem.html#geographical-data"><i class="fa fa-check"></i><b>5.2</b> Geographical data</a></li>
<li class="chapter" data-level="5.3" data-path="errands-and-post-mortem.html"><a href="errands-and-post-mortem.html#stochastic-gradient-descent"><i class="fa fa-check"></i><b>5.3</b> Stochastic Gradient Descent</a><ul>
<li class="chapter" data-level="5.3.1" data-path="errands-and-post-mortem.html"><a href="errands-and-post-mortem.html#conclusions"><i class="fa fa-check"></i><b>5.3.1</b> Conclusions</a></li>
<li class="chapter" data-level="5.3.2" data-path="errands-and-post-mortem.html"><a href="errands-and-post-mortem.html#gradient-descent"><i class="fa fa-check"></i><b>5.3.2</b> Gradient descent</a></li>
<li class="chapter" data-level="5.3.3" data-path="errands-and-post-mortem.html"><a href="errands-and-post-mortem.html#stochastic-gradient-descent-1"><i class="fa fa-check"></i><b>5.3.3</b> Stochastic Gradient Descent</a></li>
<li class="chapter" data-level="5.3.4" data-path="errands-and-post-mortem.html"><a href="errands-and-post-mortem.html#cost-function-for-multi-modal-npv"><i class="fa fa-check"></i><b>5.3.4</b> Cost function for multi-modal NPV</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="errands-and-post-mortem.html"><a href="errands-and-post-mortem.html#final-final-conclusion"><i class="fa fa-check"></i><b>5.4</b> Final final Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>6</b> Appendix</a><ul>
<li class="chapter" data-level="6.1" data-path="appendix.html"><a href="appendix.html#sec:list-assumptions"><i class="fa fa-check"></i><b>6.1</b> List of assumptions / limitations regarding the dataset</a></li>
<li class="chapter" data-level="6.2" data-path="appendix.html"><a href="appendix.html#data-preparation-and-formatting"><i class="fa fa-check"></i><b>6.2</b> Data preparation and formatting</a><ul>
<li class="chapter" data-level="6.2.1" data-path="appendix.html"><a href="appendix.html#sec:lendingclub-dataset"><i class="fa fa-check"></i><b>6.2.1</b> LendingClub dataset</a></li>
<li class="chapter" data-level="6.2.2" data-path="appendix.html"><a href="appendix.html#zip-codes-and-fips-codes"><i class="fa fa-check"></i><b>6.2.2</b> Zip codes and FIPS codes</a></li>
<li class="chapter" data-level="6.2.3" data-path="appendix.html"><a href="appendix.html#market-interest-rates"><i class="fa fa-check"></i><b>6.2.3</b> Market interest rates</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="appendix.html"><a href="appendix.html#sec:list-model-variables"><i class="fa fa-check"></i><b>6.3</b> List of variables</a></li>
<li class="chapter" data-level="6.4" data-path="appendix.html"><a href="appendix.html#maxima-derivation-of-the-cost-function"><i class="fa fa-check"></i><b>6.4</b> Maxima derivation of the cost function</a></li>
<li class="chapter" data-level="6.5" data-path="appendix.html"><a href="appendix.html#system-version"><i class="fa fa-check"></i><b>6.5</b> System version</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org/" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">LendingClub Loans Pricing</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="errands-and-post-mortem" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Errands and post-mortem</h1>
<p>This project took much longer that the MovieLens capstone. Here is a short list of ideas explored, pitfalls, lessons learned, and character-builders. This last section is written in the belief that knowing what does not work is as worthy as what does work.<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a></p>
<div id="modeling" class="section level2">
<h2><span class="header-section-number">5.1</span> Modeling</h2>
<p>One bit of advice I have known of, agreed with, and naturally set aside, was is to build early and small. In other words, deep and wide exploration of the dataset for the sake of it without modeling is wasteful of time and ideas. Modeling early, small and wrong (at least initially) is a better way to keep track of progress, a good sense of the eventual challenges, and suggest fruitful data exploration avenues. More importantly, it is in and by itself of form of exploration of the dataset. It also tends to explore the data wide-and-shallow rather than deep-but-narrow.</p>
<p>Having said that, I did some early exploration of models. Principal Component Analysis, naive Linear Regression, Extreme Boosting and Random Forest were toyed with. No model could be trained on the full set. I therefore came to limit the training set on a random sample of 0.1% (1 thousandth) of the initial full set.</p>
<p>I then went on a quest to formulate a model suitable for batch training (either simple sequential batches or stochastic) and gradient descent.</p>
<p>I also considered online training. However, an untested (and possibly completely wrong) intuition was that online methods are not adapted to an unbalanced dataset: the number of defaults/write-offs is low for high quality ratings. However, the dataset is evidently a time series which points to online training.</p>
<p>Along the way, the main unanswered question remained what to study out of the dataset: focus on a very narrow of variables? enrich it with other sources to study the impact of cyclical economic crises? determine an optimal pricing of each loan?</p>
<p>Let’s look at a couple of those:</p>
</div>
<div id="geographical-data" class="section level2">
<h2><span class="header-section-number">5.2</span> Geographical data</h2>
<p>We sourced US zip and FIPS (<em>Federal Information Processing Standards</em>) codes, and macroeconomical data for possible geographical statistics. The source code for the data import and reformatting is available in the GitHub repository.</p>
<p>Macro-economical datasets were sourced from the same website as Microsoft Excel files. They were converted as-is to tab-separated csv files with LibreOffice. Geofred turned out the best data source.</p>
<ul>
<li><p>Median income per household:
<a href="https://geofred.stlouisfed.org/map/?th=pubugn&amp;cc=5&amp;rc=false&amp;im=fractile&amp;sb&amp;lng=-112.41&amp;lat=44.31&amp;zm=4&amp;sl&amp;sv&amp;am=Average&amp;at=Not%20Seasonally%20Adjusted,%20Annual,%20Dollars&amp;sti=2022&amp;fq=Annual&amp;rt=county&amp;un=lin&amp;dt=2017-01-01">https://geofred.stlouisfed.org/map/?th=pubugn&amp;cc=5&amp;rc=false&amp;im=fractile&amp;sb&amp;lng=-112.41&amp;lat=44.31&amp;zm=4&amp;sl&amp;sv&amp;am=Average&amp;at=Not%20Seasonally%20Adjusted,%20Annual,%20Dollars&amp;sti=2022&amp;fq=Annual&amp;rt=county&amp;un=lin&amp;dt=2017-01-01</a></p></li>
<li><p>Per capita personal income:
<a href="https://geofred.stlouisfed.org/map/?th=pubugn&amp;cc=5&amp;rc=false&amp;im=fractile&amp;sb&amp;lng=-112.41&amp;lat=44.31&amp;zm=4&amp;sl&amp;sv&amp;am=Average&amp;at=Not%20Seasonally%20Adjusted,%20Annual,%20Dollars&amp;sti=882&amp;fq=Annual&amp;rt=county&amp;un=lin&amp;dt=2017-01-01">https://geofred.stlouisfed.org/map/?th=pubugn&amp;cc=5&amp;rc=false&amp;im=fractile&amp;sb&amp;lng=-112.41&amp;lat=44.31&amp;zm=4&amp;sl&amp;sv&amp;am=Average&amp;at=Not%20Seasonally%20Adjusted,%20Annual,%20Dollars&amp;sti=882&amp;fq=Annual&amp;rt=county&amp;un=lin&amp;dt=2017-01-01</a></p></li>
<li><p>Unemployment:
<a href="https://geofred.stlouisfed.org/map/?th=rdpu&amp;cc=5&amp;rc=false&amp;im=fractile&amp;sb&amp;lng=-90&amp;lat=40&amp;zm=4&amp;sl&amp;sv&amp;am=Average&amp;at=Not%20Seasonally%20Adjusted,%20Monthly,%20Percent&amp;sti=1224&amp;fq=Monthly&amp;rt=county&amp;un=lin&amp;dt=2019-08-01">https://geofred.stlouisfed.org/map/?th=rdpu&amp;cc=5&amp;rc=false&amp;im=fractile&amp;sb&amp;lng=-90&amp;lat=40&amp;zm=4&amp;sl&amp;sv&amp;am=Average&amp;at=Not%20Seasonally%20Adjusted,%20Monthly,%20Percent&amp;sti=1224&amp;fq=Monthly&amp;rt=county&amp;un=lin&amp;dt=2019-08-01</a></p></li>
</ul>
<p>Of key interest were indicators of economic stress with the following intuition: if a borrower had a good credit standing, traditional banks would provide cheaper access to credit. In times of financial distress (indicated by higher unemployment, lower GDP growth, income per household, …), we should see higher volumes of loans, and/or changes in the loan application patterns.</p>
<p>Given the time available, that data turned out to be too difficult to use:</p>
<ul>
<li><p>it was incomplete since the reported figures were not available over the entire timespan of the LendingClub dataset;</p></li>
<li><p>ZIP codes and FIPS location reference change over time, meaning that determining economic indicators for a given loan was no easy to automatise or would have require substantial time-consuming hand-made adjustment.</p></li>
</ul>
<p>Lesson learned: data sourcing, cleaning is a full-time job by itself. <span class="citation">(De Prado <a href="#ref-de2018advances">2018</a>)</span>, as one of many sources, warned us. And was ignored…</p>
</div>
<div id="stochastic-gradient-descent" class="section level2">
<h2><span class="header-section-number">5.3</span> Stochastic Gradient Descent</h2>
<div id="conclusions" class="section level3">
<h3><span class="header-section-number">5.3.1</span> Conclusions</h3>
<p>This subsection is a bit detailed. The main final points are however simple:</p>
<ul>
<li><p>A more thorough search for exisitng literature and craft would have been time better spent.</p>
<ul>
<li><p>Throwing more <em>iron</em> should be a last resort after trying to be more clever (or more realistically looking for what actually clever people have done in the past). This report is not intended to be a PhD thesis.</p></li>
<li><p>R is not (yet) equipped to take advantage of advances in full program automatic differentiation (and leverage deep learning optimisation library) like Swift<a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a> and Julia<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a> are. R has the <code>Madness</code> package and can also interface with Julia. But that was another rabbit hole that was too dark from the outset.</p></li>
<li><p>On the positive side, calculating the derivative of the multimodal NPV function was checked with Maxima symbolic math capabilities and was an opportunity to re-acquaint ourselves with it.</p></li>
</ul></li>
</ul>
<p><strong>Here is what was written at the time of exploring SGD.</strong></p>
<p>The early exploration of stochastic gradient as the only way to tackle extremely large dataset was decided on the basis of this diagram: <a href="errands-and-post-mortem.html#fig:scikit-map">5.1</a><a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a>. It is otherwise extremely valuable, but we should realised much earlier that financial institutions have beeen dealing with such datasets for decades, at times when computing capacity was a orders of magnitude lower than now. If they could do it then, exploring how they did it should have been done first.</p>

<div class="sourceCode" id="cb73"><pre class="sourceCode numberSource r numberLines lineAnchors"><code class="sourceCode r"><a class="sourceLine" id="cb73-1" href="#cb73-1" data-line-number="1">knitr<span class="op">::</span><span class="kw">include_graphics</span>(<span class="st">&quot;images/scikit-learn-mlmap.png&quot;</span>, <span class="dt">auto_pdf =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:scikit-map"></span>
<img src="images/scikit-learn-mlmap.png" alt="Scikit Learn algorithm cheat-sheet" width="70%" />
<p class="caption">
Figure 5.1: Scikit Learn algorithm cheat-sheet
</p>
</div>

</div>
<div id="gradient-descent" class="section level3">
<h3><span class="header-section-number">5.3.2</span> Gradient descent</h3>
<p>Gradient descent is a generic numerical optimisation algorithm to iteratively converge towards a (sometimes local) minumum of a given function. It is extensively used in statistical learning to minimise error functions.</p>
<p>In the case of a simple linear regression model, the model training error <span class="math inline">\(J\)</span> (the <em>cost function</em>) as a function of <span class="math inline">\(\theta\)</span> is:</p>
<p><span class="math display">\[J_{(\theta)} = \frac{1}{2} \sum_{i=1}^{N}{\epsilon(y_i, \theta X_i)}\]</span>
where the model parameters are denoted <span class="math inline">\(\theta_i\)</span>, <span class="math inline">\(X_i \in \mathbb{R^n}\)</span> are the predictors, <span class="math inline">\(Y_i \in \mathbb{R^n}\)</span> are the responses and <span class="math inline">\(\epsilon\)</span> is a distance function. Typically, <span class="math inline">\(\epsilon\)</span> will be the Manhattan error or the Euclidian norm (<span class="math inline">\(A = (a_1, \cdots , a_n), B = (b_1, \cdots , b_n)\)</span>).</p>
<p><strong>Manhattan</strong>: <span class="math inline">\(\epsilon(A, B) = \sum_{i=1}^n|a_i - b_i|\)</span>)$</p>
<p><strong>Euclidian norm</strong>: <span class="math inline">\(\epsilon(A, B) = \sqrt{\sum_{i=1}^n \left( a_i - b_i \right) ^2}\)</span></p>
<p>The gradient descent algorithm uses the gradient of the error function, <span class="math inline">\(\nabla J_{(\theta)}\)</span>, defined as:</p>
<p><span class="math display">\[
\nabla J_{(\theta)} = \left( \frac{\partial J}{\partial \theta_{0}},\frac{\partial J}{\partial \theta_{1}}, \cdots, \frac{\partial J}{\partial \theta_{p}} \right)
\]</span></p>
<p>And in the case of linear regression is in a matrix form that can be computed efficiently:</p>
<p><span class="math display">\[
\nabla J_{(\theta)} =  \left( y^{T} - \theta X^{T} \right) X
\]</span></p>
<p>The gradient decent algorithm finds parameters in the following manner iterating over the training samples:</p>
<p>While <span class="math inline">\(|| \alpha \nabla J_{(\theta)} || &gt; \eta\)</span>, <span class="math inline">\(\theta := \theta - \alpha \nabla J_{(\theta)}\)</span></p>
<p>In practice, the cost function will add a penalty term to regularise the model parameters (see below).</p>
</div>
<div id="stochastic-gradient-descent-1" class="section level3">
<h3><span class="header-section-number">5.3.3</span> Stochastic Gradient Descent</h3>
<p>With realistic datasets, gradient descent can experience slow convergence because (1) each iteration requires calculation of the gradient for every single training example, and (2) since each individual sample is potentially very different from another, the calculated gradient may not be optimal. In such case, the gradient descent can be done using a batch of several training samples and use the average of the cost function (<strong>batch gradient descent</strong>). This addresses those two sources of inefficiency.</p>
<p>This method however still requires iterating over the entire dataset. We can instead iterate over batched of random training samples drawn from the entire dataset, instead of being drawn sequentially. This is the <em>stochastic gradient descent</em>.</p>
<p>Aside from the choice of the initial choice of samples, and the averaging of the cost function, the update of <span class="math inline">\(\theta\)</span> remains identical.</p>
</div>
<div id="cost-function-for-multi-modal-npv" class="section level3">
<h3><span class="header-section-number">5.3.4</span> Cost function for multi-modal NPV</h3>
<p>Cost function as a function of the <span class="math inline">\(Q\)</span> parameter (equivalent to scorecard).</p>
<p>Looking back at the distribution of the NPV between the -1 and about 1.5, it is multimodal and looks like the sum of 4 log-normal distributions with modes centered on about</p>
<p><span class="math display">\[
PDF(x) = \frac{1}{x \sigma \sqrt{2 \pi}} exp{\left( -\frac{1}2 \left( \frac{ \log(x) - \mu }{\sigma} \right)^2 \right)}
\]</span></p>
<p><span class="math display">\[
\text{mode} = m = e^{\mu - \sigma^2} \text{, therefore: } \mu = log(\text{mode}) + \sigma^2
\]</span></p>
<p><span class="math display">\[
PDF(x) = \sqrt{\frac{e}{2 \pi}} \frac{1}{x \sigma}  exp{\left( -\frac{1}2 \left( \frac{\log(\frac{x}{m}) - \sigma^2}  {\sigma} \right)^2 \right)}
\]</span></p>
<p>We will center the distribution on the mode, therefore:</p>
<p><span class="math display">\[
PDF(x) = \sqrt{\frac{e}{2 \pi}} \frac{1}{\left( x - m \right) \sigma}  exp{ \left( -\frac{1}2 \left( \frac{\log(\frac{x - m}{m}) - \sigma^2}  {\sigma} \right)^2 \right) }
\]</span></p>
<p>The distribution’s tail is towards positive infinity. For the symmetric result, we would replace <span class="math inline">\(\left( x - m \right)\)</span> by <span class="math inline">\(-\left( x - m \right)\)</span>.</p>
<p>If we use 4 log-normal distributions, the cost function is:</p>
<p><span class="math display">\[
\operatorname{J}\left( x,Q\right) =-{{\left[ x-\left( \alpha_1 \operatorname{PDF_1}\left( x,Q\right) + \alpha_2 \operatorname{PDF_2}\left( x,Q\right) + \alpha_2 \operatorname{PDF_3}\left( x,Q\right) + 
\alpha_4 \operatorname{PDF_4}\left( x,Q\right) \right) \right] }^2}
\]</span></p>
<p>To optimise the shape of the total multi-modal distribution, we will assume that each <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(m\)</span> and <span class="math inline">\(\sigma\)</span> is a linear function of <span class="math inline">\(Q\)</span>. The derivative
<span class="math inline">\(\frac{\partial{\operatorname{J}}}{\partial{Q}}\)</span> is<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a>:</p>
<p><span class="math display">\[
\begin{array}{ccc}
\frac{\partial{\operatorname{J}}}{\partial{Q}} \left(x, Q \right) = - \sqrt{\frac{2}{\pi}} x
&amp; - &amp; \sqrt{\frac{2}{\pi}} \frac{\alpha_1}{\sigma_1 \left(-x+m_1 \right)} {e^{-\frac{1}{2} \left( \frac{ \log{\left( \frac{-x+m_1}{ m_1} \right)} + \sigma_1^2}{\sigma_1} \right) ^2}} \\
&amp; - &amp; \frac{1}{\sqrt{2 \pi}} \frac{\alpha_2}{\sigma_2 \left(-x+m_2 \right)} {e^{-\frac{1}{2} \left( \frac{ \log{\left( \frac{-x+m_2}{ m_2} \right)} + \sigma_2^2}{\sigma_2} \right) ^2}} \\
&amp; - &amp; \sqrt{\frac{2}{\pi}} \frac{\alpha_3}{\sigma_3 \left(-x+m_3 \right)} {e^{-\frac{1}{2} \left( \frac{ \log{\left( \frac{-x+m_3}{ m_3} \right)} + \sigma_3^2}{\sigma_3} \right) ^2}} \\
&amp; - &amp; \sqrt{\frac{2}{\pi}} \frac{\alpha_4}{\sigma_4 \left( x-m_4 \right)} {e^{-\frac{1}{2} \left( \frac{ \log{\left( \frac{ x-m_4}{ m_4} \right)} + \sigma_4^2}{\sigma_4} \right) ^2}}
\end{array}
\]</span></p>
<p>We then worked on the basis of code developed for the <em>Movielens</em> capston.<a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a></p>
</div>
</div>
<div id="final-final-conclusion" class="section level2">
<h2><span class="header-section-number">5.4</span> Final final Conclusion</h2>
<p>We only received 999 cuts. We survived…</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-de2018advances">
<p>De Prado, Marcos Lopez. 2018. <em>Advances in Financial Machine Learning</em>. John Wiley &amp; Sons.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="20">
<li id="fn20"><p>Nobody gets a prize for having been incorrect. But nobody gets a prize not knowing where others have been incorrect.<a href="errands-and-post-mortem.html#fnref20" class="footnote-back">↩</a></p></li>
<li id="fn21"><p><a href="https://blog.tensorflow.org/2019/06/fastais-deep-learning-from-foundations_28.html" class="uri">https://blog.tensorflow.org/2019/06/fastais-deep-learning-from-foundations_28.html</a><a href="errands-and-post-mortem.html#fnref21" class="footnote-back">↩</a></p></li>
<li id="fn22"><p><a href="https://fluxml.ai/Zygote.jl/latest/" class="uri">https://fluxml.ai/Zygote.jl/latest/</a><a href="errands-and-post-mortem.html#fnref22" class="footnote-back">↩</a></p></li>
<li id="fn23"><p>Source: <a href="https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html" class="uri">https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html</a><a href="errands-and-post-mortem.html#fnref23" class="footnote-back">↩</a></p></li>
<li id="fn24"><p>This was actually generated using Maxima (code in Appendix) which allows for quicker iterations.<a href="errands-and-post-mortem.html#fnref24" class="footnote-back">↩</a></p></li>
<li id="fn25"><p>See <a href="https://github.com/Emmanuel-R8/https://github.com/Emmanuel-R8/HarvardX-Movielens" class="uri">https://github.com/Emmanuel-R8/https://github.com/Emmanuel-R8/HarvardX-Movielens</a><a href="errands-and-post-mortem.html#fnref25" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="conclusion.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="appendix.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/Emmanuel-R8/HarvardX-LendingClub/edit/master/07-2-postmortem.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["HarvardX Credit Scoring of the LendingClub Dataset.pdf", "HarvardX Credit Scoring of the LendingClub Dataset.epub"],
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
