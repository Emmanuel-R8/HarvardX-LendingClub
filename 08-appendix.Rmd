# Appendix {-}

## List of assumptions / limitations regarding the dataset

As mentioned during this report, we had to make numerous assumptions given the lack of clarity of the variable descriptions. 

+ _Dataset quality_: Aside from cents rounding issues, the dataset does not contain any flagrant errors that we could see (e.g. minor error of amount or rate, zipcode). Quality of the variable description is a different matter altogether.

+ _Ratings_: The day-1 rating is between A1 and (and no lower than) G5. No note is rated lower than E5 after 6 November 2017, and lower than D5 after 30 June 2019.

+ _Credit history_: Credit history information for the principal borrower relates to pre-approval and not post-funding. This is clear for the joint applicants, but simply an assumption for the principal borrower.

+ _Recoveries_: Recoveries (if any) are assumed to be paid 3 months after the last scheduled payment date (variable `last_pymnt_d`)

+ _Survival effect_: The dataset does not include applications that were rejected.

We do hope that LendingClub investors receive information of much better quality!


## Data preparation and formatting

We used different sources of information:

+ The LendingClub dataset made available on Kaggle;

+ US georgraphical data about zip and FIPS codes;

+ Market interest rates from the Saint Louis Federal Reserve Bank; and, 

+ Macro data from the same source.

We here show the code used to prepare the data.


### LendinClub dataset

```{r data_preparation,eval=FALSE,echo=TRUE}
local({
  #
  # STEP 1: Download the dataset
  #
  #   Got to https://www.kaggle.com/wendykan/lending-club-loan-data
  #
  #   Download into the 'datasets' subdirectory
  #   Unzip the file.
  #   WARNING: The unzipping will be about 2.4GB
  #
  #   Name the sql database "datasets/lending_club.sqlite"
  #
  
  #
  # STEP 2: Prepare the dabase as a tibble
  #
  
  ##
  ## WARNING: THIS ASSUMES A 'datasets' DIRECTORY WAS CREATED
  ## 
  library(RSQLite)
  db_conn <-
    dbConnect(RSQLite::SQLite(), "datasets/lending_club.sqlite")
  dbListTables(db_conn)
  
  # Returns a 2.96GB data frame
  lending_club <- dbGetQuery(db_conn, "SELECT * FROM loan")
  lending_club <- as_tibble(lending_club)
  
  # Close the database
  dbDisconnect(db_conn)
  
  # Compressed to ca.285MB on disk
  saveRDS(lending_club, "datasets/lending_club.rds")
  
  
  library(tidyverse)
  library(lubridate)
  library(hablar)
  
  # Before reformat in case the previous step was already done
  # lending_club <- readRDS("datasets/lending_club.rds")
  #
  # str(lending_club)
  #
  
  # Leave the original dataset untouched and work with a copy.
  lc <- lending_club
  
  lc <- lc %>%

    # Add loan identification number to track the loans across calculations
    mutate(loanID = row_number()) %>% 
    
    # Remove useless strings
    mutate(
      term       = str_remove(term, " months"),
      emp_length = str_replace(emp_length, "<1", "0"),
      emp_length = str_replace(emp_length, "10+", "10"),
      emp_length = str_remove(emp_length, "years")
    ) %>%
    
    # Creates dates out of strings - Parse errors will be raised when no dates.
    mutate(
      debt_settlement_flag_date = as_date(dmy(
        str_c("1-", debt_settlement_flag_date)
      )),
      earliest_cr_line          = as_date(dmy(str_c(
        "1-", earliest_cr_line
      ))),
      hardship_start_date       = as_date(dmy(str_c(
        "1-", hardship_start_date
      ))),
      hardship_end_date         = as_date(dmy(str_c(
        "1-", hardship_end_date
      ))),
      issue_d                   = as_date(dmy(str_c("1-", issue_d))),
      last_credit_pull_d        = as_date(dmy(str_c(
        "1-", last_credit_pull_d
      ))),
      last_pymnt_d              = as_date(dmy(str_c(
        "1-", last_pymnt_d
      ))),
      next_pymnt_d              = as_date(dmy(str_c(
        "1-", next_pymnt_d
      ))),
      payment_plan_start_date   = as_date(dmy(str_c(
        "1-", payment_plan_start_date
      ))),
      sec_app_earliest_cr_line  = as_date(dmy(str_c(
        "1-", sec_app_earliest_cr_line
      ))),
      settlement_date           = as_date(dmy(str_c(
        "1-", settlement_date
      )))
    ) %>%
    
    # Bulk type conversion with convert from the `hablar` package
    convert(
      # Strings
      chr(emp_title, title, url, zip_code),
      
      # Factors
      fct(
        addr_state,
        application_type,
        debt_settlement_flag,
        desc,
        disbursement_method,
        grade,
        hardship_flag,
        hardship_loan_status,
        hardship_reason,
        hardship_status,
        hardship_type,
        home_ownership,
        id,
        initial_list_status,
        loan_status,
        member_id,
        policy_code,
        purpose,
        pymnt_plan,
        settlement_status,
        sub_grade,
        verification_status,
        verification_status_joint
      ),
      
      # Integers
      int(
        acc_now_delinq,
        acc_open_past_24mths,
        chargeoff_within_12_mths,
        collections_12_mths_ex_med,
        deferral_term,
        delinq_2yrs,
        emp_length,
        hardship_dpd,
        hardship_length,
        inq_fi,
        inq_last_12m,
        inq_last_6mths,
        mo_sin_old_il_acct,
        mo_sin_old_rev_tl_op,
        mo_sin_rcnt_rev_tl_op,
        mo_sin_rcnt_tl,
        mort_acc,
        mths_since_last_delinq,
        mths_since_last_major_derog,
        mths_since_last_record,
        mths_since_rcnt_il,
        mths_since_recent_bc,
        mths_since_recent_bc_dlq,
        mths_since_recent_inq,
        mths_since_recent_revol_delinq,
        num_accts_ever_120_pd,
        num_actv_bc_tl,
        num_actv_rev_tl,
        num_bc_sats,
        num_bc_tl,
        num_il_tl,
        num_op_rev_tl,
        num_rev_accts,
        num_rev_tl_bal_gt_0,
        num_sats,
        num_tl_120dpd_2m,
        num_tl_30dpd,
        num_tl_90g_dpd_24m,
        num_tl_op_past_12m,
        open_acc,
        open_acc_6m,
        open_act_il,
        open_il_12m,
        open_il_24m,
        open_rv_12m,
        open_rv_24m,
        sec_app_chargeoff_within_12_mths,
        sec_app_collections_12_mths_ex_med,
        sec_app_inq_last_6mths,
        sec_app_mort_acc,
        sec_app_mths_since_last_major_derog,
        sec_app_num_rev_accts,
        sec_app_open_acc,
        sec_app_open_act_il,
        term
      ),
      
      # Floating point
      dbl(
        all_util,
        annual_inc,
        annual_inc_joint,
        avg_cur_bal,
        bc_open_to_buy,
        bc_util,
        collection_recovery_fee,
        delinq_amnt,
        dti,
        dti_joint,
        funded_amnt,
        funded_amnt_inv,
        hardship_amount,
        hardship_last_payment_amount,
        hardship_payoff_balance_amount,
        il_util,
        installment,
        int_rate,
        last_pymnt_amnt,
        loan_amnt,
        max_bal_bc,
        orig_projected_additional_accrued_interest,
        out_prncp,
        out_prncp_inv,
        pct_tl_nvr_dlq,
        percent_bc_gt_75,
        pub_rec,
        pub_rec_bankruptcies,
        recoveries,
        revol_bal,
        revol_bal_joint,
        revol_util,
        sec_app_revol_util,
        settlement_amount,
        settlement_percentage,
        tax_liens,
        tot_coll_amt,
        tot_cur_bal,
        tot_hi_cred_lim,
        total_acc,
        total_bal_ex_mort,
        total_bal_il,
        total_bc_limit,
        total_cu_tl,
        total_il_high_credit_limit,
        total_pymnt,
        total_pymnt_inv,
        total_rec_int,
        total_rec_late_fee,
        total_rec_prncp,
        total_rev_hi_lim
      )
    ) %>%
    
    # Converts some values to 1/-1 (instead of Boolean)
    mutate(
      pymnt_plan =           if_else(pymnt_plan == "y",           1, -1),
      hardship_flag =        if_else(hardship_flag == "Y",        1, -1),
      debt_settlement_flag = if_else(debt_settlement_flag == "Y", 1, -1)
    ) %>%
    
    # Some values are percentages
    mutate(
      int_rate = int_rate / 100,
      dti = dti / 100,
      dti_joint = dti_joint / 100,
      revol_util = revol_util / 100,
      il_util = il_util / 100,
      all_util = all_util / 100,
      bc_open_to_buy = bc_util / 100,
      pct_tl_nvr_dlq = pct_tl_nvr_dlq / 100,
      percent_bc_gt_75 = percent_bc_gt_75 / 100,
      sec_app_revol_util = sec_app_revol_util / 100
    ) %>%
    
    # Create quasi-centered numerical grades out of grade factors with "A" = 3 down to "G" = -3
    mutate(grade_num = 4 - as.integer(grade)) %>%
    
    # Ditto with sub_grades. "A1" = +3.4, "A3" = +3.0, down to "G3" = -3.0, "G5" = -3.4
    mutate(sub_grade_num = 3.6 - as.integer(sub_grade) / 5) %>%
    
    # Keep the first 3 digits of the zipcode as numbers
    mutate(zip_code = as.integer(str_sub(zip_code, 1, 3))) %>%
    
    # order by date
    arrange(issue_d) %>% 
    
    # Remove empty columns
    select(-id, -member_id, -url)
  
  saveRDS(lc, "datasets/lending_club_reformatted.rds")
  
  
  # Select loans which have matured or been terminated
  past_loans <- lc %>%
    filter(
      loan_status %in% c(
        "Charged Off",
        "Does not meet the credit policy. Status:Charged Off",
        "Does not meet the credit policy. Status:Fully Paid",
        "Fully Paid"
      )
    )
  
  saveRDS(past_loans, "datasets/lending_club_reformatted_paid.rds")
})```

```

### Zip codes and FIPS codes

The R package `zipcode` was installed.

```{r zip-package,eval=FALSE,echo=TRUE}
#
# ZIPCodes dataset.
#

library(zipcode)
data(zipcode)
zips <- zipcode %>%
  as_tibble() %>%
  mutate(zip = as.integer(str_sub(zip, 1, 3)))

saveRDS(zips, "datasets/zips.rds")
```


A csv file containing zip codes, FIPS codes and population information was downloaded from the _Simple Maps_ ^[https://simplemaps.com/data/us-zips] website. 

```{r simplemaps,eval=FALSE,echo=TRUE}
local({
  kaggleCodes <- read.csv("datasets/csv/ZIP-COUNTY-FIPS_2017-06.csv")
  
  kaggleCodes <- 
    kaggleCodes %>% 
    as_tibble() %>% 
    mutate(zip = floor(ZIP/100), 
           FIPS = STCOUNTYFP, 
           COUNTYNAME = str_replace(COUNTYNAME, pattern = "County", replacement = ""),
           COUNTYNAME = str_replace(COUNTYNAME, pattern = "Borough", replacement = ""),
           COUNTYNAME = str_replace(COUNTYNAME, pattern = "Municipio", replacement = ""),
           COUNTYNAME = str_replace(COUNTYNAME, pattern = "Parish", replacement = ""),
           COUNTYNAME = str_replace(COUNTYNAME, pattern = "Census Area", replacement = "")) %>% 
    rename(county = COUNTYNAME) %>% 
    select(zip, county, FIPS) %>% 
    arrange(zip)

  saveRDS(zipfips, "datasets/kaggleCodes.rds")
})
```

### Market interest rates

Market interest rates (3-year and 5-year swap rates) were download from the Saint Louis Federal Reserve Bank. Datasets are split between before and after the LIBOR fixing scandal. The datasets are merged with disctinct dates.

Download sources are:

+ Pre-LIBOR 3-y swap https://fred.stlouisfed.org/series/DSWP3
+ Post-LIBOR 3-y swap https://fred.stlouisfed.org/series/ICERATES1100USD3Y

+ Pre-LIBOR 5-y swap https://fred.stlouisfed.org/series/MSWP5
+ Post-LIBOR 5-y swap https://fred.stlouisfed.org/series/ICERATES1100USD5Y


```{r market-rates,eval=FALSE,echo=TRUE}
local({
  LIBOR3Y <- read.csv("datasets/csv/DSWP3.csv") %>%
    as_tibble() %>%
    filter(DSWP3 != ".") %>%
    mutate(DATE = as_date(DATE),
           RATE3Y = as.numeric(as.character(DSWP3)) / 100) %>%
    select(DATE, RATE3Y)
  
  ICE3Y <- read.csv("datasets/csv/ICERATES1100USD3Y.csv") %>%
    as_tibble() %>%
    filter(ICERATES1100USD3Y != ".") %>%
    mutate(DATE = as_date(DATE),
           RATE3Y = as.numeric(as.character(ICERATES1100USD3Y)) / 100) %>%
    select(DATE, RATE3Y)
  
  
  LIBOR5Y <- read.csv("datasets/csv/DSWP5.csv") %>%
    as_tibble() %>%
    filter(DSWP5 != ".") %>%
    mutate(DATE = as_date(DATE),
           RATE5Y = as.numeric(as.character(DSWP5)) / 100) %>%
    select(DATE, RATE5Y)
  
  ICE5Y <- read.csv("datasets/csv/ICERATES1100USD5Y.csv") %>%
    as_tibble() %>%
    filter(ICERATES1100USD5Y != ".") %>%
    mutate(DATE = as_date(DATE),
           RATE5Y = as.numeric(as.character(ICERATES1100USD5Y)) / 100) %>%
    select(DATE, RATE5Y)
  
  RATES3Y <- LIBOR3Y %>% rbind(ICE3Y) %>%
    arrange(DATE) %>% distinct(DATE, .keep_all = TRUE)
  
  RATES5Y <- LIBOR5Y %>% rbind(ICE5Y) %>%
    arrange(DATE) %>% distinct(DATE, .keep_all = TRUE)
  
  saveRDS(RATES3Y, "datasets/rates3Y.rds")
  saveRDS(RATES5Y, "datasets/rates5Y.rds")
  
  
  # Note there are 7212 days from 1 Jan 2000 to 30 Sep 2019
  #
  # (ymd("2000-01-01") %--% ymd("2019-09-30")) %/% days(1)
  RATES <- tibble(n = seq(0, 7212)) %>%
    
    # Create a column with all dates
    mutate(DATE = ymd("2000-01-01") + days(n)) %>%
    select(-n) %>%
    
    # Add all daily 3- then 5-year rates and fill missing down
    left_join(RATES3Y) %>%
    fill(RATE3Y, .direction = "down") %>%
    
    left_join(RATES5Y) %>%
    fill(RATE5Y, .direction = "down")
  
  saveRDS(RATES, "datasets/rates.rds")
})
```

### Macro-economical data

Macro-economical datasets were sourced from the same website as Microsoft Excel files. They were converted as-is to tab-separated csv files with LibreOffice. 

+ Median income per household:
https://geofred.stlouisfed.org/map/?th=pubugn&cc=5&rc=false&im=fractile&sb&lng=-112.41&lat=44.31&zm=4&sl&sv&am=Average&at=Not%20Seasonally%20Adjusted,%20Annual,%20Dollars&sti=2022&fq=Annual&rt=county&un=lin&dt=2017-01-01

+ Per capita personal income: 
https://geofred.stlouisfed.org/map/?th=pubugn&cc=5&rc=false&im=fractile&sb&lng=-112.41&lat=44.31&zm=4&sl&sv&am=Average&at=Not%20Seasonally%20Adjusted,%20Annual,%20Dollars&sti=882&fq=Annual&rt=county&un=lin&dt=2017-01-01

+ Unemployment:
https://geofred.stlouisfed.org/map/?th=rdpu&cc=5&rc=false&im=fractile&sb&lng=-90&lat=40&zm=4&sl&sv&am=Average&at=Not%20Seasonally%20Adjusted,%20Monthly,%20Percent&sti=1224&fq=Monthly&rt=county&un=lin&dt=2019-08-01



```{r macro-data,eval=FALSE,echo=TRUE}
local({
  ###################################################################################################
  ##
  ## Median income per household by FIPS from 2002 to 2017
  ##
  # Prepare median income
  medianIncome <-
    # Load the dataset after dropping the first line
    read.csv(
      "datasets/csv/GeoFRED_Estimate_of_Median_Household_Income_by_County_Dollars.csv",
      sep = "\t",
      skip = 1,
      stringsAsFactors = FALSE
    ) %>%
    
    # Drops columnsn containing a unique identifier and the FIPS name
    select(-"Series.ID", -"Region.Name") %>%
    
    # Rename the relevant column to 'FIPS'
    rename(FIPS = "Region.Code") %>%
    
    # Order by FIPS
    arrange(FIPS) %>% 
    
    # Convert to a 'long' table, i.e. one column for FIPS, one for date, one for income
    pivot_longer(cols = starts_with("X"), 
                 names_to = "Date", 
                 values_to = "medianIncome") %>% 
    
    # Create actual dates
    mutate(Date = str_replace(Date, "[X]", ""),
           Date = ymd(str_c(Date, "-12-31")))
  
  saveRDS(medianIncome, "datasets/medianincome.rds")

  
  
  ###################################################################################################
  ##
  ## Per capita income by FIPS from 2002 to 2017
  ##
  personalIncome <-
    # Load the dataset after dropping the first line
    read.csv(
      "datasets/csv/GeoFRED_Per_Capita_Personal_Income_by_County_Dollars.csv",
      sep = "\t",
      skip = 1,
      stringsAsFactors = FALSE
    ) %>%
    
    # Drops columnsn containing a unique identifier and the FIPS name
    select(-"Series.ID", -"Region.Name") %>%
    
    # Rename the relevant column to 'FIPS'
    rename(FIPS = "Region.Code") %>%
    
    # Order by FIPS
    arrange(FIPS) %>% 
    
    # Convert to a 'long' table, i.e. one column for FIPS, one for date, one for income
    pivot_longer(cols = starts_with("X"), 
                 names_to = "Date", 
                 values_to = "personalIncome") %>% 
    
    # Create actual dates
    mutate(Date = str_replace(Date, "[X]", ""),
           Date = ymd(str_c(Date, "-12-31")))
  
  saveRDS(personalIncome, "datasets/personalincome.rds")
  
  
  ###################################################################################################
  ##
  ## Unemplyment rate monthly by FIPS from January 2000 to August 2019
  ##
  unemploymentRate <-
    # Load the dataset after dropping the first line
    read.csv(
      "datasets/csv/GeoFRED_Unemployment_Rate_by_County_Percent.csv",
      sep = "\t",
      skip = 1,
      stringsAsFactors = FALSE
    ) %>%
    
    # Drops columnsn containing a unique identifier and the FIPS name
    select(-"Series.ID", -"Region.Name") %>%
    
    # Rename the relevant column to 'FIPS'
    rename(FIPS = "Region.Code") %>%
    
    # Order by FIPS
    arrange(FIPS) %>% 
    
    mutate_all(as.double) %>% 
  
    # Convert to a 'long' table, i.e. one column for FIPS, one for date, one for income
    pivot_longer(cols = starts_with("X"), 
                 names_to = "Date", 
                 values_to = "unemploymentRate", 
                 values_ptypes = c("unemploymentRate", numeric)) %>% 
    
    # Converts the content of the Year column to an actual date
    mutate(
      Date = str_replace(Date, "[X]", ""),
      Date = str_replace(Date, "[.]", "-"),
      Date = ymd(str_c(Date, "-1"))
    )
  
  saveRDS(unemploymentRate, "datasets/unemployment.rds")
})
```


## List of variables 

This table presents the list of variables provided in the original dataset. The descriptions come from a spreadsheet attached with the dataset and, unfortunately, are not extremely precise and subject to interpretation. We added comments and/or particular interpretations in _CAPITAL LETTERS_.


```{r variable-description,cache=FALSE}
LC_variable %>%
  select(variable_name, description) %>% 
  
  # Format the table.
  kable(
    "latex",
    caption = "Description of the dataset variables as provided in the dataset downloaded from Kaggle",
    booktabs = T,
    longtable = T,
    col.names = c("Variable Name", "Description")
  ) %>%
  kable_styling(full_width = F,
                latex_options = c("repeat_header")) %>%
  column_spec(1, width = "7cm") %>%
  column_spec(2, width = "7cm")


```


## Calculations of the internal rate of returns and month-to-default

The following shows two versions of the same code. The R version is provided because of the description of the assignment. However, the R version takes just under a full day to run. A Julia version, which is a direct translation of the R code, runs in about 150s (ca. 500x faster).  

### R code

```{r IRR-calculation,eval=FALSE,echo=TRUE}
# 
# Calculate all the IRRs and month of default for all the loans. 
# WARNING: This takes around a full day to run!!!!
# 
# The actual data was generated by the Julia version, with cross-checks.
# Julia version takes about 150 sec on the same unoptimised code.
# 
local({
  loansIRR <-
    loans %>%
    rowwise() %>%
    do(calculateIRR(loanNumber = .$loanID,
                    loan = .$funded_amnt, intRate = .$int_rate, term = .$term,
                    totalPaid = .$total_pymnt, totalPrincipalPaid = .$total_rec_prncp,
                    totalInterestPaid = .$total_rec_int,
                    recoveries = .$recoveries, lateFees = .$total_rec_late_fee))

  saveRDS(loansIRR, "datasets/lending_club_IRRs.rds")
  
  })
```

### Julia translation

```{julia julia-IRR,eval=FALSE,echo=TRUE}
######################################################################################################################
##
## Prepare datasets
##

## Previously saved from R with:
##     lending_club <- readRDS("lending_club.rds"); write.csv(lending_club, "lending_club.rds")
##
## WARNING: 1.7GB on disk
##
using CSV
lendingClub = CSV.read("datasets/lending_club.csv"; delim = ",")



######################################################################################################################
##
## IRR calculations
##
## Given some numerical parameters describing a loan in the dataset, returns its Internal Rate
## of Return.
##
## In the first instance, the function creates a schedule of payments.
## In many cases, the schedule will be extremely simple: a series of 36 or 60 equal instalements.
##
## But in some cases, a loan repayment are accelerated. Therefore the total amount of interest will
## be lower than expected (but this is good for the investor because highe interest rate over
## shorter tenor.).
##
## In other cases, the borrower defaults. Overall payments are less than expected.
##
## Based on the limited information of the dataset, the function makes educated guesses on the exact schedule.
##
using DataFrames, Roots

function calculateIRR(; loanNumber = 1, loan = 0.0, intRate = 0.0, term = 36,
  totalPaid = 0.0, totalPrincipalPaid = 0.0, totalInterestPaid = 0.0,
  recoveries = 0.0, lateFees = 0.0,
  showSchedule = false)

  # number of monthly payments.
  # It exceeds 60 months in case recoveries on a 60-month loan takes the schedule after 60 months.
  nMonths = 90

  # Months after which a loan defaults (normal tenor if no default or early prepayment)
  monthDefault = term

  # Note: *100 /100 to calculate in cent because ceiling cannot specify significant digits.
  installment = ceil(loan * intRate / 12 / (1 - 1 / (1 + intRate / 12) ^ term), digits = 2)

  # We create a schedule
  schedule = DataFrame(month = 0:nMonths, monthlyPayment = 0.0, totalPandI = 0.0, totalI = 0.0, totalP = 0.0)

  for i in 2:(nMonths + 1)
    # Get situation at the end of previous month
    previousTotalPandI = schedule[i - 1, :totalPandI]
    previousTotalP     = schedule[i - 1, :totalP]
    previousTotalI     = schedule[i - 1, :totalI]

    # This is the beginning of a new month. First and foremost, the borrower is expected to pay the
    # accrued interest on amount of principal outstanding.
    # ceiling doesn't seem accept to accept significative digits.
    accruedInterest = ceil((loan - previousTotalP) * intRate / 12; digits = 2)

    # If that amount takes the schedule above the total amount of interest shown in the data set,
    # we should stop the schedule at this point
    if previousTotalI + accruedInterest > totalInterestPaid

      # We stop the normal schedule at this date.
      # Interest is paid (although less than scheduled)
      schedule[i, :monthlyPayment] = totalInterestPaid - previousTotalI

      # As well as whatever principal is left as per the dataset
      schedule[i, :monthlyPayment] = schedule[i, :monthlyPayment] + totalPrincipalPaid - previousTotalP

      # Then 3-month after the last payment date, recoveries and and later fees are paid
      schedule[i + 3, :monthlyPayment] = schedule[i + 3, :monthlyPayment] + recoveries + lateFees

      # Not really useful, but for completeness
      schedule[i, :totalPandI] = totalPaid
      schedule[i, :totalI]     = totalInterestPaid
      schedule[i, :totalP]     = totalPrincipalPaid

      # If total principal paid is less than borrower, then it is a default, and the monthDefault
      # is adjusted.
      if (totalPrincipalPaid < loan)
        monthDefault = i
      end

      # No more payments to add to the schedule
      break

    else
      # Deal with normal schedule
      schedule[i, :monthlyPayment] = installment
      schedule[i, :totalPandI]     = schedule[i - 1, :totalPandI] + installment
      schedule[i, :totalI]         = schedule[i - 1, :totalI]     + accruedInterest
      schedule[i, :totalP]         = schedule[i - 1, :totalP]     + installment - accruedInterest
    end
  end

  # At this point schedule[, :monthlyPayment] contains the schedule of all payments, but needs to
  # include the initial loan.
  schedule[1, :monthlyPayment] = -loan

  if (showSchedule)
    print(schedule)
  end

  cashFlow = schedule[:,:monthlyPayment]

  NPV = function(interest)
    t = 0:(length(cashFlow) - 1)
    return sum(cashFlow ./ (1 + interest) .^ t)
  end

  rootInterest = try
                  round(12 * find_zero(NPV, (-0.9, 1.0), Bisection(); xatol = 0.000001); digits = 4)
                catch e
                  NaN
                end

  return((
    loanID = loanNumber,
    IRR = rootInterest,
    monthDefault = monthDefault
  ))
end


##
## Calculate the IRR and repayment schedule of a particular loan identified by its loanID
function loanNumberIRR(loanNumber)
  l = lc[ lc[:, :Column1] .== loanNumber, :]
  global lc
  calculateIRR(loanNumber = l[1, :Column1],
               loan = l[1, :funded_amnt], intRate = l[1, :int_rate], term =l[1, :tenor],
               totalPaid = l[1, :total_pymnt], totalPrincipalPaid = l[1, :total_rec_prncp],
               totalInterestPaid = l[1, :total_rec_int],
               recoveries = l[1, :recoveries], lateFees = l[1, :total_rec_late_fee],
               showSchedule = true)
end


#######################################################################################################################
##
## Quick check
##
calculateIRR(loanNumber = 1, loan = 5600, intRate = 0.1299, term = 36,
             totalPaid = 6791.72, totalPrincipalPaid = 5600, totalInterestPaid = 1191.72,
             recoveries = 0, lateFees = 0,
             showSchedule = false)

calculateIRR(loanNumber = 1, loan = 35000, intRate = 0.1820, term = 60,
             totalPaid = 26600.1, totalPrincipalPaid = 3874.72, totalInterestPaid = 5225.38,
             recoveries = 17500, lateFees = 0.0,
             showSchedule = false)

calculateIRR(loanNumber = 1734666, loan = 35000, intRate = 0.0797, term = 36,
             totalPaid = 1057.04, totalPrincipalPaid = 863.83, totalInterestPaid = 193.72,
             recoveries = 0, lateFees = 0,
             showSchedule = false)




##
## Look for the loans which have gone to their end
##
indextmp = (lendingClub.loan_status .== "Fully Paid") .|
           (lendingClub.loan_status .== "Charged Off") .|
           (lendingClub.loan_status .== "Does not meet the credit policy. Status:Charged Off") .|
           (lendingClub.loan_status .== "Does not meet the credit policy. Status:Fully Paid")

## Create the dataset we will use - Should be the same as lending_club_reformatted_paid.rds
lc = lendingClub[indextmp, :]

## Select relevant variables to calculate profitability
## Column1 contains the loanID's
cols = [:Column1, :funded_amnt, :int_rate, :term,
        :total_pymnt, :total_rec_prncp, :total_rec_int,
        :recoveries, :total_rec_late_fee]

lc = select(lc, cols)

## Interest rates as percentage
lc[:, :int_rate] = lc[:, :int_rate] ./ 100

## Create a new column
lc[:tenor] = 0

## that will record the official loan tenor as a number (instead of string)
lc[startswith.( lc[:, :term], " 36"), :tenor] .= 36
lc[startswith.( lc[:, :term], " 60"), :tenor] .= 60

## New data frame to store the results
IRR_Result = DataFrame(loanID = zeros(Int64, nrow(lc)),
                       IRR = zeros(Float64, nrow(lc)),
                       monthDefault = zeros(Int64, nrow(lc)))


# ~150 sec. to do the whole dataset
@time for i in 1:nrow(lc)
  global IRR_Result

  # Use multiple-return-value
  (IRR_Result[i, :loanID], IRR_Result[i, :IRR], IRR_Result[i, :monthDefault]) =
      calculateIRR(
          loanNumber = lc[i, :Column1],
          loan = lc[i, :funded_amnt], intRate = lc[i, :int_rate], term =lc[i, :tenor],
          totalPaid = lc[i, :total_pymnt], totalPrincipalPaid = lc[i, :total_rec_prncp],
          totalInterestPaid = lc[i, :total_rec_int],
          recoveries = lc[i, :recoveries], lateFees = lc[i, :total_rec_late_fee],
          showSchedule = false)
end


IRR_Result[1:10,:]
# Check
loanNumberIRR(171)

CSV.write("datasets/loanIRR.csv", IRR_Result)
```





## System version

```{r system_version,eval=TRUE,eval=TRUE,cache=FALSE}
Sys.info()

```



