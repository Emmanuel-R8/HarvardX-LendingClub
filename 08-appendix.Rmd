# Appendix {-}

## List of assumptions / limitations regarding the dataset

As mentioned during this report, we had to make numerous assumptions given the lack of clarity of the variable descriptions. 

+ The dataset does not contain any errors that we cannot notice (e.g. minor error of amount or rate, zipcode).

+ The day-1 rating is between A1 and (and no lower than) G5. No note is rated lower than E5 from 6 November 2017, and lower than D5 from 30 June 2019.

+ Credit history information for the principal borrower relates to pre-approval and not post-funding. This is clear for the joint applicants, but simply an assumption for the principal borrower.

+ _Survival effect_: The dataset does not include applications that were rejected.

We do hope that LendingClub investors receive information of much better quality!


## Data preparation and formatting

We used different sources of information:

+ The LendingClub dataset made available on Kaggle;

+ US georgraphical data about zip and FIPS codes;

+ Market interest rates from the Saint Louis Federal Reserve Bank; and, 

+ Macro data from the same source.

We here show the code used to prepare the data.


### LendinClub dataset

```{r data_preparation,eval=FALSE,echo=TRUE}
local({
  #
  # STEP 1: Download the dataset
  #
  #   Got to https://www.kaggle.com/wendykan/lending-club-loan-data
  #
  #   Download into the 'datasets' subdirectory
  #   Unzip the file.
  #   WARNING: The unzipping will be about 2.4GB
  #
  #   Name the sql database "datasets/lending_club.sqlite"
  #
  
  #
  # STEP 2: Prepare the dabase as a tibble
  #
  
  library(RSQLite)
  db_conn <-
    dbConnect(RSQLite::SQLite(), "datasets/lending_club.sqlite")
  dbListTables(db_conn)
  
  # Returns a 2.96GB data frame
  lending_club <- dbGetQuery(db_conn, "SELECT * FROM loan")
  lending_club <- as_tibble(lending_club)
  
  # Close the database
  dbDisconnect(db_conn)
  
  # Compressed to ca.285MB on disk
  saveRDS(lending_club, "datasets/lending_club.rds")
  
  
  library(tidyverse)
  library(lubridate)
  library(hablar)
  
  # Before reformat in case the previous step was already done
  # lending_club <- readRDS("datasets/lending_club.rds")
  #
  # str(lending_club)
  #
  
  # We leave the original dataset untouched and work with a copy.
  lc <- lending_club
  
  lc <- lc %>%
    # Remove useless strings
    mutate(
      term       = str_remove(term, " months"),
      emp_length = str_replace(emp_length, "<1", "0"),
      emp_length = str_replace(emp_length, "10+", "10"),
      emp_length = str_remove(emp_length, "years")
    ) %>%
    
    # Creates dates out of strings - Parse errors will be raised when no dates.
    mutate(
      debt_settlement_flag_date = as_date(dmy(
        str_c("1-", debt_settlement_flag_date)
      )),
      earliest_cr_line          = as_date(dmy(str_c(
        "1-", earliest_cr_line
      ))),
      hardship_start_date       = as_date(dmy(str_c(
        "1-", hardship_start_date
      ))),
      hardship_end_date         = as_date(dmy(str_c(
        "1-", hardship_end_date
      ))),
      issue_d                   = as_date(dmy(str_c("1-", issue_d))),
      last_credit_pull_d        = as_date(dmy(str_c(
        "1-", last_credit_pull_d
      ))),
      last_pymnt_d              = as_date(dmy(str_c(
        "1-", last_pymnt_d
      ))),
      next_pymnt_d              = as_date(dmy(str_c(
        "1-", next_pymnt_d
      ))),
      payment_plan_start_date   = as_date(dmy(str_c(
        "1-", payment_plan_start_date
      ))),
      sec_app_earliest_cr_line  = as_date(dmy(str_c(
        "1-", sec_app_earliest_cr_line
      ))),
      settlement_date           = as_date(dmy(str_c(
        "1-", settlement_date
      )))
    ) %>%
    
    # Bulk type conversion with convert from the `hablar` package
    convert(
      # Strings
      chr(emp_title, title, url, zip_code),
      
      # Factors
      fct(
        addr_state,
        application_type,
        debt_settlement_flag,
        desc,
        disbursement_method,
        grade,
        hardship_flag,
        hardship_loan_status,
        hardship_reason,
        hardship_status,
        hardship_type,
        home_ownership,
        id,
        initial_list_status,
        loan_status,
        member_id,
        policy_code,
        purpose,
        pymnt_plan,
        settlement_status,
        sub_grade,
        verification_status,
        verification_status_joint
      ),
      
      # Integers
      int(
        acc_now_delinq,
        acc_open_past_24mths,
        chargeoff_within_12_mths,
        collections_12_mths_ex_med,
        deferral_term,
        delinq_2yrs,
        emp_length,
        hardship_dpd,
        hardship_length,
        inq_fi,
        inq_last_12m,
        inq_last_6mths,
        mo_sin_old_il_acct,
        mo_sin_old_rev_tl_op,
        mo_sin_rcnt_rev_tl_op,
        mo_sin_rcnt_tl,
        mort_acc,
        mths_since_last_delinq,
        mths_since_last_major_derog,
        mths_since_last_record,
        mths_since_rcnt_il,
        mths_since_recent_bc,
        mths_since_recent_bc_dlq,
        mths_since_recent_inq,
        mths_since_recent_revol_delinq,
        num_accts_ever_120_pd,
        num_actv_bc_tl,
        num_actv_rev_tl,
        num_bc_sats,
        num_bc_tl,
        num_il_tl,
        num_op_rev_tl,
        num_rev_accts,
        num_rev_tl_bal_gt_0,
        num_sats,
        num_tl_120dpd_2m,
        num_tl_30dpd,
        num_tl_90g_dpd_24m,
        num_tl_op_past_12m,
        open_acc,
        open_acc_6m,
        open_act_il,
        open_il_12m,
        open_il_24m,
        open_rv_12m,
        open_rv_24m,
        sec_app_chargeoff_within_12_mths,
        sec_app_collections_12_mths_ex_med,
        sec_app_inq_last_6mths,
        sec_app_mort_acc,
        sec_app_mths_since_last_major_derog,
        sec_app_num_rev_accts,
        sec_app_open_acc,
        sec_app_open_act_il,
        term
      ),
      
      # Floating point
      dbl(
        all_util,
        annual_inc,
        annual_inc_joint,
        avg_cur_bal,
        bc_open_to_buy,
        bc_util,
        collection_recovery_fee,
        delinq_amnt,
        dti,
        dti_joint,
        funded_amnt,
        funded_amnt_inv,
        hardship_amount,
        hardship_last_payment_amount,
        hardship_payoff_balance_amount,
        il_util,
        installment,
        int_rate,
        last_pymnt_amnt,
        loan_amnt,
        max_bal_bc,
        orig_projected_additional_accrued_interest,
        out_prncp,
        out_prncp_inv,
        pct_tl_nvr_dlq,
        percent_bc_gt_75,
        pub_rec,
        pub_rec_bankruptcies,
        recoveries,
        revol_bal,
        revol_bal_joint,
        revol_util,
        sec_app_revol_util,
        settlement_amount,
        settlement_percentage,
        tax_liens,
        tot_coll_amt,
        tot_cur_bal,
        tot_hi_cred_lim,
        total_acc,
        total_bal_ex_mort,
        total_bal_il,
        total_bc_limit,
        total_cu_tl,
        total_il_high_credit_limit,
        total_pymnt,
        total_pymnt_inv,
        total_rec_int,
        total_rec_late_fee,
        total_rec_prncp,
        total_rev_hi_lim
      )
    ) %>%
    
    # Converts some values to 1/-1 (instead of Boolean)
    mutate(
      pymnt_plan =           if_else(pymnt_plan == "y",           1, -1),
      hardship_flag =        if_else(hardship_flag == "Y",        1, -1),
      debt_settlement_flag = if_else(debt_settlement_flag == "Y", 1, -1)
    ) %>%
    
    # Some values are percentages
    mutate(
      int_rate = int_rate / 100,
      dti = dti / 100,
      dti_joint = dti_joint / 100,
      revol_util = revol_util / 100,
      il_util = il_util / 100,
      all_util = all_util / 100,
      bc_open_to_buy = bc_util / 100,
      pct_tl_nvr_dlq = pct_tl_nvr_dlq / 100,
      percent_bc_gt_75 = percent_bc_gt_75 / 100,
      sec_app_revol_util = sec_app_revol_util / 100
    ) %>%
    
    # Create quasi-centered numerical grades out of grade factors with "A" = 3 down to "G" = -3
    mutate(grade_num = 4 - as.integer(grade)) %>%
    
    # Ditto with sub_grades. "A1" = +3.4, "A3" = +3.0, down to "G3" = -3.0, "G5" = -3.4
    mutate(sub_grade_num = 3.6 - as.integer(sub_grade) / 5) %>%
    
    # Keep the first 3 digits of the zipcode as numbers
    mutate(zip_code = as.integer(str_sub(zip_code, 1, 3))) %>%
    
    # Remove empty columns
    select(-id, -member_id, -url)
  
  saveRDS(lc, "datasets/lending_club_reformatted.rds")
  
  
  # Select loans which have matured or been terminated
  past_loans <- lc %>%
    filter(
      loan_status %in% c(
        "Charged Off",
        "Does not meet the credit policy. Status:Charged Off",
        "Does not meet the credit policy. Status:Fully Paid",
        "Fully Paid"
      )
    )
  
  saveRDS(past_loans, "datasets/lending_club_reformatted_paid.rds")
})
```


### Zip codes and FIPS codes

The R package `zipcode` was installed.

```{r zip-package,eval=FALSE,echo=TRUE}
#
# ZIPCodes dataset.
#

library(zipcode)
data(zipcode)
zips <- zipcode %>%
  as_tibble() %>%
  mutate(zip = as.integer(str_sub(zip, 1, 3)))

saveRDS(zips, "datasets/zips.rds")
```


A csv file containing zip codes, FIPS codes and population information was downloaded from the _Simple Maps_ ^[https://simplemaps.com/data/us-zips] website. 

```{r simplemaps,eval=FALSE,echo=TRUE}
local({
  zipfips <- read.csv("datasets/csv/uszips.csv")
  
  # Delete the last 2 digits of the zipcode and only keep relevant information
  zipfips <-
    zipfips %>%
    as_tibble() %>%
    mutate(zip = floor(zip / 100)) %>%
    select(zip, state_id, population, county_fips, county_name)
  
  saveRDS(zipfips, "datasets/zipfips.rds")
})
```

### Market interest rates

Market interest rates (3-year and 5-year swap rates) were download from the Saint Louis Federal Reserve Bank. Datasets are split between before and after the LIBOR fixing scandal. The datasets are merged with disctinct dates.

Download sources are:

+ Pre-LIBOR 3-y swap https://fred.stlouisfed.org/series/DSWP3
+ Post-LIBOR 3-y swap https://fred.stlouisfed.org/series/ICERATES1100USD3Y

+ Pre-LIBOR 5-y swap https://fred.stlouisfed.org/series/MSWP5
+ Post-LIBOR 5-y swap https://fred.stlouisfed.org/series/ICERATES1100USD5Y


```{r market-rates,eval=FALSE,echo=TRUE}
local({
  LIBOR3Y <- read.csv("datasets/csv/DSWP3.csv") %>%
    as_tibble() %>%
    filter(DSWP3 != ".") %>%
    mutate(DATE = as_date(DATE),
           RATE3Y = as.numeric(as.character(DSWP3)) / 100) %>%
    select(DATE, RATE3Y)
  
  ICE3Y <- read.csv("datasets/csv/ICERATES1100USD3Y.csv") %>%
    as_tibble() %>%
    filter(ICERATES1100USD3Y != ".") %>%
    mutate(DATE = as_date(DATE),
           RATE3Y = as.numeric(as.character(ICERATES1100USD3Y)) / 100) %>%
    select(DATE, RATE3Y)
  
  
  LIBOR5Y <- read.csv("datasets/csv/DSWP5.csv") %>%
    as_tibble() %>%
    filter(DSWP5 != ".") %>%
    mutate(DATE = as_date(DATE),
           RATE5Y = as.numeric(as.character(DSWP5)) / 100) %>%
    select(DATE, RATE5Y)
  
  ICE5Y <- read.csv("datasets/csv/ICERATES1100USD5Y.csv") %>%
    as_tibble() %>%
    filter(ICERATES1100USD5Y != ".") %>%
    mutate(DATE = as_date(DATE),
           RATE5Y = as.numeric(as.character(ICERATES1100USD5Y)) / 100) %>%
    select(DATE, RATE5Y)
  
  RATES3Y <- LIBOR3Y %>% rbind(ICE3Y) %>%
    arrange(DATE) %>% distinct(DATE, .keep_all = TRUE)
  
  RATES5Y <- LIBOR5Y %>% rbind(ICE5Y) %>%
    arrange(DATE) %>% distinct(DATE, .keep_all = TRUE)
  
  saveRDS(RATES3Y, "datasets/rates3Y.rds")
  saveRDS(RATES5Y, "datasets/rates5Y.rds")
  
  
  # Note there are 7212 days from 1 Jan 2000 to 30 Sep 2019
  #
  # (ymd("2000-01-01") %--% ymd("2019-09-30")) %/% days(1)
  RATES <- tibble(n = seq(0, 7212)) %>%
    
    # Create a column with all dates
    mutate(DATE = ymd("2000-01-01") + days(n)) %>%
    select(-n) %>%
    
    # Add all daily 3- then 5-year rates and fill missing down
    left_join(RATES3Y) %>%
    fill(RATE3Y, .direction = "down") %>%
    
    left_join(RATES5Y) %>%
    fill(RATE5Y, .direction = "down")
  
  saveRDS(RATES, "datasets/rates.rds")
})
```

### Macro-economical data

Macro-economical datasets were sourced from the same website as Microsoft Excel files. They were converted as-is to tab-separated csv files with LibreOffice. 

+ Median income per household:
https://geofred.stlouisfed.org/map/?th=pubugn&cc=5&rc=false&im=fractile&sb&lng=-112.41&lat=44.31&zm=4&sl&sv&am=Average&at=Not%20Seasonally%20Adjusted,%20Annual,%20Dollars&sti=2022&fq=Annual&rt=county&un=lin&dt=2017-01-01

+ Per capita personal income: 
https://geofred.stlouisfed.org/map/?th=pubugn&cc=5&rc=false&im=fractile&sb&lng=-112.41&lat=44.31&zm=4&sl&sv&am=Average&at=Not%20Seasonally%20Adjusted,%20Annual,%20Dollars&sti=882&fq=Annual&rt=county&un=lin&dt=2017-01-01

+ Unemployment:
https://geofred.stlouisfed.org/map/?th=rdpu&cc=5&rc=false&im=fractile&sb&lng=-90&lat=40&zm=4&sl&sv&am=Average&at=Not%20Seasonally%20Adjusted,%20Monthly,%20Percent&sti=1224&fq=Monthly&rt=county&un=lin&dt=2019-08-01



```{r macro-data,eval=FALSE,echo=TRUE}
local({
  ###################################################################################################
  ##
  ## Median income per household by FIPS from 2002 to 2017
  ##
  medianIncome <-
    # Load the dataset after dropping the first line
    read.csv(
      "datasets/csv/GeoFRED_Estimate_of_Median_Household_Income_by_County_Dollars.csv",
      sep = "\t",
      skip = 1,
      stringsAsFactors = FALSE
    ) %>%
    
    # Drops columnsn containing a unique identifier and the FIPS name
    select(-"Series.ID", -"Region.Name") %>%
    
    # Rename the relevant column to 'FIPS'
    rename(FIPS = "Region.Code") %>%
    
    # Order by FIPS
    arrange(FIPS) %>%
    
    # Transpose the table to have the FIPS as columns, and the years as observations
    t()
  
  # After the transpose, correct the name of the columns by using the first row (from which blanks are removed)
  colnames(medianIncome) <- medianIncome[1, ] %>% str_remove("[ ]")
  
  # Create a new column with the name of the year and converts to tible
  medianIncome <-
    cbind(Year = rownames(medianIncome), medianIncome) %>%
    as_tibble() %>%
    slice(2:n())
  
  # Converts the content of the Year column to an actual date
  medianIncome <- medianIncome %>%
    mutate(Year = str_replace(Year, "[X]", ""),
           Year = ymd(str_c(Year, "-12-31")))
  
  saveRDS(medianIncome, "datasets/medianincome.rds")
  
  
  ###################################################################################################
  ##
  ## Per capita income by FIPS from 2002 to 2017
  ##
  personalIncome <-
    # Load the dataset after dropping the first line
    read.csv(
      "datasets/csv/GeoFRED_Per_Capita_Personal_Income_by_County_Dollars.csv",
      sep = "\t",
      skip = 1,
      stringsAsFactors = FALSE
    ) %>%
    
    # Drops columnsn containing a unique identifier and the FIPS name
    select(-"Series.ID", -"Region.Name") %>%
    
    # Rename the relevant column to 'FIPS'
    rename(FIPS = "Region.Code") %>%
    
    # Order by FIPS
    arrange(FIPS) %>%
    
    # Transpose the table to have the FIPS as columns, and the years as observations
    t()
  
  # Correct the name of the columns after the transpose
  colnames(personalIncome) <-
    personalIncome[1, ] %>% str_remove("[ ]")
  
  # Create a new column with the name of the year and converts to tible
  personalIncome <-
    cbind(Year = rownames(personalIncome), personalIncome) %>%
    as_tibble() %>%
    slice(2:n())
  
  # Converts the content of the Year column to an actual date
  personalIncome <- personalIncome %>%
    mutate(Year = str_replace(Year, "[X]", ""),
           Year = ymd(str_c(Year, "-12-31")))
  
  saveRDS(personalIncome, "datasets/personalincome.rds")
  
  
  ###################################################################################################
  ##
  ## Unemplyment rate monthly by FIPS from January 2000 to August 2019
  ##
  unemploymentRate <-
    # Load the dataset after dropping the first line
    read.csv(
      "datasets/csv/GeoFRED_Unemployment_Rate_by_County_Percent.csv",
      sep = "\t",
      skip = 1,
      stringsAsFactors = FALSE
    ) %>%
    
    # Drops columnsn containing a unique identifier and the FIPS name
    select(-"Series.ID", -"Region.Name") %>%
    
    # Rename the relevant column to 'FIPS'
    rename(FIPS = "Region.Code") %>%
    
    # Order by FIPS
    arrange(FIPS) %>%
    
    # Transpose the table to have the FIPS as columns, and the years as observations
    t()
  
  # Correct the name of the columns after the transpose
  colnames(unemploymentRate) <-
    unemploymentRate[1, ] %>% str_remove("[ ]")
  
  # Create a new column with the name of the year and converts to tible
  unemploymentRate <-
    cbind(Year = rownames(unemploymentRate), unemploymentRate) %>%
    as_tibble() %>%
    slice(2:n())
  
  # Converts the content of the Year column to an actual date
  unemploymentRate <- unemploymentRate %>%
    mutate(
      Year = str_replace(Year, "[X]", ""),
      Year = str_replace(Year, "[.]", "-"),
      Year = ymd(str_c(Year, "-1"))
    )
  
  saveRDS(unemploymentRate, "datasets/unemployment.rds")
})
```


## List of variables 

This table presents the list of variables provided in the original dataset. The descriptions come from a spreadsheet attached with the dataset and, unfortunately, are not extremely precise and subject to interpretation. We added comments and/or particular interpretations in _CAPITAL LETTERS_.


```{r variable-description,cache=FALSE}
LC_variable %>%
  select(variable_name, description) %>% 
  
  # Format the table.
  kable(
    "latex",
    caption = "Description of the dataset variables as provided in the dataset downloaded from Kaggle",
    booktabs = T,
    longtable = T,
    col.names = c("Variable Name", "Description")
  ) %>%
  kable_styling(full_width = F,
                latex_options = c("repeat_header")) %>%
  column_spec(1, width = "7cm") %>%
  column_spec(2, width = "7cm")


```


## System version

```{r system_version,eval=TRUE,eval=TRUE,cache=FALSE}
Sys.info()

```



